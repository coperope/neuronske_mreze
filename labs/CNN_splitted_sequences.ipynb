{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"CNN_splitted_sequences.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"4l9NkHEUPasv","executionInfo":{"status":"ok","timestamp":1624912529873,"user_tz":-120,"elapsed":5,"user":{"displayName":"Mihajlo Perendija","photoUrl":"","userId":"04858557923362990038"}}},"source":["import numpy as np\n","import pandas as pd\n","import math\n"],"execution_count":1,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"b98-Htg9Pak_","executionInfo":{"status":"ok","timestamp":1624912547189,"user_tz":-120,"elapsed":16786,"user":{"displayName":"Mihajlo Perendija","photoUrl":"","userId":"04858557923362990038"}},"outputId":"b32ad708-3506-4408-9841-de9bb6ed712b"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"KI_2xSqHPacQ","executionInfo":{"status":"ok","timestamp":1624912549179,"user_tz":-120,"elapsed":1995,"user":{"displayName":"Mihajlo Perendija","photoUrl":"","userId":"04858557923362990038"}}},"source":["data = pd.read_pickle('/content/drive/MyDrive/neuronske/data/full_sequences.pkl')"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"id":"aB-NoMv4Qs-A"},"source":["training = data[data['event_label'] == 'Alarm_bell_ringing']\n","\n","X = np.array(training.mfccs.tolist())\n","y = np.array(training.combine_squence_per_filename_and_event.tolist())\n","\n","X = np.einsum('ijk->ikj', X)\n","\n","# split the dataset \n","from sklearn.model_selection import train_test_split \n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state = 42)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HCP_1qOqQ2EX","executionInfo":{"status":"ok","timestamp":1624823932702,"user_tz":-120,"elapsed":14,"user":{"displayName":"Mihajlo Perendija","photoUrl":"","userId":"04858557923362990038"}},"outputId":"d40709fb-4190-401f-8f38-d55a566d03b7"},"source":["X_train.shape"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(313, 431, 13)"]},"metadata":{"tags":[]},"execution_count":5}]},{"cell_type":"code","metadata":{"id":"NWe6Vu4GPaNT","executionInfo":{"status":"ok","timestamp":1624912549180,"user_tz":-120,"elapsed":10,"user":{"displayName":"Mihajlo Perendija","photoUrl":"","userId":"04858557923362990038"}}},"source":["# USED ONLY FOR TESTING\n","# NOT GOOD FOR SEQ TO SEQ, IT IS NOT JUST CLASSIFICATION\n","# IMPLEMENT WHAT THEY DID IN TASK WHERE WE GOT THE IDEA\n","\n","# CONCLUSIONS: TOO MUCH FALSE NEGATIVES - BAD RECALL\n","#              BIGGER LATENT_TIM -> BETTER RESULTS -- LAT_DIM-F1 : 13-68, 64-70 256-73\n","def simple_evaluation(y_pred, y_test):\n","  tp = 0\n","  tn = 0\n","  fp = 0\n","  fn = 0\n","\n","  for i, pred_arr in enumerate(y_pred):\n","    for j, pred_value in enumerate(pred_arr):\n","      predicted = pred_value\n","      real = y_test[i][j]\n","      if predicted and real:\n","        tp = tp + 1\n","      elif not(predicted) and real:\n","        fn = fn + 1\n","      elif predicted and not(real):\n","        fp = fp + 1\n","      elif not(predicted) and not(real):\n","        tn = tn + 1\n","    # break\n","\n","  precision = tp / (tp + fp)\n","  recall = tp / (tp + fn)\n","  f1 = 2 * precision * recall / (precision + recall)\n","\n","  print(\"PRECISION: \" + str(precision))\n","  print(\"RECALL: \" + str(recall))\n","  print(\"F1: \" + str(f1))\n","  print(\"-\"*20)\n","  print(\"tp: \" + str(tp))\n","  print(\"tn: \" + str(tn))\n","  print(\"fp: \" + str(fp))\n","  print(\"fn: \" + str(fn))\n"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"WV9tyMMvOOCz"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"InNwDj6vOlO_","executionInfo":{"status":"ok","timestamp":1624912549181,"user_tz":-120,"elapsed":9,"user":{"displayName":"Mihajlo Perendija","photoUrl":"","userId":"04858557923362990038"}}},"source":["def chunks(lst, n):\n","  \"\"\"Yield successive n-sized chunks from lst.\"\"\"\n","  return ([lst[i:i + n] for i in range(0, len(lst), n)])\n","\n","\n","def split_sequences_into_seconds(X, y, seconds = 1):\n","  sequence_len = X.shape[1]\n","  ticks_per_chosen_second = math.ceil(sequence_len / (10 / seconds))\n","  num_of_parts_of_sequence = math.ceil(sequence_len / ticks_per_chosen_second)\n","  # ticks_per_sequence = math.ceil(sequence_len / num_of_parts_of_sequence)\n","\n","  # print(ticks_per_chosen_second)\n","  # print(num_of_parts_of_sequence)\n","  # print(ticks_per_sequence)\n","\n","  X_new = []\n","  y_new = []\n","  for i, sequence in enumerate(X):\n","    X_splits = chunks(sequence, ticks_per_chosen_second)\n","    y_splits = chunks(y[i], ticks_per_chosen_second)\n","    x_false_instances = np.array([]).reshape(0,X_splits[0].shape[1])\n","    for j, X_split in enumerate(X_splits):\n","      X_temp = X_split\n","      y_temp = y_splits[j]\n","      if len(x_false_instances) < ticks_per_chosen_second:\n","        false_indices = np.where(~y_temp)\n","        x_false_instances = np.append(x_false_instances, X_split[false_indices], axis=0)\n","\n","      diff = ticks_per_chosen_second - len(X_temp)\n","      if diff != 0:\n","        y_temp = np.append(y_temp, [0] * diff)\n","        X_temp = np.append(X_temp, x_false_instances[0: diff], axis=0)\n","        \n","      X_new.append(X_temp)\n","      y_new.append(y_temp)\n","\n","\n","  return np.asarray(X_new), np.asarray(y_new)"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YnBbX333Re4p","executionInfo":{"status":"ok","timestamp":1624821613125,"user_tz":-120,"elapsed":9,"user":{"displayName":"Mihajlo Perendija","photoUrl":"","userId":"04858557923362990038"}},"outputId":"9f53d03f-4144-435b-8942-99bca2c331ab"},"source":["X_splitted, y_splitted = split_sequences_into_seconds(X, y, 0.2)\n","print(X.shape)\n","print(X_splitted.shape)\n","print(y.shape)\n","print(y_splitted.shape)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["(392, 431, 13)\n","(18816, 9, 13)\n","(392, 431)\n","(18816, 9)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"xK-khKpXRyw6"},"source":["# split the dataset \n","from sklearn.model_selection import train_test_split \n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state = 42)\n","X_train, y_train = split_sequences_into_seconds(X_train, y_train, 0.2)\n","X_test, y_test = split_sequences_into_seconds(X_test, y_test, 0.2)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"7nxgsoqFSDU-","executionInfo":{"status":"ok","timestamp":1624912557106,"user_tz":-120,"elapsed":1906,"user":{"displayName":"Mihajlo Perendija","photoUrl":"","userId":"04858557923362990038"}}},"source":["import keras\n","def build_model_cnn(input_shape, output_shape):\n","    \"\"\"Generates CNN model\n","    :param input_shape (tuple): Shape of input set\n","    :return model: CNN model\n","    \"\"\"\n","\n","    # build network topology\n","    model = keras.Sequential()\n","\n","    # 1st conv layer\n","    model.add(keras.layers.Conv2D(128, (3, 3), activation='relu', input_shape=input_shape))\n","    model.add(keras.layers.MaxPooling2D((3, 3), strides=(2, 2), padding='same'))\n","    model.add(keras.layers.BatchNormalization())\n","\n","    # 2nd conv layer\n","    model.add(keras.layers.Conv2D(128, (3, 3), activation='relu'))\n","    model.add(keras.layers.MaxPooling2D((3, 3), strides=(2, 2), padding='same'))\n","    model.add(keras.layers.BatchNormalization())\n","\n","    # flatten output and feed it into dense layer\n","    model.add(keras.layers.Flatten())\n","    model.add(keras.layers.Dense(256, activation='relu'))\n","    model.add(keras.layers.Dropout(0.3))\n","\n","    # output layer\n","    # output layer\n","    model.add(keras.layers.Dense(output_shape, activation='sigmoid'))\n","\n","    model.compile(loss='binary_crossentropy', metrics=['accuracy'], optimizer='adam')\n","\n","    return model"],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"q2hsc9r3TBPQ","executionInfo":{"status":"ok","timestamp":1624821623910,"user_tz":-120,"elapsed":1485,"user":{"displayName":"Mihajlo Perendija","photoUrl":"","userId":"04858557923362990038"}},"outputId":"b89e242d-4f6e-4fd2-bc9c-8830a23182e3"},"source":["input_shape = (X_train.shape[1], X_train.shape[2], 1)\n","output_shape = X_train.shape[1]\n","model = build_model_cnn(input_shape, output_shape)\n","model.summary()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Model: \"sequential\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","conv2d (Conv2D)              (None, 7, 11, 128)        1280      \n","_________________________________________________________________\n","max_pooling2d (MaxPooling2D) (None, 4, 6, 128)         0         \n","_________________________________________________________________\n","batch_normalization (BatchNo (None, 4, 6, 128)         512       \n","_________________________________________________________________\n","conv2d_1 (Conv2D)            (None, 2, 4, 128)         147584    \n","_________________________________________________________________\n","max_pooling2d_1 (MaxPooling2 (None, 1, 2, 128)         0         \n","_________________________________________________________________\n","batch_normalization_1 (Batch (None, 1, 2, 128)         512       \n","_________________________________________________________________\n","flatten (Flatten)            (None, 256)               0         \n","_________________________________________________________________\n","dense (Dense)                (None, 256)               65792     \n","_________________________________________________________________\n","dropout (Dropout)            (None, 256)               0         \n","_________________________________________________________________\n","dense_1 (Dense)              (None, 9)                 2313      \n","=================================================================\n","Total params: 217,993\n","Trainable params: 217,481\n","Non-trainable params: 512\n","_________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"qGH8h5NPVwv4"},"source":["X_train.shape\n","X_train = np.expand_dims(X_train, axis=-1)\n","X_test = np.expand_dims(X_test, axis=-1)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cb2RJSLAV9_4","executionInfo":{"status":"ok","timestamp":1624821631275,"user_tz":-120,"elapsed":5,"user":{"displayName":"Mihajlo Perendija","photoUrl":"","userId":"04858557923362990038"}},"outputId":"e82d7dde-d0b7-448d-d622-798c112d0b23"},"source":["X_test.shape"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(3792, 9, 13, 1)"]},"metadata":{"tags":[]},"execution_count":13}]},{"cell_type":"code","metadata":{"id":"s-gM9PByWv-p","executionInfo":{"status":"ok","timestamp":1624912559536,"user_tz":-120,"elapsed":283,"user":{"displayName":"Mihajlo Perendija","photoUrl":"","userId":"04858557923362990038"}}},"source":["import tensorflow.keras as keras\n","import matplotlib.pyplot as plt\n","\n","def plot_history(history):\n","    \"\"\"Plots accuracy/loss for training/validation set as a function of the epochs\n","        :param history: Training history of model\n","        :return:\n","    \"\"\"\n","\n","    fig, axs = plt.subplots(2)\n","\n","    # create accuracy sublpot\n","    axs[0].plot(history.history[\"accuracy\"], label=\"train accuracy\")\n","    axs[0].plot(history.history[\"val_accuracy\"], label=\"test accuracy\")\n","    axs[0].set_ylabel(\"Accuracy\")\n","    axs[0].legend(loc=\"lower right\")\n","    axs[0].set_title(\"Accuracy eval\")\n","\n","    # create error sublpot\n","    axs[1].plot(history.history[\"loss\"], label=\"train error\")\n","    axs[1].plot(history.history[\"val_loss\"], label=\"test error\")\n","    axs[1].set_ylabel(\"Error\")\n","    axs[1].set_xlabel(\"Epoch\")\n","    axs[1].legend(loc=\"upper right\")\n","    axs[1].set_title(\"Error eval\")\n","\n","    plt.show()"],"execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":612},"id":"7RIhdaUhTge3","executionInfo":{"status":"error","timestamp":1624821747084,"user_tz":-120,"elapsed":108569,"user":{"displayName":"Mihajlo Perendija","photoUrl":"","userId":"04858557923362990038"}},"outputId":"02189f33-e291-47da-eb59-1929c4c274ab"},"source":["# train model\n","\n","history = model.fit(X_train, y_train, validation_data=(X_test, y_test), batch_size=64, epochs=110)\n","\n","# plot accuracy/error for training and validation\n","# plot_history(history)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Epoch 1/110\n","235/235 [==============================] - 33s 59ms/step - loss: 0.3228 - accuracy: 0.1397 - val_loss: 0.3245 - val_accuracy: 0.0285\n","Epoch 2/110\n","235/235 [==============================] - 13s 56ms/step - loss: 0.2318 - accuracy: 0.1678 - val_loss: 0.2838 - val_accuracy: 0.2919\n","Epoch 3/110\n","235/235 [==============================] - 13s 57ms/step - loss: 0.2039 - accuracy: 0.1773 - val_loss: 0.2962 - val_accuracy: 0.3199\n","Epoch 4/110\n","235/235 [==============================] - 13s 54ms/step - loss: 0.1939 - accuracy: 0.2138 - val_loss: 0.2866 - val_accuracy: 0.1498\n","Epoch 5/110\n","235/235 [==============================] - 13s 57ms/step - loss: 0.1791 - accuracy: 0.2358 - val_loss: 0.2943 - val_accuracy: 0.2207\n","Epoch 6/110\n","235/235 [==============================] - 14s 58ms/step - loss: 0.1653 - accuracy: 0.2736 - val_loss: 0.2757 - val_accuracy: 0.2782\n","Epoch 7/110\n","144/235 [=================>............] - ETA: 4s - loss: 0.1640 - accuracy: 0.2827"],"name":"stdout"},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-15-45eeba06b2c3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# train model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m110\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# plot accuracy/error for training and validation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1156\u001b[0m                 _r=1):\n\u001b[1;32m   1157\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1158\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1159\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1160\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    887\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    915\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    916\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 917\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    918\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    919\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3022\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   3023\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 3024\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   3025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3026\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1959\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1960\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1961\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1962\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1963\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    594\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    595\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 596\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    597\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    598\u001b[0m           outputs = execute.execute_with_cancellation(\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","metadata":{"id":"rj7zGO0UUKxW"},"source":["\n","y_pred = model.predict(X_test, batch_size=64, verbose=1)\n","y_pred = (y_pred > 0.5)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"N6EiUsBLXv5w","executionInfo":{"status":"ok","timestamp":1623269353841,"user_tz":-120,"elapsed":6,"user":{"displayName":"Petar Basic","photoUrl":"","userId":"05793307805495222209"}},"outputId":"4b281a14-d8ec-41fe-d78c-8c2308250fce"},"source":["num = 1\n","print(y_pred[num])\n","print(y_test[num])\n","print(y_test.shape)\n","print(y[num])"],"execution_count":null,"outputs":[{"output_type":"stream","text":["[False False False False False False False False False]\n","[0 0 0 0 0 0 0 0 0]\n","(3764, 9)\n","[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"," 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"," 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"," 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"," 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"," 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"," 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"," 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"," 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"," 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"," 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"," 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8KP3vE1WZkES","executionInfo":{"status":"ok","timestamp":1623271686193,"user_tz":-120,"elapsed":289,"user":{"displayName":"Petar Basic","photoUrl":"","userId":"05793307805495222209"}},"outputId":"89604b2c-d16e-406e-edbd-c1a976205c2f"},"source":["y_pred.shape[0]"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["3792"]},"metadata":{"tags":[]},"execution_count":88}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NG2AYL57gmPq","executionInfo":{"status":"ok","timestamp":1623271306470,"user_tz":-120,"elapsed":277,"user":{"displayName":"Petar Basic","photoUrl":"","userId":"05793307805495222209"}},"outputId":"07f1a8e9-bfaf-4865-8e73-f2e577f4383a"},"source":["y.shape"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(392, 431)"]},"metadata":{"tags":[]},"execution_count":86}]},{"cell_type":"code","metadata":{"id":"jiYsMnI0aFlB","executionInfo":{"status":"ok","timestamp":1624912564278,"user_tz":-120,"elapsed":261,"user":{"displayName":"Mihajlo Perendija","photoUrl":"","userId":"04858557923362990038"}}},"source":["# Doterati malo ne treba ovoliko parametara\n","def combine_predicted_to_original(y_pred, seconds, sequence_len):\n","  ticks_per_chosen_second = math.ceil(sequence_len / (10 / seconds))\n","  num_of_parts_of_sequence = math.ceil(sequence_len / ticks_per_chosen_second)\n","  y_pred_combined = []\n","  # Num of arrays at the end\n","  final_size = math.floor(y_pred.shape[0] / num_of_parts_of_sequence)\n","\n","  print(num_of_parts_of_sequence)\n","  print(final_size)\n","\n","  for i in range(0, final_size):\n","    current_arr = np.array([])\n","    for j in range(0, num_of_parts_of_sequence):\n","      current_arr = np.concatenate((current_arr, y_pred[i * num_of_parts_of_sequence + j])).astype(int)\n","    y_pred_combined.append(current_arr)\n","  return y_pred_combined"],"execution_count":8,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kzpUBFN7i-BD","executionInfo":{"status":"ok","timestamp":1623272381554,"user_tz":-120,"elapsed":291,"user":{"displayName":"Petar Basic","photoUrl":"","userId":"05793307805495222209"}},"outputId":"edb7cd4e-af9a-4b68-a990-d25ed0605701"},"source":["combined_pred_y = combine_predicted_to_original(y, y_pred, 0.2, 431)\n","combined_test_y = combine_predicted_to_original(y, y_test, 0.2, 431)\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["48\n","79\n","48\n","79\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gRyRBn2MapwJ","executionInfo":{"status":"ok","timestamp":1623272465050,"user_tz":-120,"elapsed":278,"user":{"displayName":"Petar Basic","photoUrl":"","userId":"05793307805495222209"}},"outputId":"8879edd0-2cb4-4d43-f607-cd8914206669"},"source":["simple_evaluation(combined_pred_y, combined_test_y)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["PRECISION: 0.8429460232049772\n","RECALL: 0.6703664081305162\n","F1: 0.7468156424581005\n","--------------------\n","tp: 5013\n","tn: 25716\n","fp: 934\n","fn: 2465\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"z_erkDKPW9yB"},"source":["**ANSAMBLE**"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":204},"id":"S6fqRGOtXR92","executionInfo":{"status":"ok","timestamp":1624912570022,"user_tz":-120,"elapsed":689,"user":{"displayName":"Mihajlo Perendija","photoUrl":"","userId":"04858557923362990038"}},"outputId":"8db54c9c-8d4a-4faa-ee2e-b10256cb7f21"},"source":["data = pd.read_pickle('/content/drive/MyDrive/neuronske/data/full_sequences.pkl')\n","data.head()"],"execution_count":9,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>filename</th>\n","      <th>mfccs</th>\n","      <th>event_label</th>\n","      <th>combine_squence_per_filename_and_event</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>2282.wav</td>\n","      <td>[[-659.70654, -618.7009, -581.4676, -577.1263,...</td>\n","      <td>Dog</td>\n","      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n","    </tr>\n","    <tr>\n","      <th>0</th>\n","      <td>2282.wav</td>\n","      <td>[[-659.70654, -618.7009, -581.4676, -577.1263,...</td>\n","      <td>Speech</td>\n","      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>2719.wav</td>\n","      <td>[[-584.7399, -515.89514, -473.47324, -464.3819...</td>\n","      <td>Electric_shaver_toothbrush</td>\n","      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>2719.wav</td>\n","      <td>[[-584.7399, -515.89514, -473.47324, -464.3819...</td>\n","      <td>Speech</td>\n","      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>1238.wav</td>\n","      <td>[[-401.96198, -400.9539, -411.34525, -405.876,...</td>\n","      <td>Blender</td>\n","      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   filename  ...             combine_squence_per_filename_and_event\n","0  2282.wav  ...  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...\n","0  2282.wav  ...  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...\n","1  2719.wav  ...  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...\n","1  2719.wav  ...  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...\n","2  1238.wav  ...  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...\n","\n","[5 rows x 4 columns]"]},"metadata":{"tags":[]},"execution_count":9}]},{"cell_type":"code","metadata":{"id":"smZhtxyFXOLJ"},"source":["# X_splitted, y_splitted = split_sequences_into_seconds(X, y, 0.2)\n","\n","# print(X.shape)\n","# print(X_splitted.shape)\n","# print(y.shape)\n","# print(y_splitted.shape)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WWHYMD45XGEA","executionInfo":{"status":"ok","timestamp":1624912573142,"user_tz":-120,"elapsed":276,"user":{"displayName":"Mihajlo Perendija","photoUrl":"","userId":"04858557923362990038"}},"outputId":"495b5da4-e4ef-4235-a774-5b70e9062f02"},"source":["unique_events = np.sort(data['event_label'].unique())\n","print(unique_events)"],"execution_count":10,"outputs":[{"output_type":"stream","text":["['Alarm_bell_ringing' 'Blender' 'Cat' 'Dishes' 'Dog'\n"," 'Electric_shaver_toothbrush' 'Frying' 'Running_water' 'Speech'\n"," 'Vacuum_cleaner']\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"W3ZW9jKlat2R","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1624912867727,"user_tz":-120,"elapsed":277825,"user":{"displayName":"Mihajlo Perendija","photoUrl":"","userId":"04858557923362990038"}},"outputId":"bdc0e2fc-c098-4971-8052-aa633476be60"},"source":["from sklearn.model_selection import train_test_split \n","\n","for index, event in enumerate(unique_events):\n","  training = data[data['event_label'] == event]\n","\n","  X = np.array(training.mfccs.tolist())\n","  y = np.array(training.combine_squence_per_filename_and_event.tolist())\n","\n","  X = np.einsum('ijk->ikj', X)\n","\n","  X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state = 42)\n","  X_train, y_train = split_sequences_into_seconds(X_train, y_train, 5)\n","  X_test, y_test = split_sequences_into_seconds(X_test, y_test, 5)\n","\n","  print(\"-\"*80)\n","  print(str(index) + \" ------ \" + event + \" \" + str(len(X)))\n","\n","  input_shape = (X_train.shape[1], X_train.shape[2], 1)\n","  output_shape = X_train.shape[1]\n","  print(\"X_train shape: \")\n","  print(X_train.shape)\n","  \n","  X_train = np.expand_dims(X_train, axis=-1)\n","  X_test = np.expand_dims(X_test, axis=-1)  \n","  model = build_model_cnn(input_shape, output_shape)\n","  model.summary()\n","  model.fit(X_train, y_train, validation_split=0.2, batch_size=128, epochs=120)\n","  model.save('/content/drive/MyDrive/neuronske/models/' + 'CNN_splitted_seq' + str(event) + '.h5')\n","  print(\"-\"*80)\n"],"execution_count":11,"outputs":[{"output_type":"stream","text":["--------------------------------------------------------------------------------\n","0 ------ Alarm_bell_ringing 392\n","X_train shape: \n","(626, 216, 13)\n","Model: \"sequential\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","conv2d (Conv2D)              (None, 214, 11, 128)      1280      \n","_________________________________________________________________\n","max_pooling2d (MaxPooling2D) (None, 107, 6, 128)       0         \n","_________________________________________________________________\n","batch_normalization (BatchNo (None, 107, 6, 128)       512       \n","_________________________________________________________________\n","conv2d_1 (Conv2D)            (None, 105, 4, 128)       147584    \n","_________________________________________________________________\n","max_pooling2d_1 (MaxPooling2 (None, 53, 2, 128)        0         \n","_________________________________________________________________\n","batch_normalization_1 (Batch (None, 53, 2, 128)        512       \n","_________________________________________________________________\n","flatten (Flatten)            (None, 13568)             0         \n","_________________________________________________________________\n","dense (Dense)                (None, 256)               3473664   \n","_________________________________________________________________\n","dropout (Dropout)            (None, 256)               0         \n","_________________________________________________________________\n","dense_1 (Dense)              (None, 216)               55512     \n","=================================================================\n","Total params: 3,679,064\n","Trainable params: 3,678,552\n","Non-trainable params: 512\n","_________________________________________________________________\n","Epoch 1/120\n","4/4 [==============================] - 33s 552ms/step - loss: 0.7436 - accuracy: 0.0000e+00 - val_loss: 1.1326 - val_accuracy: 0.0000e+00\n","Epoch 2/120\n","4/4 [==============================] - 0s 36ms/step - loss: 0.6103 - accuracy: 0.0060 - val_loss: 1.3246 - val_accuracy: 0.0079\n","Epoch 3/120\n","4/4 [==============================] - 0s 38ms/step - loss: 0.5395 - accuracy: 0.0100 - val_loss: 1.2434 - val_accuracy: 0.0000e+00\n","Epoch 4/120\n","4/4 [==============================] - 0s 35ms/step - loss: 0.4796 - accuracy: 0.0080 - val_loss: 1.1060 - val_accuracy: 0.0079\n","Epoch 5/120\n","4/4 [==============================] - 0s 35ms/step - loss: 0.4338 - accuracy: 0.0240 - val_loss: 1.1409 - val_accuracy: 0.0000e+00\n","Epoch 6/120\n","4/4 [==============================] - 0s 37ms/step - loss: 0.3993 - accuracy: 0.0080 - val_loss: 1.1851 - val_accuracy: 0.0079\n","Epoch 7/120\n","4/4 [==============================] - 0s 36ms/step - loss: 0.3749 - accuracy: 0.0120 - val_loss: 1.1527 - val_accuracy: 0.0159\n","Epoch 8/120\n","4/4 [==============================] - 0s 35ms/step - loss: 0.3503 - accuracy: 0.0040 - val_loss: 0.9391 - val_accuracy: 0.0159\n","Epoch 9/120\n","4/4 [==============================] - 0s 36ms/step - loss: 0.3282 - accuracy: 0.0160 - val_loss: 0.7456 - val_accuracy: 0.0000e+00\n","Epoch 10/120\n","4/4 [==============================] - 0s 35ms/step - loss: 0.3142 - accuracy: 0.0100 - val_loss: 0.7222 - val_accuracy: 0.0079\n","Epoch 11/120\n","4/4 [==============================] - 0s 36ms/step - loss: 0.2983 - accuracy: 0.0120 - val_loss: 0.5956 - val_accuracy: 0.0079\n","Epoch 12/120\n","4/4 [==============================] - 0s 36ms/step - loss: 0.2783 - accuracy: 0.0060 - val_loss: 0.5379 - val_accuracy: 0.0079\n","Epoch 13/120\n","4/4 [==============================] - 0s 37ms/step - loss: 0.2641 - accuracy: 0.0180 - val_loss: 0.4967 - val_accuracy: 0.0000e+00\n","Epoch 14/120\n","4/4 [==============================] - 0s 35ms/step - loss: 0.2535 - accuracy: 0.0140 - val_loss: 0.4715 - val_accuracy: 0.0000e+00\n","Epoch 15/120\n","4/4 [==============================] - 0s 35ms/step - loss: 0.2375 - accuracy: 0.0100 - val_loss: 0.4161 - val_accuracy: 0.0000e+00\n","Epoch 16/120\n","4/4 [==============================] - 0s 35ms/step - loss: 0.2271 - accuracy: 0.0180 - val_loss: 0.4385 - val_accuracy: 0.0000e+00\n","Epoch 17/120\n","4/4 [==============================] - 0s 36ms/step - loss: 0.2087 - accuracy: 0.0160 - val_loss: 0.4162 - val_accuracy: 0.0159\n","Epoch 18/120\n","4/4 [==============================] - 0s 35ms/step - loss: 0.1946 - accuracy: 0.0160 - val_loss: 0.3864 - val_accuracy: 0.0079\n","Epoch 19/120\n","4/4 [==============================] - 0s 37ms/step - loss: 0.1808 - accuracy: 0.0100 - val_loss: 0.4214 - val_accuracy: 0.0238\n","Epoch 20/120\n","4/4 [==============================] - 0s 37ms/step - loss: 0.1695 - accuracy: 0.0240 - val_loss: 0.3600 - val_accuracy: 0.0000e+00\n","Epoch 21/120\n","4/4 [==============================] - 0s 39ms/step - loss: 0.1622 - accuracy: 0.0180 - val_loss: 0.4004 - val_accuracy: 0.0159\n","Epoch 22/120\n","4/4 [==============================] - 0s 35ms/step - loss: 0.1524 - accuracy: 0.0120 - val_loss: 0.3622 - val_accuracy: 0.0159\n","Epoch 23/120\n","4/4 [==============================] - 0s 37ms/step - loss: 0.1414 - accuracy: 0.0180 - val_loss: 0.3691 - val_accuracy: 0.0159\n","Epoch 24/120\n","4/4 [==============================] - 0s 36ms/step - loss: 0.1333 - accuracy: 0.0240 - val_loss: 0.3814 - val_accuracy: 0.0159\n","Epoch 25/120\n","4/4 [==============================] - 0s 35ms/step - loss: 0.1249 - accuracy: 0.0200 - val_loss: 0.3507 - val_accuracy: 0.0159\n","Epoch 26/120\n","4/4 [==============================] - 0s 35ms/step - loss: 0.1231 - accuracy: 0.0100 - val_loss: 0.3635 - val_accuracy: 0.0079\n","Epoch 27/120\n","4/4 [==============================] - 0s 36ms/step - loss: 0.1142 - accuracy: 0.0120 - val_loss: 0.3573 - val_accuracy: 0.0000e+00\n","Epoch 28/120\n","4/4 [==============================] - 0s 38ms/step - loss: 0.1084 - accuracy: 0.0200 - val_loss: 0.3646 - val_accuracy: 0.0000e+00\n","Epoch 29/120\n","4/4 [==============================] - 0s 36ms/step - loss: 0.1039 - accuracy: 0.0220 - val_loss: 0.4244 - val_accuracy: 0.0000e+00\n","Epoch 30/120\n","4/4 [==============================] - 0s 37ms/step - loss: 0.1009 - accuracy: 0.0120 - val_loss: 0.3530 - val_accuracy: 0.0000e+00\n","Epoch 31/120\n","4/4 [==============================] - 0s 36ms/step - loss: 0.0977 - accuracy: 0.0140 - val_loss: 0.4144 - val_accuracy: 0.0079\n","Epoch 32/120\n","4/4 [==============================] - 0s 36ms/step - loss: 0.0924 - accuracy: 0.0160 - val_loss: 0.3935 - val_accuracy: 0.0079\n","Epoch 33/120\n","4/4 [==============================] - 0s 37ms/step - loss: 0.0888 - accuracy: 0.0240 - val_loss: 0.3318 - val_accuracy: 0.0159\n","Epoch 34/120\n","4/4 [==============================] - 0s 37ms/step - loss: 0.0864 - accuracy: 0.0160 - val_loss: 0.3600 - val_accuracy: 0.0000e+00\n","Epoch 35/120\n","4/4 [==============================] - 0s 36ms/step - loss: 0.0827 - accuracy: 0.0260 - val_loss: 0.3333 - val_accuracy: 0.0000e+00\n","Epoch 36/120\n","4/4 [==============================] - 0s 35ms/step - loss: 0.0794 - accuracy: 0.0180 - val_loss: 0.3149 - val_accuracy: 0.0000e+00\n","Epoch 37/120\n","4/4 [==============================] - 0s 36ms/step - loss: 0.0738 - accuracy: 0.0200 - val_loss: 0.3211 - val_accuracy: 0.0000e+00\n","Epoch 38/120\n","4/4 [==============================] - 0s 36ms/step - loss: 0.0721 - accuracy: 0.0200 - val_loss: 0.3068 - val_accuracy: 0.0079\n","Epoch 39/120\n","4/4 [==============================] - 0s 39ms/step - loss: 0.0665 - accuracy: 0.0140 - val_loss: 0.3290 - val_accuracy: 0.0079\n","Epoch 40/120\n","4/4 [==============================] - 0s 36ms/step - loss: 0.0681 - accuracy: 0.0180 - val_loss: 0.3466 - val_accuracy: 0.0079\n","Epoch 41/120\n","4/4 [==============================] - 0s 37ms/step - loss: 0.0648 - accuracy: 0.0200 - val_loss: 0.3290 - val_accuracy: 0.0079\n","Epoch 42/120\n","4/4 [==============================] - 0s 37ms/step - loss: 0.0626 - accuracy: 0.0180 - val_loss: 0.3768 - val_accuracy: 0.0159\n","Epoch 43/120\n","4/4 [==============================] - 0s 37ms/step - loss: 0.0633 - accuracy: 0.0200 - val_loss: 0.3985 - val_accuracy: 0.0159\n","Epoch 44/120\n","4/4 [==============================] - 0s 36ms/step - loss: 0.0602 - accuracy: 0.0160 - val_loss: 0.3795 - val_accuracy: 0.0079\n","Epoch 45/120\n","4/4 [==============================] - 0s 36ms/step - loss: 0.0568 - accuracy: 0.0120 - val_loss: 0.3829 - val_accuracy: 0.0159\n","Epoch 46/120\n","4/4 [==============================] - 0s 37ms/step - loss: 0.0559 - accuracy: 0.0160 - val_loss: 0.3212 - val_accuracy: 0.0159\n","Epoch 47/120\n","4/4 [==============================] - 0s 36ms/step - loss: 0.0532 - accuracy: 0.0140 - val_loss: 0.3345 - val_accuracy: 0.0159\n","Epoch 48/120\n","4/4 [==============================] - 0s 36ms/step - loss: 0.0516 - accuracy: 0.0200 - val_loss: 0.3273 - val_accuracy: 0.0079\n","Epoch 49/120\n","4/4 [==============================] - 0s 38ms/step - loss: 0.0488 - accuracy: 0.0220 - val_loss: 0.3441 - val_accuracy: 0.0079\n","Epoch 50/120\n","4/4 [==============================] - 0s 35ms/step - loss: 0.0489 - accuracy: 0.0180 - val_loss: 0.3697 - val_accuracy: 0.0079\n","Epoch 51/120\n","4/4 [==============================] - 0s 38ms/step - loss: 0.0473 - accuracy: 0.0220 - val_loss: 0.3912 - val_accuracy: 0.0079\n","Epoch 52/120\n","4/4 [==============================] - 0s 35ms/step - loss: 0.0489 - accuracy: 0.0080 - val_loss: 0.3791 - val_accuracy: 0.0079\n","Epoch 53/120\n","4/4 [==============================] - 0s 35ms/step - loss: 0.0461 - accuracy: 0.0220 - val_loss: 0.4863 - val_accuracy: 0.0079\n","Epoch 54/120\n","4/4 [==============================] - 0s 35ms/step - loss: 0.0473 - accuracy: 0.0200 - val_loss: 0.3614 - val_accuracy: 0.0000e+00\n","Epoch 55/120\n","4/4 [==============================] - 0s 35ms/step - loss: 0.0429 - accuracy: 0.0140 - val_loss: 0.3624 - val_accuracy: 0.0159\n","Epoch 56/120\n","4/4 [==============================] - 0s 36ms/step - loss: 0.0388 - accuracy: 0.0260 - val_loss: 0.3689 - val_accuracy: 0.0079\n","Epoch 57/120\n","4/4 [==============================] - 0s 37ms/step - loss: 0.0419 - accuracy: 0.0160 - val_loss: 0.3596 - val_accuracy: 0.0238\n","Epoch 58/120\n","4/4 [==============================] - 0s 34ms/step - loss: 0.0400 - accuracy: 0.0120 - val_loss: 0.3670 - val_accuracy: 0.0317\n","Epoch 59/120\n","4/4 [==============================] - 0s 37ms/step - loss: 0.0393 - accuracy: 0.0160 - val_loss: 0.3822 - val_accuracy: 0.0238\n","Epoch 60/120\n","4/4 [==============================] - 0s 35ms/step - loss: 0.0400 - accuracy: 0.0200 - val_loss: 0.3584 - val_accuracy: 0.0159\n","Epoch 61/120\n","4/4 [==============================] - 0s 35ms/step - loss: 0.0418 - accuracy: 0.0140 - val_loss: 0.3430 - val_accuracy: 0.0159\n","Epoch 62/120\n","4/4 [==============================] - 0s 34ms/step - loss: 0.0394 - accuracy: 0.0160 - val_loss: 0.3761 - val_accuracy: 0.0159\n","Epoch 63/120\n","4/4 [==============================] - 0s 35ms/step - loss: 0.0395 - accuracy: 0.0220 - val_loss: 0.3941 - val_accuracy: 0.0238\n","Epoch 64/120\n","4/4 [==============================] - 0s 36ms/step - loss: 0.0358 - accuracy: 0.0120 - val_loss: 0.3781 - val_accuracy: 0.0317\n","Epoch 65/120\n","4/4 [==============================] - 0s 36ms/step - loss: 0.0346 - accuracy: 0.0160 - val_loss: 0.3715 - val_accuracy: 0.0238\n","Epoch 66/120\n","4/4 [==============================] - 0s 35ms/step - loss: 0.0374 - accuracy: 0.0280 - val_loss: 0.3769 - val_accuracy: 0.0238\n","Epoch 67/120\n","4/4 [==============================] - 0s 36ms/step - loss: 0.0347 - accuracy: 0.0120 - val_loss: 0.3675 - val_accuracy: 0.0159\n","Epoch 68/120\n","4/4 [==============================] - 0s 37ms/step - loss: 0.0314 - accuracy: 0.0100 - val_loss: 0.3654 - val_accuracy: 0.0159\n","Epoch 69/120\n","4/4 [==============================] - 0s 37ms/step - loss: 0.0353 - accuracy: 0.0120 - val_loss: 0.3835 - val_accuracy: 0.0079\n","Epoch 70/120\n","4/4 [==============================] - 0s 40ms/step - loss: 0.0305 - accuracy: 0.0100 - val_loss: 0.4074 - val_accuracy: 0.0159\n","Epoch 71/120\n","4/4 [==============================] - 0s 35ms/step - loss: 0.0342 - accuracy: 0.0120 - val_loss: 0.4248 - val_accuracy: 0.0159\n","Epoch 72/120\n","4/4 [==============================] - 0s 36ms/step - loss: 0.0292 - accuracy: 0.0060 - val_loss: 0.4202 - val_accuracy: 0.0079\n","Epoch 73/120\n","4/4 [==============================] - 0s 36ms/step - loss: 0.0309 - accuracy: 0.0080 - val_loss: 0.4130 - val_accuracy: 0.0238\n","Epoch 74/120\n","4/4 [==============================] - 0s 35ms/step - loss: 0.0328 - accuracy: 0.0080 - val_loss: 0.4115 - val_accuracy: 0.0159\n","Epoch 75/120\n","4/4 [==============================] - 0s 37ms/step - loss: 0.0311 - accuracy: 0.0140 - val_loss: 0.4273 - val_accuracy: 0.0079\n","Epoch 76/120\n","4/4 [==============================] - 0s 36ms/step - loss: 0.0292 - accuracy: 0.0140 - val_loss: 0.4206 - val_accuracy: 0.0238\n","Epoch 77/120\n","4/4 [==============================] - 0s 34ms/step - loss: 0.0322 - accuracy: 0.0100 - val_loss: 0.4693 - val_accuracy: 0.0079\n","Epoch 78/120\n","4/4 [==============================] - 0s 36ms/step - loss: 0.0266 - accuracy: 0.0080 - val_loss: 0.4737 - val_accuracy: 0.0079\n","Epoch 79/120\n","4/4 [==============================] - 0s 36ms/step - loss: 0.0292 - accuracy: 0.0100 - val_loss: 0.4405 - val_accuracy: 0.0238\n","Epoch 80/120\n","4/4 [==============================] - 0s 37ms/step - loss: 0.0267 - accuracy: 0.0100 - val_loss: 0.4513 - val_accuracy: 0.0238\n","Epoch 81/120\n","4/4 [==============================] - 0s 37ms/step - loss: 0.0235 - accuracy: 0.0100 - val_loss: 0.4330 - val_accuracy: 0.0238\n","Epoch 82/120\n","4/4 [==============================] - 0s 37ms/step - loss: 0.0244 - accuracy: 0.0140 - val_loss: 0.4291 - val_accuracy: 0.0159\n","Epoch 83/120\n","4/4 [==============================] - 0s 35ms/step - loss: 0.0289 - accuracy: 0.0140 - val_loss: 0.4614 - val_accuracy: 0.0159\n","Epoch 84/120\n","4/4 [==============================] - 0s 35ms/step - loss: 0.0242 - accuracy: 0.0240 - val_loss: 0.4649 - val_accuracy: 0.0317\n","Epoch 85/120\n","4/4 [==============================] - 0s 37ms/step - loss: 0.0246 - accuracy: 0.0080 - val_loss: 0.4302 - val_accuracy: 0.0159\n","Epoch 86/120\n","4/4 [==============================] - 0s 37ms/step - loss: 0.0262 - accuracy: 0.0080 - val_loss: 0.4242 - val_accuracy: 0.0159\n","Epoch 87/120\n","4/4 [==============================] - 0s 36ms/step - loss: 0.0254 - accuracy: 0.0160 - val_loss: 0.4404 - val_accuracy: 0.0159\n","Epoch 88/120\n","4/4 [==============================] - 0s 36ms/step - loss: 0.0256 - accuracy: 0.0140 - val_loss: 0.4584 - val_accuracy: 0.0159\n","Epoch 89/120\n","4/4 [==============================] - 0s 35ms/step - loss: 0.0225 - accuracy: 0.0060 - val_loss: 0.4757 - val_accuracy: 0.0079\n","Epoch 90/120\n","4/4 [==============================] - 0s 35ms/step - loss: 0.0237 - accuracy: 0.0160 - val_loss: 0.4656 - val_accuracy: 0.0079\n","Epoch 91/120\n","4/4 [==============================] - 0s 37ms/step - loss: 0.0241 - accuracy: 0.0140 - val_loss: 0.4719 - val_accuracy: 0.0079\n","Epoch 92/120\n","4/4 [==============================] - 0s 38ms/step - loss: 0.0226 - accuracy: 0.0100 - val_loss: 0.4505 - val_accuracy: 0.0159\n","Epoch 93/120\n","4/4 [==============================] - 0s 38ms/step - loss: 0.0198 - accuracy: 0.0020 - val_loss: 0.4757 - val_accuracy: 0.0159\n","Epoch 94/120\n","4/4 [==============================] - 0s 37ms/step - loss: 0.0238 - accuracy: 0.0060 - val_loss: 0.4798 - val_accuracy: 0.0159\n","Epoch 95/120\n","4/4 [==============================] - 0s 38ms/step - loss: 0.0260 - accuracy: 0.0140 - val_loss: 0.4882 - val_accuracy: 0.0159\n","Epoch 96/120\n","4/4 [==============================] - 0s 35ms/step - loss: 0.0206 - accuracy: 0.0120 - val_loss: 0.4932 - val_accuracy: 0.0079\n","Epoch 97/120\n","4/4 [==============================] - 0s 36ms/step - loss: 0.0214 - accuracy: 0.0080 - val_loss: 0.5228 - val_accuracy: 0.0079\n","Epoch 98/120\n","4/4 [==============================] - 0s 36ms/step - loss: 0.0189 - accuracy: 0.0160 - val_loss: 0.5234 - val_accuracy: 0.0397\n","Epoch 99/120\n","4/4 [==============================] - 0s 37ms/step - loss: 0.0191 - accuracy: 0.0220 - val_loss: 0.5165 - val_accuracy: 0.0317\n","Epoch 100/120\n","4/4 [==============================] - 0s 34ms/step - loss: 0.0211 - accuracy: 0.0220 - val_loss: 0.4903 - val_accuracy: 0.0317\n","Epoch 101/120\n","4/4 [==============================] - 0s 37ms/step - loss: 0.0207 - accuracy: 0.0100 - val_loss: 0.4652 - val_accuracy: 0.0159\n","Epoch 102/120\n","4/4 [==============================] - 0s 38ms/step - loss: 0.0187 - accuracy: 0.0160 - val_loss: 0.4493 - val_accuracy: 0.0159\n","Epoch 103/120\n","4/4 [==============================] - 0s 37ms/step - loss: 0.0189 - accuracy: 0.0160 - val_loss: 0.4575 - val_accuracy: 0.0159\n","Epoch 104/120\n","4/4 [==============================] - 0s 38ms/step - loss: 0.0197 - accuracy: 0.0080 - val_loss: 0.4538 - val_accuracy: 0.0159\n","Epoch 105/120\n","4/4 [==============================] - 0s 35ms/step - loss: 0.0174 - accuracy: 0.0120 - val_loss: 0.4890 - val_accuracy: 0.0159\n","Epoch 106/120\n","4/4 [==============================] - 0s 34ms/step - loss: 0.0172 - accuracy: 0.0180 - val_loss: 0.5146 - val_accuracy: 0.0079\n","Epoch 107/120\n","4/4 [==============================] - 0s 36ms/step - loss: 0.0198 - accuracy: 0.0040 - val_loss: 0.5398 - val_accuracy: 0.0000e+00\n","Epoch 108/120\n","4/4 [==============================] - 0s 38ms/step - loss: 0.0212 - accuracy: 0.0100 - val_loss: 0.5277 - val_accuracy: 0.0159\n","Epoch 109/120\n","4/4 [==============================] - 0s 40ms/step - loss: 0.0192 - accuracy: 0.0120 - val_loss: 0.6205 - val_accuracy: 0.0079\n","Epoch 110/120\n","4/4 [==============================] - 0s 35ms/step - loss: 0.0182 - accuracy: 0.0120 - val_loss: 0.5982 - val_accuracy: 0.0159\n","Epoch 111/120\n","4/4 [==============================] - 0s 37ms/step - loss: 0.0170 - accuracy: 0.0140 - val_loss: 0.5043 - val_accuracy: 0.0397\n","Epoch 112/120\n","4/4 [==============================] - 0s 37ms/step - loss: 0.0184 - accuracy: 0.0140 - val_loss: 0.4886 - val_accuracy: 0.0397\n","Epoch 113/120\n","4/4 [==============================] - 0s 36ms/step - loss: 0.0162 - accuracy: 0.0220 - val_loss: 0.5512 - val_accuracy: 0.0317\n","Epoch 114/120\n","4/4 [==============================] - 0s 37ms/step - loss: 0.0184 - accuracy: 0.0100 - val_loss: 0.5853 - val_accuracy: 0.0317\n","Epoch 115/120\n","4/4 [==============================] - 0s 36ms/step - loss: 0.0182 - accuracy: 0.0240 - val_loss: 0.5697 - val_accuracy: 0.0317\n","Epoch 116/120\n","4/4 [==============================] - 0s 36ms/step - loss: 0.0162 - accuracy: 0.0100 - val_loss: 0.5700 - val_accuracy: 0.0238\n","Epoch 117/120\n","4/4 [==============================] - 0s 38ms/step - loss: 0.0144 - accuracy: 0.0100 - val_loss: 0.5746 - val_accuracy: 0.0238\n","Epoch 118/120\n","4/4 [==============================] - 0s 35ms/step - loss: 0.0179 - accuracy: 0.0140 - val_loss: 0.5608 - val_accuracy: 0.0238\n","Epoch 119/120\n","4/4 [==============================] - 0s 37ms/step - loss: 0.0158 - accuracy: 0.0060 - val_loss: 0.5168 - val_accuracy: 0.0317\n","Epoch 120/120\n","4/4 [==============================] - 0s 36ms/step - loss: 0.0180 - accuracy: 0.0140 - val_loss: 0.5184 - val_accuracy: 0.0317\n","--------------------------------------------------------------------------------\n","--------------------------------------------------------------------------------\n","1 ------ Blender 436\n","X_train shape: \n","(696, 216, 13)\n","Model: \"sequential_1\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","conv2d_2 (Conv2D)            (None, 214, 11, 128)      1280      \n","_________________________________________________________________\n","max_pooling2d_2 (MaxPooling2 (None, 107, 6, 128)       0         \n","_________________________________________________________________\n","batch_normalization_2 (Batch (None, 107, 6, 128)       512       \n","_________________________________________________________________\n","conv2d_3 (Conv2D)            (None, 105, 4, 128)       147584    \n","_________________________________________________________________\n","max_pooling2d_3 (MaxPooling2 (None, 53, 2, 128)        0         \n","_________________________________________________________________\n","batch_normalization_3 (Batch (None, 53, 2, 128)        512       \n","_________________________________________________________________\n","flatten_1 (Flatten)          (None, 13568)             0         \n","_________________________________________________________________\n","dense_2 (Dense)              (None, 256)               3473664   \n","_________________________________________________________________\n","dropout_1 (Dropout)          (None, 256)               0         \n","_________________________________________________________________\n","dense_3 (Dense)              (None, 216)               55512     \n","=================================================================\n","Total params: 3,679,064\n","Trainable params: 3,678,552\n","Non-trainable params: 512\n","_________________________________________________________________\n","Epoch 1/120\n","5/5 [==============================] - 2s 311ms/step - loss: 0.7306 - accuracy: 0.0054 - val_loss: 1.9742 - val_accuracy: 0.0000e+00\n","Epoch 2/120\n","5/5 [==============================] - 0s 32ms/step - loss: 0.5859 - accuracy: 0.0036 - val_loss: 3.1322 - val_accuracy: 0.0000e+00\n","Epoch 3/120\n","5/5 [==============================] - 0s 32ms/step - loss: 0.4853 - accuracy: 0.0018 - val_loss: 4.3441 - val_accuracy: 0.0071\n","Epoch 4/120\n","5/5 [==============================] - 0s 32ms/step - loss: 0.4083 - accuracy: 0.0036 - val_loss: 5.7709 - val_accuracy: 0.0071\n","Epoch 5/120\n","5/5 [==============================] - 0s 34ms/step - loss: 0.3572 - accuracy: 0.0072 - val_loss: 5.2426 - val_accuracy: 0.0000e+00\n","Epoch 6/120\n","5/5 [==============================] - 0s 31ms/step - loss: 0.3013 - accuracy: 0.0108 - val_loss: 3.5750 - val_accuracy: 0.0071\n","Epoch 7/120\n","5/5 [==============================] - 0s 31ms/step - loss: 0.2666 - accuracy: 0.0036 - val_loss: 3.2239 - val_accuracy: 0.0071\n","Epoch 8/120\n","5/5 [==============================] - 0s 32ms/step - loss: 0.2349 - accuracy: 0.0072 - val_loss: 2.5624 - val_accuracy: 0.0929\n","Epoch 9/120\n","5/5 [==============================] - 0s 32ms/step - loss: 0.2029 - accuracy: 0.0198 - val_loss: 1.8936 - val_accuracy: 0.0214\n","Epoch 10/120\n","5/5 [==============================] - 0s 32ms/step - loss: 0.1834 - accuracy: 0.0054 - val_loss: 2.2722 - val_accuracy: 0.0071\n","Epoch 11/120\n","5/5 [==============================] - 0s 32ms/step - loss: 0.1688 - accuracy: 0.0198 - val_loss: 1.2638 - val_accuracy: 0.2000\n","Epoch 12/120\n","5/5 [==============================] - 0s 33ms/step - loss: 0.1475 - accuracy: 0.0108 - val_loss: 1.2573 - val_accuracy: 0.0000e+00\n","Epoch 13/120\n","5/5 [==============================] - 0s 31ms/step - loss: 0.1372 - accuracy: 0.0090 - val_loss: 1.0088 - val_accuracy: 0.0143\n","Epoch 14/120\n","5/5 [==============================] - 0s 30ms/step - loss: 0.1279 - accuracy: 0.0324 - val_loss: 1.0192 - val_accuracy: 0.0000e+00\n","Epoch 15/120\n","5/5 [==============================] - 0s 30ms/step - loss: 0.1185 - accuracy: 0.0108 - val_loss: 0.8182 - val_accuracy: 0.0000e+00\n","Epoch 16/120\n","5/5 [==============================] - 0s 35ms/step - loss: 0.1040 - accuracy: 0.0144 - val_loss: 0.6566 - val_accuracy: 0.0429\n","Epoch 17/120\n","5/5 [==============================] - 0s 30ms/step - loss: 0.1009 - accuracy: 0.0036 - val_loss: 0.5795 - val_accuracy: 0.2357\n","Epoch 18/120\n","5/5 [==============================] - 0s 32ms/step - loss: 0.0925 - accuracy: 0.0252 - val_loss: 0.5706 - val_accuracy: 0.0929\n","Epoch 19/120\n","5/5 [==============================] - 0s 33ms/step - loss: 0.0875 - accuracy: 0.0144 - val_loss: 0.5010 - val_accuracy: 0.0571\n","Epoch 20/120\n","5/5 [==============================] - 0s 32ms/step - loss: 0.0822 - accuracy: 0.0180 - val_loss: 0.4392 - val_accuracy: 0.2071\n","Epoch 21/120\n","5/5 [==============================] - 0s 33ms/step - loss: 0.0765 - accuracy: 0.0342 - val_loss: 0.3995 - val_accuracy: 0.0000e+00\n","Epoch 22/120\n","5/5 [==============================] - 0s 35ms/step - loss: 0.0677 - accuracy: 0.0126 - val_loss: 0.3577 - val_accuracy: 0.0000e+00\n","Epoch 23/120\n","5/5 [==============================] - 0s 32ms/step - loss: 0.0646 - accuracy: 0.0144 - val_loss: 0.3648 - val_accuracy: 0.0143\n","Epoch 24/120\n","5/5 [==============================] - 0s 30ms/step - loss: 0.0636 - accuracy: 0.0108 - val_loss: 0.3778 - val_accuracy: 0.1357\n","Epoch 25/120\n","5/5 [==============================] - 0s 33ms/step - loss: 0.0633 - accuracy: 0.0270 - val_loss: 0.3048 - val_accuracy: 0.0714\n","Epoch 26/120\n","5/5 [==============================] - 0s 32ms/step - loss: 0.0607 - accuracy: 0.0162 - val_loss: 0.3597 - val_accuracy: 0.0000e+00\n","Epoch 27/120\n","5/5 [==============================] - 0s 32ms/step - loss: 0.0584 - accuracy: 0.0108 - val_loss: 0.2885 - val_accuracy: 0.0286\n","Epoch 28/120\n","5/5 [==============================] - 0s 34ms/step - loss: 0.0583 - accuracy: 0.0342 - val_loss: 0.3209 - val_accuracy: 0.1786\n","Epoch 29/120\n","5/5 [==============================] - 0s 34ms/step - loss: 0.0539 - accuracy: 0.0270 - val_loss: 0.3270 - val_accuracy: 0.0500\n","Epoch 30/120\n","5/5 [==============================] - 0s 32ms/step - loss: 0.0542 - accuracy: 0.0234 - val_loss: 0.2731 - val_accuracy: 0.0143\n","Epoch 31/120\n","5/5 [==============================] - 0s 33ms/step - loss: 0.0517 - accuracy: 0.0144 - val_loss: 0.2732 - val_accuracy: 0.0143\n","Epoch 32/120\n","5/5 [==============================] - 0s 37ms/step - loss: 0.0517 - accuracy: 0.0072 - val_loss: 0.2609 - val_accuracy: 0.0000e+00\n","Epoch 33/120\n","5/5 [==============================] - 0s 32ms/step - loss: 0.0463 - accuracy: 0.0072 - val_loss: 0.2503 - val_accuracy: 0.0214\n","Epoch 34/120\n","5/5 [==============================] - 0s 32ms/step - loss: 0.0461 - accuracy: 0.0216 - val_loss: 0.2844 - val_accuracy: 0.1000\n","Epoch 35/120\n","5/5 [==============================] - 0s 34ms/step - loss: 0.0451 - accuracy: 0.0216 - val_loss: 0.2468 - val_accuracy: 0.0500\n","Epoch 36/120\n","5/5 [==============================] - 0s 32ms/step - loss: 0.0424 - accuracy: 0.0162 - val_loss: 0.2320 - val_accuracy: 0.0357\n","Epoch 37/120\n","5/5 [==============================] - 0s 32ms/step - loss: 0.0413 - accuracy: 0.0162 - val_loss: 0.2485 - val_accuracy: 0.0500\n","Epoch 38/120\n","5/5 [==============================] - 0s 31ms/step - loss: 0.0386 - accuracy: 0.0126 - val_loss: 0.2375 - val_accuracy: 0.0286\n","Epoch 39/120\n","5/5 [==============================] - 0s 33ms/step - loss: 0.0387 - accuracy: 0.0216 - val_loss: 0.2630 - val_accuracy: 0.0500\n","Epoch 40/120\n","5/5 [==============================] - 0s 36ms/step - loss: 0.0381 - accuracy: 0.0216 - val_loss: 0.2346 - val_accuracy: 0.0143\n","Epoch 41/120\n","5/5 [==============================] - 0s 31ms/step - loss: 0.0350 - accuracy: 0.0090 - val_loss: 0.2284 - val_accuracy: 0.0643\n","Epoch 42/120\n","5/5 [==============================] - 0s 33ms/step - loss: 0.0331 - accuracy: 0.0216 - val_loss: 0.2335 - val_accuracy: 0.1071\n","Epoch 43/120\n","5/5 [==============================] - 0s 30ms/step - loss: 0.0358 - accuracy: 0.0378 - val_loss: 0.2522 - val_accuracy: 0.0286\n","Epoch 44/120\n","5/5 [==============================] - 0s 33ms/step - loss: 0.0324 - accuracy: 0.0108 - val_loss: 0.2264 - val_accuracy: 0.0000e+00\n","Epoch 45/120\n","5/5 [==============================] - 0s 31ms/step - loss: 0.0318 - accuracy: 0.0054 - val_loss: 0.2235 - val_accuracy: 0.0071\n","Epoch 46/120\n","5/5 [==============================] - 0s 30ms/step - loss: 0.0322 - accuracy: 0.0090 - val_loss: 0.2449 - val_accuracy: 0.0071\n","Epoch 47/120\n","5/5 [==============================] - 0s 32ms/step - loss: 0.0311 - accuracy: 0.0216 - val_loss: 0.2450 - val_accuracy: 0.0714\n","Epoch 48/120\n","5/5 [==============================] - 0s 33ms/step - loss: 0.0294 - accuracy: 0.0342 - val_loss: 0.2262 - val_accuracy: 0.0857\n","Epoch 49/120\n","5/5 [==============================] - 0s 33ms/step - loss: 0.0291 - accuracy: 0.0288 - val_loss: 0.2212 - val_accuracy: 0.0500\n","Epoch 50/120\n","5/5 [==============================] - 0s 37ms/step - loss: 0.0291 - accuracy: 0.0198 - val_loss: 0.2147 - val_accuracy: 0.0000e+00\n","Epoch 51/120\n","5/5 [==============================] - 0s 32ms/step - loss: 0.0285 - accuracy: 0.0126 - val_loss: 0.2131 - val_accuracy: 0.0000e+00\n","Epoch 52/120\n","5/5 [==============================] - 0s 33ms/step - loss: 0.0276 - accuracy: 0.0108 - val_loss: 0.2241 - val_accuracy: 0.0000e+00\n","Epoch 53/120\n","5/5 [==============================] - 0s 32ms/step - loss: 0.0255 - accuracy: 0.0144 - val_loss: 0.2604 - val_accuracy: 0.0000e+00\n","Epoch 54/120\n","5/5 [==============================] - 0s 32ms/step - loss: 0.0249 - accuracy: 0.0090 - val_loss: 0.2563 - val_accuracy: 0.0357\n","Epoch 55/120\n","5/5 [==============================] - 0s 33ms/step - loss: 0.0250 - accuracy: 0.0108 - val_loss: 0.2464 - val_accuracy: 0.1000\n","Epoch 56/120\n","5/5 [==============================] - 0s 31ms/step - loss: 0.0252 - accuracy: 0.0234 - val_loss: 0.2331 - val_accuracy: 0.0857\n","Epoch 57/120\n","5/5 [==============================] - 0s 31ms/step - loss: 0.0222 - accuracy: 0.0234 - val_loss: 0.2471 - val_accuracy: 0.0786\n","Epoch 58/120\n","5/5 [==============================] - 0s 32ms/step - loss: 0.0216 - accuracy: 0.0324 - val_loss: 0.2508 - val_accuracy: 0.1143\n","Epoch 59/120\n","5/5 [==============================] - 0s 32ms/step - loss: 0.0245 - accuracy: 0.0504 - val_loss: 0.2436 - val_accuracy: 0.1429\n","Epoch 60/120\n","5/5 [==============================] - 0s 33ms/step - loss: 0.0226 - accuracy: 0.0360 - val_loss: 0.2437 - val_accuracy: 0.0714\n","Epoch 61/120\n","5/5 [==============================] - 0s 34ms/step - loss: 0.0203 - accuracy: 0.0288 - val_loss: 0.2660 - val_accuracy: 0.0000e+00\n","Epoch 62/120\n","5/5 [==============================] - 0s 31ms/step - loss: 0.0207 - accuracy: 0.0126 - val_loss: 0.2738 - val_accuracy: 0.0000e+00\n","Epoch 63/120\n","5/5 [==============================] - 0s 32ms/step - loss: 0.0208 - accuracy: 0.0090 - val_loss: 0.2648 - val_accuracy: 0.0000e+00\n","Epoch 64/120\n","5/5 [==============================] - 0s 31ms/step - loss: 0.0204 - accuracy: 0.0108 - val_loss: 0.2729 - val_accuracy: 0.0071\n","Epoch 65/120\n","5/5 [==============================] - 0s 33ms/step - loss: 0.0226 - accuracy: 0.0162 - val_loss: 0.2756 - val_accuracy: 0.0143\n","Epoch 66/120\n","5/5 [==============================] - 0s 33ms/step - loss: 0.0224 - accuracy: 0.0234 - val_loss: 0.2796 - val_accuracy: 0.0000e+00\n","Epoch 67/120\n","5/5 [==============================] - 0s 32ms/step - loss: 0.0187 - accuracy: 0.0108 - val_loss: 0.2828 - val_accuracy: 0.0000e+00\n","Epoch 68/120\n","5/5 [==============================] - 0s 35ms/step - loss: 0.0206 - accuracy: 0.0090 - val_loss: 0.2803 - val_accuracy: 0.0286\n","Epoch 69/120\n","5/5 [==============================] - 0s 34ms/step - loss: 0.0193 - accuracy: 0.0306 - val_loss: 0.2676 - val_accuracy: 0.0357\n","Epoch 70/120\n","5/5 [==============================] - 0s 31ms/step - loss: 0.0185 - accuracy: 0.0180 - val_loss: 0.2748 - val_accuracy: 0.0071\n","Epoch 71/120\n","5/5 [==============================] - 0s 33ms/step - loss: 0.0175 - accuracy: 0.0144 - val_loss: 0.2728 - val_accuracy: 0.0000e+00\n","Epoch 72/120\n","5/5 [==============================] - 0s 33ms/step - loss: 0.0178 - accuracy: 0.0090 - val_loss: 0.2627 - val_accuracy: 0.0429\n","Epoch 73/120\n","5/5 [==============================] - 0s 32ms/step - loss: 0.0187 - accuracy: 0.0252 - val_loss: 0.2769 - val_accuracy: 0.0143\n","Epoch 74/120\n","5/5 [==============================] - 0s 32ms/step - loss: 0.0190 - accuracy: 0.0234 - val_loss: 0.2977 - val_accuracy: 0.0071\n","Epoch 75/120\n","5/5 [==============================] - 0s 35ms/step - loss: 0.0180 - accuracy: 0.0108 - val_loss: 0.2848 - val_accuracy: 0.0000e+00\n","Epoch 76/120\n","5/5 [==============================] - 0s 31ms/step - loss: 0.0159 - accuracy: 0.0126 - val_loss: 0.2649 - val_accuracy: 0.0000e+00\n","Epoch 77/120\n","5/5 [==============================] - 0s 35ms/step - loss: 0.0162 - accuracy: 0.0126 - val_loss: 0.2627 - val_accuracy: 0.0357\n","Epoch 78/120\n","5/5 [==============================] - 0s 34ms/step - loss: 0.0165 - accuracy: 0.0216 - val_loss: 0.2830 - val_accuracy: 0.0643\n","Epoch 79/120\n","5/5 [==============================] - 0s 30ms/step - loss: 0.0164 - accuracy: 0.0306 - val_loss: 0.2956 - val_accuracy: 0.0857\n","Epoch 80/120\n","5/5 [==============================] - 0s 33ms/step - loss: 0.0144 - accuracy: 0.0288 - val_loss: 0.2871 - val_accuracy: 0.0714\n","Epoch 81/120\n","5/5 [==============================] - 0s 34ms/step - loss: 0.0153 - accuracy: 0.0450 - val_loss: 0.2708 - val_accuracy: 0.0286\n","Epoch 82/120\n","5/5 [==============================] - 0s 32ms/step - loss: 0.0165 - accuracy: 0.0216 - val_loss: 0.2853 - val_accuracy: 0.0000e+00\n","Epoch 83/120\n","5/5 [==============================] - 0s 33ms/step - loss: 0.0147 - accuracy: 0.0090 - val_loss: 0.2976 - val_accuracy: 0.0000e+00\n","Epoch 84/120\n","5/5 [==============================] - 0s 33ms/step - loss: 0.0162 - accuracy: 0.0162 - val_loss: 0.3027 - val_accuracy: 0.0071\n","Epoch 85/120\n","5/5 [==============================] - 0s 32ms/step - loss: 0.0119 - accuracy: 0.0216 - val_loss: 0.3071 - val_accuracy: 0.0286\n","Epoch 86/120\n","5/5 [==============================] - 0s 31ms/step - loss: 0.0156 - accuracy: 0.0270 - val_loss: 0.3023 - val_accuracy: 0.0857\n","Epoch 87/120\n","5/5 [==============================] - 0s 32ms/step - loss: 0.0142 - accuracy: 0.0270 - val_loss: 0.2955 - val_accuracy: 0.0214\n","Epoch 88/120\n","5/5 [==============================] - 0s 31ms/step - loss: 0.0136 - accuracy: 0.0198 - val_loss: 0.3069 - val_accuracy: 0.0143\n","Epoch 89/120\n","5/5 [==============================] - 0s 32ms/step - loss: 0.0154 - accuracy: 0.0180 - val_loss: 0.2799 - val_accuracy: 0.0214\n","Epoch 90/120\n","5/5 [==============================] - 0s 33ms/step - loss: 0.0122 - accuracy: 0.0234 - val_loss: 0.2685 - val_accuracy: 0.0071\n","Epoch 91/120\n","5/5 [==============================] - 0s 34ms/step - loss: 0.0123 - accuracy: 0.0108 - val_loss: 0.2671 - val_accuracy: 0.0000e+00\n","Epoch 92/120\n","5/5 [==============================] - 0s 34ms/step - loss: 0.0125 - accuracy: 0.0108 - val_loss: 0.2983 - val_accuracy: 0.0143\n","Epoch 93/120\n","5/5 [==============================] - 0s 32ms/step - loss: 0.0130 - accuracy: 0.0180 - val_loss: 0.3080 - val_accuracy: 0.0357\n","Epoch 94/120\n","5/5 [==============================] - 0s 31ms/step - loss: 0.0138 - accuracy: 0.0180 - val_loss: 0.3092 - val_accuracy: 0.0214\n","Epoch 95/120\n","5/5 [==============================] - 0s 33ms/step - loss: 0.0120 - accuracy: 0.0234 - val_loss: 0.3224 - val_accuracy: 0.0000e+00\n","Epoch 96/120\n","5/5 [==============================] - 0s 34ms/step - loss: 0.0128 - accuracy: 0.0180 - val_loss: 0.3108 - val_accuracy: 0.0000e+00\n","Epoch 97/120\n","5/5 [==============================] - 0s 35ms/step - loss: 0.0106 - accuracy: 0.0162 - val_loss: 0.3121 - val_accuracy: 0.0143\n","Epoch 98/120\n","5/5 [==============================] - 0s 33ms/step - loss: 0.0124 - accuracy: 0.0144 - val_loss: 0.3106 - val_accuracy: 0.0286\n","Epoch 99/120\n","5/5 [==============================] - 0s 33ms/step - loss: 0.0116 - accuracy: 0.0162 - val_loss: 0.2987 - val_accuracy: 0.0357\n","Epoch 100/120\n","5/5 [==============================] - 0s 34ms/step - loss: 0.0119 - accuracy: 0.0252 - val_loss: 0.2948 - val_accuracy: 0.0571\n","Epoch 101/120\n","5/5 [==============================] - 0s 31ms/step - loss: 0.0123 - accuracy: 0.0342 - val_loss: 0.3024 - val_accuracy: 0.0357\n","Epoch 102/120\n","5/5 [==============================] - 0s 32ms/step - loss: 0.0134 - accuracy: 0.0216 - val_loss: 0.3060 - val_accuracy: 0.0286\n","Epoch 103/120\n","5/5 [==============================] - 0s 31ms/step - loss: 0.0116 - accuracy: 0.0252 - val_loss: 0.3082 - val_accuracy: 0.0000e+00\n","Epoch 104/120\n","5/5 [==============================] - 0s 35ms/step - loss: 0.0114 - accuracy: 0.0144 - val_loss: 0.3238 - val_accuracy: 0.0214\n","Epoch 105/120\n","5/5 [==============================] - 0s 31ms/step - loss: 0.0116 - accuracy: 0.0090 - val_loss: 0.3373 - val_accuracy: 0.0357\n","Epoch 106/120\n","5/5 [==============================] - 0s 31ms/step - loss: 0.0123 - accuracy: 0.0342 - val_loss: 0.3232 - val_accuracy: 0.0500\n","Epoch 107/120\n","5/5 [==============================] - 0s 30ms/step - loss: 0.0129 - accuracy: 0.0288 - val_loss: 0.3179 - val_accuracy: 0.0571\n","Epoch 108/120\n","5/5 [==============================] - 0s 31ms/step - loss: 0.0116 - accuracy: 0.0198 - val_loss: 0.3306 - val_accuracy: 0.0429\n","Epoch 109/120\n","5/5 [==============================] - 0s 32ms/step - loss: 0.0096 - accuracy: 0.0108 - val_loss: 0.3443 - val_accuracy: 0.0214\n","Epoch 110/120\n","5/5 [==============================] - 0s 32ms/step - loss: 0.0104 - accuracy: 0.0288 - val_loss: 0.3515 - val_accuracy: 0.0714\n","Epoch 111/120\n","5/5 [==============================] - 0s 32ms/step - loss: 0.0130 - accuracy: 0.0378 - val_loss: 0.3220 - val_accuracy: 0.0286\n","Epoch 112/120\n","5/5 [==============================] - 0s 31ms/step - loss: 0.0131 - accuracy: 0.0180 - val_loss: 0.2837 - val_accuracy: 0.0143\n","Epoch 113/120\n","5/5 [==============================] - 0s 36ms/step - loss: 0.0115 - accuracy: 0.0180 - val_loss: 0.2836 - val_accuracy: 0.0643\n","Epoch 114/120\n","5/5 [==============================] - 0s 34ms/step - loss: 0.0103 - accuracy: 0.0324 - val_loss: 0.3153 - val_accuracy: 0.0500\n","Epoch 115/120\n","5/5 [==============================] - 0s 31ms/step - loss: 0.0083 - accuracy: 0.0414 - val_loss: 0.3177 - val_accuracy: 0.0571\n","Epoch 116/120\n","5/5 [==============================] - 0s 31ms/step - loss: 0.0121 - accuracy: 0.0198 - val_loss: 0.3057 - val_accuracy: 0.0429\n","Epoch 117/120\n","5/5 [==============================] - 0s 32ms/step - loss: 0.0115 - accuracy: 0.0288 - val_loss: 0.3064 - val_accuracy: 0.0571\n","Epoch 118/120\n","5/5 [==============================] - 0s 33ms/step - loss: 0.0116 - accuracy: 0.0360 - val_loss: 0.2856 - val_accuracy: 0.0571\n","Epoch 119/120\n","5/5 [==============================] - 0s 34ms/step - loss: 0.0107 - accuracy: 0.0468 - val_loss: 0.3033 - val_accuracy: 0.1214\n","Epoch 120/120\n","5/5 [==============================] - 0s 30ms/step - loss: 0.0090 - accuracy: 0.0342 - val_loss: 0.3180 - val_accuracy: 0.0929\n","--------------------------------------------------------------------------------\n","--------------------------------------------------------------------------------\n","2 ------ Cat 274\n","X_train shape: \n","(438, 216, 13)\n","Model: \"sequential_2\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","conv2d_4 (Conv2D)            (None, 214, 11, 128)      1280      \n","_________________________________________________________________\n","max_pooling2d_4 (MaxPooling2 (None, 107, 6, 128)       0         \n","_________________________________________________________________\n","batch_normalization_4 (Batch (None, 107, 6, 128)       512       \n","_________________________________________________________________\n","conv2d_5 (Conv2D)            (None, 105, 4, 128)       147584    \n","_________________________________________________________________\n","max_pooling2d_5 (MaxPooling2 (None, 53, 2, 128)        0         \n","_________________________________________________________________\n","batch_normalization_5 (Batch (None, 53, 2, 128)        512       \n","_________________________________________________________________\n","flatten_2 (Flatten)          (None, 13568)             0         \n","_________________________________________________________________\n","dense_4 (Dense)              (None, 256)               3473664   \n","_________________________________________________________________\n","dropout_2 (Dropout)          (None, 256)               0         \n","_________________________________________________________________\n","dense_5 (Dense)              (None, 216)               55512     \n","=================================================================\n","Total params: 3,679,064\n","Trainable params: 3,678,552\n","Non-trainable params: 512\n","_________________________________________________________________\n","Epoch 1/120\n","3/3 [==============================] - 2s 906ms/step - loss: 0.8331 - accuracy: 0.0029 - val_loss: 0.9151 - val_accuracy: 0.0000e+00\n","Epoch 2/120\n","3/3 [==============================] - 0s 34ms/step - loss: 0.6577 - accuracy: 0.0000e+00 - val_loss: 0.9260 - val_accuracy: 0.0114\n","Epoch 3/120\n","3/3 [==============================] - 0s 35ms/step - loss: 0.6246 - accuracy: 0.0029 - val_loss: 0.9412 - val_accuracy: 0.0114\n","Epoch 4/120\n","3/3 [==============================] - 0s 41ms/step - loss: 0.5775 - accuracy: 0.0057 - val_loss: 1.0754 - val_accuracy: 0.0000e+00\n","Epoch 5/120\n","3/3 [==============================] - 0s 36ms/step - loss: 0.5366 - accuracy: 0.0057 - val_loss: 1.1205 - val_accuracy: 0.0000e+00\n","Epoch 6/120\n","3/3 [==============================] - 0s 35ms/step - loss: 0.4969 - accuracy: 0.0086 - val_loss: 1.1420 - val_accuracy: 0.0000e+00\n","Epoch 7/120\n","3/3 [==============================] - 0s 49ms/step - loss: 0.4659 - accuracy: 0.0086 - val_loss: 1.0504 - val_accuracy: 0.0000e+00\n","Epoch 8/120\n","3/3 [==============================] - 0s 41ms/step - loss: 0.4367 - accuracy: 0.0114 - val_loss: 0.9344 - val_accuracy: 0.0000e+00\n","Epoch 9/120\n","3/3 [==============================] - 0s 36ms/step - loss: 0.4122 - accuracy: 0.0086 - val_loss: 0.7732 - val_accuracy: 0.0000e+00\n","Epoch 10/120\n","3/3 [==============================] - 0s 36ms/step - loss: 0.3860 - accuracy: 0.0029 - val_loss: 0.6805 - val_accuracy: 0.0000e+00\n","Epoch 11/120\n","3/3 [==============================] - 0s 43ms/step - loss: 0.3672 - accuracy: 0.0057 - val_loss: 0.6933 - val_accuracy: 0.0000e+00\n","Epoch 12/120\n","3/3 [==============================] - 0s 36ms/step - loss: 0.3446 - accuracy: 0.0086 - val_loss: 0.6785 - val_accuracy: 0.0000e+00\n","Epoch 13/120\n","3/3 [==============================] - 0s 41ms/step - loss: 0.3270 - accuracy: 0.0057 - val_loss: 0.6303 - val_accuracy: 0.0000e+00\n","Epoch 14/120\n","3/3 [==============================] - 0s 40ms/step - loss: 0.3014 - accuracy: 0.0057 - val_loss: 0.6320 - val_accuracy: 0.0000e+00\n","Epoch 15/120\n","3/3 [==============================] - 0s 36ms/step - loss: 0.2802 - accuracy: 0.0057 - val_loss: 0.5930 - val_accuracy: 0.0000e+00\n","Epoch 16/120\n","3/3 [==============================] - 0s 45ms/step - loss: 0.2634 - accuracy: 0.0057 - val_loss: 0.5971 - val_accuracy: 0.0000e+00\n","Epoch 17/120\n","3/3 [==============================] - 0s 41ms/step - loss: 0.2505 - accuracy: 0.0143 - val_loss: 0.5761 - val_accuracy: 0.0000e+00\n","Epoch 18/120\n","3/3 [==============================] - 0s 42ms/step - loss: 0.2268 - accuracy: 0.0029 - val_loss: 0.5545 - val_accuracy: 0.0000e+00\n","Epoch 19/120\n","3/3 [==============================] - 0s 47ms/step - loss: 0.2130 - accuracy: 0.0029 - val_loss: 0.5414 - val_accuracy: 0.0000e+00\n","Epoch 20/120\n","3/3 [==============================] - 0s 36ms/step - loss: 0.2001 - accuracy: 0.0086 - val_loss: 0.5448 - val_accuracy: 0.0114\n","Epoch 21/120\n","3/3 [==============================] - 0s 36ms/step - loss: 0.1854 - accuracy: 0.0143 - val_loss: 0.5081 - val_accuracy: 0.0000e+00\n","Epoch 22/120\n","3/3 [==============================] - 0s 43ms/step - loss: 0.1767 - accuracy: 0.0000e+00 - val_loss: 0.5203 - val_accuracy: 0.0000e+00\n","Epoch 23/120\n","3/3 [==============================] - 0s 42ms/step - loss: 0.1660 - accuracy: 0.0029 - val_loss: 0.4653 - val_accuracy: 0.0000e+00\n","Epoch 24/120\n","3/3 [==============================] - 0s 45ms/step - loss: 0.1555 - accuracy: 0.0057 - val_loss: 0.4712 - val_accuracy: 0.0000e+00\n","Epoch 25/120\n","3/3 [==============================] - 0s 37ms/step - loss: 0.1513 - accuracy: 0.0057 - val_loss: 0.4524 - val_accuracy: 0.0000e+00\n","Epoch 26/120\n","3/3 [==============================] - 0s 43ms/step - loss: 0.1448 - accuracy: 0.0086 - val_loss: 0.4268 - val_accuracy: 0.0000e+00\n","Epoch 27/120\n","3/3 [==============================] - 0s 36ms/step - loss: 0.1337 - accuracy: 0.0029 - val_loss: 0.4416 - val_accuracy: 0.0000e+00\n","Epoch 28/120\n","3/3 [==============================] - 0s 35ms/step - loss: 0.1284 - accuracy: 0.0143 - val_loss: 0.4054 - val_accuracy: 0.0000e+00\n","Epoch 29/120\n","3/3 [==============================] - 0s 42ms/step - loss: 0.1264 - accuracy: 0.0114 - val_loss: 0.3977 - val_accuracy: 0.0000e+00\n","Epoch 30/120\n","3/3 [==============================] - 0s 36ms/step - loss: 0.1140 - accuracy: 0.0114 - val_loss: 0.3984 - val_accuracy: 0.0114\n","Epoch 31/120\n","3/3 [==============================] - 0s 35ms/step - loss: 0.1134 - accuracy: 0.0057 - val_loss: 0.3908 - val_accuracy: 0.0114\n","Epoch 32/120\n","3/3 [==============================] - 0s 41ms/step - loss: 0.1117 - accuracy: 0.0086 - val_loss: 0.3736 - val_accuracy: 0.0114\n","Epoch 33/120\n","3/3 [==============================] - 0s 47ms/step - loss: 0.1073 - accuracy: 0.0114 - val_loss: 0.3766 - val_accuracy: 0.0114\n","Epoch 34/120\n","3/3 [==============================] - 0s 35ms/step - loss: 0.1074 - accuracy: 0.0143 - val_loss: 0.3887 - val_accuracy: 0.0114\n","Epoch 35/120\n","3/3 [==============================] - 0s 42ms/step - loss: 0.1004 - accuracy: 0.0086 - val_loss: 0.3681 - val_accuracy: 0.0114\n","Epoch 36/120\n","3/3 [==============================] - 0s 36ms/step - loss: 0.0969 - accuracy: 0.0114 - val_loss: 0.3703 - val_accuracy: 0.0000e+00\n","Epoch 37/120\n","3/3 [==============================] - 0s 43ms/step - loss: 0.0910 - accuracy: 0.0029 - val_loss: 0.3702 - val_accuracy: 0.0000e+00\n","Epoch 38/120\n","3/3 [==============================] - 0s 36ms/step - loss: 0.0883 - accuracy: 0.0114 - val_loss: 0.3559 - val_accuracy: 0.0000e+00\n","Epoch 39/120\n","3/3 [==============================] - 0s 42ms/step - loss: 0.0845 - accuracy: 0.0057 - val_loss: 0.3682 - val_accuracy: 0.0000e+00\n","Epoch 40/120\n","3/3 [==============================] - 0s 42ms/step - loss: 0.0849 - accuracy: 0.0171 - val_loss: 0.3575 - val_accuracy: 0.0000e+00\n","Epoch 41/120\n","3/3 [==============================] - 0s 36ms/step - loss: 0.0834 - accuracy: 0.0114 - val_loss: 0.3604 - val_accuracy: 0.0000e+00\n","Epoch 42/120\n","3/3 [==============================] - 0s 37ms/step - loss: 0.0763 - accuracy: 0.0114 - val_loss: 0.3534 - val_accuracy: 0.0000e+00\n","Epoch 43/120\n","3/3 [==============================] - 0s 36ms/step - loss: 0.0758 - accuracy: 0.0143 - val_loss: 0.3594 - val_accuracy: 0.0000e+00\n","Epoch 44/120\n","3/3 [==============================] - 0s 41ms/step - loss: 0.0792 - accuracy: 0.0086 - val_loss: 0.3555 - val_accuracy: 0.0114\n","Epoch 45/120\n","3/3 [==============================] - 0s 43ms/step - loss: 0.0713 - accuracy: 0.0057 - val_loss: 0.3436 - val_accuracy: 0.0114\n","Epoch 46/120\n","3/3 [==============================] - 0s 36ms/step - loss: 0.0729 - accuracy: 0.0029 - val_loss: 0.3349 - val_accuracy: 0.0114\n","Epoch 47/120\n","3/3 [==============================] - 0s 41ms/step - loss: 0.0722 - accuracy: 0.0086 - val_loss: 0.3454 - val_accuracy: 0.0114\n","Epoch 48/120\n","3/3 [==============================] - 0s 42ms/step - loss: 0.0697 - accuracy: 0.0086 - val_loss: 0.3354 - val_accuracy: 0.0000e+00\n","Epoch 49/120\n","3/3 [==============================] - 0s 41ms/step - loss: 0.0650 - accuracy: 0.0029 - val_loss: 0.3424 - val_accuracy: 0.0000e+00\n","Epoch 50/120\n","3/3 [==============================] - 0s 37ms/step - loss: 0.0625 - accuracy: 0.0114 - val_loss: 0.3584 - val_accuracy: 0.0114\n","Epoch 51/120\n","3/3 [==============================] - 0s 36ms/step - loss: 0.0590 - accuracy: 0.0086 - val_loss: 0.3634 - val_accuracy: 0.0000e+00\n","Epoch 52/120\n","3/3 [==============================] - 0s 35ms/step - loss: 0.0571 - accuracy: 0.0029 - val_loss: 0.3634 - val_accuracy: 0.0000e+00\n","Epoch 53/120\n","3/3 [==============================] - 0s 35ms/step - loss: 0.0582 - accuracy: 0.0029 - val_loss: 0.3541 - val_accuracy: 0.0000e+00\n","Epoch 54/120\n","3/3 [==============================] - 0s 43ms/step - loss: 0.0550 - accuracy: 0.0029 - val_loss: 0.3510 - val_accuracy: 0.0000e+00\n","Epoch 55/120\n","3/3 [==============================] - 0s 39ms/step - loss: 0.0561 - accuracy: 0.0114 - val_loss: 0.3612 - val_accuracy: 0.0000e+00\n","Epoch 56/120\n","3/3 [==============================] - 0s 42ms/step - loss: 0.0505 - accuracy: 0.0029 - val_loss: 0.3744 - val_accuracy: 0.0000e+00\n","Epoch 57/120\n","3/3 [==============================] - 0s 36ms/step - loss: 0.0551 - accuracy: 0.0000e+00 - val_loss: 0.3710 - val_accuracy: 0.0114\n","Epoch 58/120\n","3/3 [==============================] - 0s 36ms/step - loss: 0.0512 - accuracy: 0.0143 - val_loss: 0.3773 - val_accuracy: 0.0000e+00\n","Epoch 59/120\n","3/3 [==============================] - 0s 42ms/step - loss: 0.0524 - accuracy: 0.0086 - val_loss: 0.3758 - val_accuracy: 0.0000e+00\n","Epoch 60/120\n","3/3 [==============================] - 0s 40ms/step - loss: 0.0503 - accuracy: 0.0114 - val_loss: 0.3583 - val_accuracy: 0.0000e+00\n","Epoch 61/120\n","3/3 [==============================] - 0s 35ms/step - loss: 0.0483 - accuracy: 0.0086 - val_loss: 0.3577 - val_accuracy: 0.0000e+00\n","Epoch 62/120\n","3/3 [==============================] - 0s 36ms/step - loss: 0.0496 - accuracy: 0.0057 - val_loss: 0.3781 - val_accuracy: 0.0000e+00\n","Epoch 63/120\n","3/3 [==============================] - 0s 42ms/step - loss: 0.0468 - accuracy: 0.0086 - val_loss: 0.3859 - val_accuracy: 0.0000e+00\n","Epoch 64/120\n","3/3 [==============================] - 0s 41ms/step - loss: 0.0441 - accuracy: 0.0086 - val_loss: 0.3938 - val_accuracy: 0.0000e+00\n","Epoch 65/120\n","3/3 [==============================] - 0s 35ms/step - loss: 0.0441 - accuracy: 0.0086 - val_loss: 0.3873 - val_accuracy: 0.0000e+00\n","Epoch 66/120\n","3/3 [==============================] - 0s 53ms/step - loss: 0.0433 - accuracy: 0.0086 - val_loss: 0.3754 - val_accuracy: 0.0000e+00\n","Epoch 67/120\n","3/3 [==============================] - 0s 40ms/step - loss: 0.0423 - accuracy: 0.0029 - val_loss: 0.3771 - val_accuracy: 0.0000e+00\n","Epoch 68/120\n","3/3 [==============================] - 0s 44ms/step - loss: 0.0385 - accuracy: 0.0114 - val_loss: 0.3733 - val_accuracy: 0.0000e+00\n","Epoch 69/120\n","3/3 [==============================] - 0s 42ms/step - loss: 0.0419 - accuracy: 0.0000e+00 - val_loss: 0.3643 - val_accuracy: 0.0000e+00\n","Epoch 70/120\n","3/3 [==============================] - 0s 36ms/step - loss: 0.0402 - accuracy: 0.0114 - val_loss: 0.3672 - val_accuracy: 0.0000e+00\n","Epoch 71/120\n","3/3 [==============================] - 0s 37ms/step - loss: 0.0377 - accuracy: 0.0086 - val_loss: 0.3843 - val_accuracy: 0.0000e+00\n","Epoch 72/120\n","3/3 [==============================] - 0s 36ms/step - loss: 0.0398 - accuracy: 0.0143 - val_loss: 0.3765 - val_accuracy: 0.0000e+00\n","Epoch 73/120\n","3/3 [==============================] - 0s 43ms/step - loss: 0.0374 - accuracy: 0.0057 - val_loss: 0.3676 - val_accuracy: 0.0000e+00\n","Epoch 74/120\n","3/3 [==============================] - 0s 36ms/step - loss: 0.0385 - accuracy: 0.0029 - val_loss: 0.3874 - val_accuracy: 0.0000e+00\n","Epoch 75/120\n","3/3 [==============================] - 0s 35ms/step - loss: 0.0337 - accuracy: 0.0057 - val_loss: 0.4091 - val_accuracy: 0.0000e+00\n","Epoch 76/120\n","3/3 [==============================] - 0s 44ms/step - loss: 0.0400 - accuracy: 0.0057 - val_loss: 0.4178 - val_accuracy: 0.0000e+00\n","Epoch 77/120\n","3/3 [==============================] - 0s 34ms/step - loss: 0.0348 - accuracy: 0.0029 - val_loss: 0.4233 - val_accuracy: 0.0000e+00\n","Epoch 78/120\n","3/3 [==============================] - 0s 43ms/step - loss: 0.0332 - accuracy: 0.0143 - val_loss: 0.4185 - val_accuracy: 0.0000e+00\n","Epoch 79/120\n","3/3 [==============================] - 0s 36ms/step - loss: 0.0323 - accuracy: 0.0057 - val_loss: 0.4011 - val_accuracy: 0.0000e+00\n","Epoch 80/120\n","3/3 [==============================] - 0s 41ms/step - loss: 0.0337 - accuracy: 0.0114 - val_loss: 0.3941 - val_accuracy: 0.0000e+00\n","Epoch 81/120\n","3/3 [==============================] - 0s 41ms/step - loss: 0.0294 - accuracy: 0.0114 - val_loss: 0.4123 - val_accuracy: 0.0000e+00\n","Epoch 82/120\n","3/3 [==============================] - 0s 40ms/step - loss: 0.0307 - accuracy: 0.0057 - val_loss: 0.4197 - val_accuracy: 0.0000e+00\n","Epoch 83/120\n","3/3 [==============================] - 0s 36ms/step - loss: 0.0349 - accuracy: 0.0057 - val_loss: 0.3995 - val_accuracy: 0.0000e+00\n","Epoch 84/120\n","3/3 [==============================] - 0s 36ms/step - loss: 0.0288 - accuracy: 0.0086 - val_loss: 0.3867 - val_accuracy: 0.0000e+00\n","Epoch 85/120\n","3/3 [==============================] - 0s 35ms/step - loss: 0.0315 - accuracy: 0.0086 - val_loss: 0.3847 - val_accuracy: 0.0000e+00\n","Epoch 86/120\n","3/3 [==============================] - 0s 40ms/step - loss: 0.0319 - accuracy: 0.0114 - val_loss: 0.3830 - val_accuracy: 0.0000e+00\n","Epoch 87/120\n","3/3 [==============================] - 0s 42ms/step - loss: 0.0286 - accuracy: 0.0114 - val_loss: 0.3731 - val_accuracy: 0.0000e+00\n","Epoch 88/120\n","3/3 [==============================] - 0s 34ms/step - loss: 0.0273 - accuracy: 0.0057 - val_loss: 0.3762 - val_accuracy: 0.0000e+00\n","Epoch 89/120\n","3/3 [==============================] - 0s 36ms/step - loss: 0.0275 - accuracy: 0.0000e+00 - val_loss: 0.3952 - val_accuracy: 0.0000e+00\n","Epoch 90/120\n","3/3 [==============================] - 0s 35ms/step - loss: 0.0289 - accuracy: 0.0029 - val_loss: 0.4377 - val_accuracy: 0.0000e+00\n","Epoch 91/120\n","3/3 [==============================] - 0s 45ms/step - loss: 0.0255 - accuracy: 0.0000e+00 - val_loss: 0.4621 - val_accuracy: 0.0000e+00\n","Epoch 92/120\n","3/3 [==============================] - 0s 36ms/step - loss: 0.0312 - accuracy: 0.0057 - val_loss: 0.4377 - val_accuracy: 0.0000e+00\n","Epoch 93/120\n","3/3 [==============================] - 0s 37ms/step - loss: 0.0279 - accuracy: 0.0057 - val_loss: 0.4367 - val_accuracy: 0.0000e+00\n","Epoch 94/120\n","3/3 [==============================] - 0s 35ms/step - loss: 0.0239 - accuracy: 0.0086 - val_loss: 0.4564 - val_accuracy: 0.0000e+00\n","Epoch 95/120\n","3/3 [==============================] - 0s 39ms/step - loss: 0.0277 - accuracy: 0.0086 - val_loss: 0.4586 - val_accuracy: 0.0000e+00\n","Epoch 96/120\n","3/3 [==============================] - 0s 35ms/step - loss: 0.0236 - accuracy: 0.0029 - val_loss: 0.4305 - val_accuracy: 0.0000e+00\n","Epoch 97/120\n","3/3 [==============================] - 0s 36ms/step - loss: 0.0257 - accuracy: 0.0086 - val_loss: 0.4109 - val_accuracy: 0.0000e+00\n","Epoch 98/120\n","3/3 [==============================] - 0s 41ms/step - loss: 0.0306 - accuracy: 0.0057 - val_loss: 0.4160 - val_accuracy: 0.0000e+00\n","Epoch 99/120\n","3/3 [==============================] - 0s 42ms/step - loss: 0.0285 - accuracy: 0.0029 - val_loss: 0.4312 - val_accuracy: 0.0000e+00\n","Epoch 100/120\n","3/3 [==============================] - 0s 35ms/step - loss: 0.0230 - accuracy: 0.0000e+00 - val_loss: 0.4187 - val_accuracy: 0.0000e+00\n","Epoch 101/120\n","3/3 [==============================] - 0s 36ms/step - loss: 0.0321 - accuracy: 0.0029 - val_loss: 0.4081 - val_accuracy: 0.0000e+00\n","Epoch 102/120\n","3/3 [==============================] - 0s 34ms/step - loss: 0.0233 - accuracy: 0.0029 - val_loss: 0.4271 - val_accuracy: 0.0000e+00\n","Epoch 103/120\n","3/3 [==============================] - 0s 35ms/step - loss: 0.0247 - accuracy: 0.0057 - val_loss: 0.4276 - val_accuracy: 0.0000e+00\n","Epoch 104/120\n","3/3 [==============================] - 0s 41ms/step - loss: 0.0203 - accuracy: 0.0057 - val_loss: 0.4461 - val_accuracy: 0.0000e+00\n","Epoch 105/120\n","3/3 [==============================] - 0s 44ms/step - loss: 0.0227 - accuracy: 0.0057 - val_loss: 0.4866 - val_accuracy: 0.0000e+00\n","Epoch 106/120\n","3/3 [==============================] - 0s 36ms/step - loss: 0.0217 - accuracy: 0.0086 - val_loss: 0.4848 - val_accuracy: 0.0000e+00\n","Epoch 107/120\n","3/3 [==============================] - 0s 42ms/step - loss: 0.0222 - accuracy: 0.0000e+00 - val_loss: 0.4460 - val_accuracy: 0.0114\n","Epoch 108/120\n","3/3 [==============================] - 0s 37ms/step - loss: 0.0248 - accuracy: 0.0143 - val_loss: 0.4291 - val_accuracy: 0.0114\n","Epoch 109/120\n","3/3 [==============================] - 0s 44ms/step - loss: 0.0260 - accuracy: 0.0029 - val_loss: 0.4245 - val_accuracy: 0.0114\n","Epoch 110/120\n","3/3 [==============================] - 0s 36ms/step - loss: 0.0208 - accuracy: 0.0114 - val_loss: 0.4234 - val_accuracy: 0.0114\n","Epoch 111/120\n","3/3 [==============================] - 0s 35ms/step - loss: 0.0200 - accuracy: 0.0029 - val_loss: 0.4266 - val_accuracy: 0.0114\n","Epoch 112/120\n","3/3 [==============================] - 0s 41ms/step - loss: 0.0179 - accuracy: 0.0114 - val_loss: 0.4328 - val_accuracy: 0.0000e+00\n","Epoch 113/120\n","3/3 [==============================] - 0s 44ms/step - loss: 0.0233 - accuracy: 0.0057 - val_loss: 0.4522 - val_accuracy: 0.0000e+00\n","Epoch 114/120\n","3/3 [==============================] - 0s 36ms/step - loss: 0.0181 - accuracy: 0.0029 - val_loss: 0.4905 - val_accuracy: 0.0000e+00\n","Epoch 115/120\n","3/3 [==============================] - 0s 36ms/step - loss: 0.0239 - accuracy: 0.0029 - val_loss: 0.4586 - val_accuracy: 0.0000e+00\n","Epoch 116/120\n","3/3 [==============================] - 0s 44ms/step - loss: 0.0202 - accuracy: 0.0057 - val_loss: 0.4401 - val_accuracy: 0.0000e+00\n","Epoch 117/120\n","3/3 [==============================] - 0s 35ms/step - loss: 0.0207 - accuracy: 0.0057 - val_loss: 0.4488 - val_accuracy: 0.0000e+00\n","Epoch 118/120\n","3/3 [==============================] - 0s 42ms/step - loss: 0.0164 - accuracy: 0.0029 - val_loss: 0.4775 - val_accuracy: 0.0000e+00\n","Epoch 119/120\n","3/3 [==============================] - 0s 39ms/step - loss: 0.0189 - accuracy: 0.0057 - val_loss: 0.5220 - val_accuracy: 0.0000e+00\n","Epoch 120/120\n","3/3 [==============================] - 0s 35ms/step - loss: 0.0217 - accuracy: 0.0029 - val_loss: 0.5392 - val_accuracy: 0.0000e+00\n","--------------------------------------------------------------------------------\n","--------------------------------------------------------------------------------\n","3 ------ Dishes 444\n","X_train shape: \n","(710, 216, 13)\n","Model: \"sequential_3\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","conv2d_6 (Conv2D)            (None, 214, 11, 128)      1280      \n","_________________________________________________________________\n","max_pooling2d_6 (MaxPooling2 (None, 107, 6, 128)       0         \n","_________________________________________________________________\n","batch_normalization_6 (Batch (None, 107, 6, 128)       512       \n","_________________________________________________________________\n","conv2d_7 (Conv2D)            (None, 105, 4, 128)       147584    \n","_________________________________________________________________\n","max_pooling2d_7 (MaxPooling2 (None, 53, 2, 128)        0         \n","_________________________________________________________________\n","batch_normalization_7 (Batch (None, 53, 2, 128)        512       \n","_________________________________________________________________\n","flatten_3 (Flatten)          (None, 13568)             0         \n","_________________________________________________________________\n","dense_6 (Dense)              (None, 256)               3473664   \n","_________________________________________________________________\n","dropout_3 (Dropout)          (None, 256)               0         \n","_________________________________________________________________\n","dense_7 (Dense)              (None, 216)               55512     \n","=================================================================\n","Total params: 3,679,064\n","Trainable params: 3,678,552\n","Non-trainable params: 512\n","_________________________________________________________________\n","Epoch 1/120\n","5/5 [==============================] - 2s 338ms/step - loss: 0.7190 - accuracy: 0.0035 - val_loss: 1.6397 - val_accuracy: 0.0000e+00\n","Epoch 2/120\n","5/5 [==============================] - 0s 35ms/step - loss: 0.5184 - accuracy: 0.0018 - val_loss: 2.9695 - val_accuracy: 0.0000e+00\n","Epoch 3/120\n","5/5 [==============================] - 0s 31ms/step - loss: 0.4174 - accuracy: 0.0018 - val_loss: 3.1674 - val_accuracy: 0.0000e+00\n","Epoch 4/120\n","5/5 [==============================] - 0s 32ms/step - loss: 0.3633 - accuracy: 0.0018 - val_loss: 3.2117 - val_accuracy: 0.0000e+00\n","Epoch 5/120\n","5/5 [==============================] - 0s 31ms/step - loss: 0.3268 - accuracy: 0.0088 - val_loss: 2.6957 - val_accuracy: 0.0000e+00\n","Epoch 6/120\n","5/5 [==============================] - 0s 33ms/step - loss: 0.3022 - accuracy: 0.0088 - val_loss: 2.0249 - val_accuracy: 0.0000e+00\n","Epoch 7/120\n","5/5 [==============================] - 0s 34ms/step - loss: 0.2867 - accuracy: 0.0035 - val_loss: 1.7298 - val_accuracy: 0.0000e+00\n","Epoch 8/120\n","5/5 [==============================] - 0s 34ms/step - loss: 0.2691 - accuracy: 0.0141 - val_loss: 1.3780 - val_accuracy: 0.0000e+00\n","Epoch 9/120\n","5/5 [==============================] - 0s 32ms/step - loss: 0.2547 - accuracy: 0.0176 - val_loss: 1.1633 - val_accuracy: 0.0141\n","Epoch 10/120\n","5/5 [==============================] - 0s 33ms/step - loss: 0.2433 - accuracy: 0.0123 - val_loss: 0.9162 - val_accuracy: 0.0000e+00\n","Epoch 11/120\n","5/5 [==============================] - 0s 36ms/step - loss: 0.2354 - accuracy: 0.0405 - val_loss: 0.7161 - val_accuracy: 0.0070\n","Epoch 12/120\n","5/5 [==============================] - 0s 33ms/step - loss: 0.2247 - accuracy: 0.0246 - val_loss: 0.6191 - val_accuracy: 0.0000e+00\n","Epoch 13/120\n","5/5 [==============================] - 0s 31ms/step - loss: 0.2108 - accuracy: 0.0158 - val_loss: 0.5081 - val_accuracy: 0.0000e+00\n","Epoch 14/120\n","5/5 [==============================] - 0s 31ms/step - loss: 0.2011 - accuracy: 0.0176 - val_loss: 0.4664 - val_accuracy: 0.0000e+00\n","Epoch 15/120\n","5/5 [==============================] - 0s 34ms/step - loss: 0.1913 - accuracy: 0.0282 - val_loss: 0.4367 - val_accuracy: 0.0000e+00\n","Epoch 16/120\n","5/5 [==============================] - 0s 31ms/step - loss: 0.1784 - accuracy: 0.0194 - val_loss: 0.3921 - val_accuracy: 0.0000e+00\n","Epoch 17/120\n","5/5 [==============================] - 0s 32ms/step - loss: 0.1688 - accuracy: 0.0264 - val_loss: 0.3823 - val_accuracy: 0.0000e+00\n","Epoch 18/120\n","5/5 [==============================] - 0s 32ms/step - loss: 0.1586 - accuracy: 0.0317 - val_loss: 0.3862 - val_accuracy: 0.0141\n","Epoch 19/120\n","5/5 [==============================] - 0s 32ms/step - loss: 0.1494 - accuracy: 0.0264 - val_loss: 0.3647 - val_accuracy: 0.0070\n","Epoch 20/120\n","5/5 [==============================] - 0s 31ms/step - loss: 0.1395 - accuracy: 0.0282 - val_loss: 0.3630 - val_accuracy: 0.0070\n","Epoch 21/120\n","5/5 [==============================] - 0s 31ms/step - loss: 0.1307 - accuracy: 0.0194 - val_loss: 0.3835 - val_accuracy: 0.0070\n","Epoch 22/120\n","5/5 [==============================] - 0s 31ms/step - loss: 0.1210 - accuracy: 0.0176 - val_loss: 0.3671 - val_accuracy: 0.0070\n","Epoch 23/120\n","5/5 [==============================] - 0s 31ms/step - loss: 0.1179 - accuracy: 0.0211 - val_loss: 0.3563 - val_accuracy: 0.0141\n","Epoch 24/120\n","5/5 [==============================] - 0s 37ms/step - loss: 0.1103 - accuracy: 0.0158 - val_loss: 0.3586 - val_accuracy: 0.0070\n","Epoch 25/120\n","5/5 [==============================] - 0s 32ms/step - loss: 0.1053 - accuracy: 0.0229 - val_loss: 0.3585 - val_accuracy: 0.0000e+00\n","Epoch 26/120\n","5/5 [==============================] - 0s 35ms/step - loss: 0.0967 - accuracy: 0.0158 - val_loss: 0.3732 - val_accuracy: 0.0000e+00\n","Epoch 27/120\n","5/5 [==============================] - 0s 34ms/step - loss: 0.0948 - accuracy: 0.0194 - val_loss: 0.3651 - val_accuracy: 0.0000e+00\n","Epoch 28/120\n","5/5 [==============================] - 0s 32ms/step - loss: 0.0923 - accuracy: 0.0194 - val_loss: 0.4193 - val_accuracy: 0.0000e+00\n","Epoch 29/120\n","5/5 [==============================] - 0s 32ms/step - loss: 0.0856 - accuracy: 0.0370 - val_loss: 0.3612 - val_accuracy: 0.0070\n","Epoch 30/120\n","5/5 [==============================] - 0s 35ms/step - loss: 0.0865 - accuracy: 0.0282 - val_loss: 0.4060 - val_accuracy: 0.0070\n","Epoch 31/120\n","5/5 [==============================] - 0s 32ms/step - loss: 0.0805 - accuracy: 0.0229 - val_loss: 0.3695 - val_accuracy: 0.0352\n","Epoch 32/120\n","5/5 [==============================] - 0s 32ms/step - loss: 0.0773 - accuracy: 0.0246 - val_loss: 0.3659 - val_accuracy: 0.0000e+00\n","Epoch 33/120\n","5/5 [==============================] - 0s 33ms/step - loss: 0.0752 - accuracy: 0.0246 - val_loss: 0.3832 - val_accuracy: 0.0000e+00\n","Epoch 34/120\n","5/5 [==============================] - 0s 33ms/step - loss: 0.0745 - accuracy: 0.0317 - val_loss: 0.3742 - val_accuracy: 0.0000e+00\n","Epoch 35/120\n","5/5 [==============================] - 0s 34ms/step - loss: 0.0673 - accuracy: 0.0158 - val_loss: 0.4068 - val_accuracy: 0.0070\n","Epoch 36/120\n","5/5 [==============================] - 0s 34ms/step - loss: 0.0681 - accuracy: 0.0282 - val_loss: 0.3815 - val_accuracy: 0.0070\n","Epoch 37/120\n","5/5 [==============================] - 0s 32ms/step - loss: 0.0669 - accuracy: 0.0229 - val_loss: 0.3817 - val_accuracy: 0.0282\n","Epoch 38/120\n","5/5 [==============================] - 0s 37ms/step - loss: 0.0640 - accuracy: 0.0211 - val_loss: 0.3784 - val_accuracy: 0.0282\n","Epoch 39/120\n","5/5 [==============================] - 0s 36ms/step - loss: 0.0607 - accuracy: 0.0176 - val_loss: 0.3946 - val_accuracy: 0.0070\n","Epoch 40/120\n","5/5 [==============================] - 0s 33ms/step - loss: 0.0593 - accuracy: 0.0158 - val_loss: 0.4039 - val_accuracy: 0.0070\n","Epoch 41/120\n","5/5 [==============================] - 0s 35ms/step - loss: 0.0571 - accuracy: 0.0387 - val_loss: 0.4213 - val_accuracy: 0.0211\n","Epoch 42/120\n","5/5 [==============================] - 0s 31ms/step - loss: 0.0564 - accuracy: 0.0335 - val_loss: 0.4056 - val_accuracy: 0.0282\n","Epoch 43/120\n","5/5 [==============================] - 0s 35ms/step - loss: 0.0539 - accuracy: 0.0299 - val_loss: 0.4420 - val_accuracy: 0.0070\n","Epoch 44/120\n","5/5 [==============================] - 0s 33ms/step - loss: 0.0523 - accuracy: 0.0229 - val_loss: 0.4053 - val_accuracy: 0.0141\n","Epoch 45/120\n","5/5 [==============================] - 0s 33ms/step - loss: 0.0506 - accuracy: 0.0335 - val_loss: 0.4328 - val_accuracy: 0.0070\n","Epoch 46/120\n","5/5 [==============================] - 0s 33ms/step - loss: 0.0462 - accuracy: 0.0211 - val_loss: 0.4420 - val_accuracy: 0.0000e+00\n","Epoch 47/120\n","5/5 [==============================] - 0s 32ms/step - loss: 0.0492 - accuracy: 0.0387 - val_loss: 0.4466 - val_accuracy: 0.0141\n","Epoch 48/120\n","5/5 [==============================] - 0s 38ms/step - loss: 0.0483 - accuracy: 0.0229 - val_loss: 0.4790 - val_accuracy: 0.0070\n","Epoch 49/120\n","5/5 [==============================] - 0s 41ms/step - loss: 0.0440 - accuracy: 0.0299 - val_loss: 0.4563 - val_accuracy: 0.0070\n","Epoch 50/120\n","5/5 [==============================] - 0s 34ms/step - loss: 0.0447 - accuracy: 0.0264 - val_loss: 0.4801 - val_accuracy: 0.0000e+00\n","Epoch 51/120\n","5/5 [==============================] - 0s 32ms/step - loss: 0.0457 - accuracy: 0.0299 - val_loss: 0.4478 - val_accuracy: 0.0070\n","Epoch 52/120\n","5/5 [==============================] - 0s 32ms/step - loss: 0.0414 - accuracy: 0.0194 - val_loss: 0.4483 - val_accuracy: 0.0070\n","Epoch 53/120\n","5/5 [==============================] - 0s 33ms/step - loss: 0.0416 - accuracy: 0.0158 - val_loss: 0.4612 - val_accuracy: 0.0000e+00\n","Epoch 54/120\n","5/5 [==============================] - 0s 33ms/step - loss: 0.0411 - accuracy: 0.0282 - val_loss: 0.4585 - val_accuracy: 0.0000e+00\n","Epoch 55/120\n","5/5 [==============================] - 0s 32ms/step - loss: 0.0391 - accuracy: 0.0194 - val_loss: 0.4886 - val_accuracy: 0.0070\n","Epoch 56/120\n","5/5 [==============================] - 0s 34ms/step - loss: 0.0380 - accuracy: 0.0246 - val_loss: 0.4448 - val_accuracy: 0.0000e+00\n","Epoch 57/120\n","5/5 [==============================] - 0s 38ms/step - loss: 0.0371 - accuracy: 0.0264 - val_loss: 0.4916 - val_accuracy: 0.0070\n","Epoch 58/120\n","5/5 [==============================] - 0s 33ms/step - loss: 0.0382 - accuracy: 0.0246 - val_loss: 0.4972 - val_accuracy: 0.0141\n","Epoch 59/120\n","5/5 [==============================] - 0s 34ms/step - loss: 0.0384 - accuracy: 0.0229 - val_loss: 0.4801 - val_accuracy: 0.0000e+00\n","Epoch 60/120\n","5/5 [==============================] - 0s 34ms/step - loss: 0.0359 - accuracy: 0.0282 - val_loss: 0.5277 - val_accuracy: 0.0141\n","Epoch 61/120\n","5/5 [==============================] - 0s 33ms/step - loss: 0.0375 - accuracy: 0.0176 - val_loss: 0.5155 - val_accuracy: 0.0000e+00\n","Epoch 62/120\n","5/5 [==============================] - 0s 33ms/step - loss: 0.0343 - accuracy: 0.0194 - val_loss: 0.5067 - val_accuracy: 0.0000e+00\n","Epoch 63/120\n","5/5 [==============================] - 0s 34ms/step - loss: 0.0336 - accuracy: 0.0176 - val_loss: 0.4612 - val_accuracy: 0.0000e+00\n","Epoch 64/120\n","5/5 [==============================] - 0s 35ms/step - loss: 0.0331 - accuracy: 0.0194 - val_loss: 0.4985 - val_accuracy: 0.0141\n","Epoch 65/120\n","5/5 [==============================] - 0s 33ms/step - loss: 0.0329 - accuracy: 0.0335 - val_loss: 0.5267 - val_accuracy: 0.0211\n","Epoch 66/120\n","5/5 [==============================] - 0s 32ms/step - loss: 0.0332 - accuracy: 0.0211 - val_loss: 0.5598 - val_accuracy: 0.0000e+00\n","Epoch 67/120\n","5/5 [==============================] - 0s 33ms/step - loss: 0.0288 - accuracy: 0.0229 - val_loss: 0.5888 - val_accuracy: 0.0070\n","Epoch 68/120\n","5/5 [==============================] - 0s 33ms/step - loss: 0.0292 - accuracy: 0.0194 - val_loss: 0.6229 - val_accuracy: 0.0000e+00\n","Epoch 69/120\n","5/5 [==============================] - 0s 34ms/step - loss: 0.0267 - accuracy: 0.0158 - val_loss: 0.6432 - val_accuracy: 0.0000e+00\n","Epoch 70/120\n","5/5 [==============================] - 0s 34ms/step - loss: 0.0289 - accuracy: 0.0176 - val_loss: 0.5714 - val_accuracy: 0.0070\n","Epoch 71/120\n","5/5 [==============================] - 0s 34ms/step - loss: 0.0258 - accuracy: 0.0176 - val_loss: 0.5596 - val_accuracy: 0.0141\n","Epoch 72/120\n","5/5 [==============================] - 0s 32ms/step - loss: 0.0252 - accuracy: 0.0335 - val_loss: 0.5581 - val_accuracy: 0.0141\n","Epoch 73/120\n","5/5 [==============================] - 0s 33ms/step - loss: 0.0261 - accuracy: 0.0158 - val_loss: 0.4977 - val_accuracy: 0.0282\n","Epoch 74/120\n","5/5 [==============================] - 0s 36ms/step - loss: 0.0300 - accuracy: 0.0194 - val_loss: 0.5024 - val_accuracy: 0.0282\n","Epoch 75/120\n","5/5 [==============================] - 0s 34ms/step - loss: 0.0261 - accuracy: 0.0194 - val_loss: 0.5983 - val_accuracy: 0.0211\n","Epoch 76/120\n","5/5 [==============================] - 0s 33ms/step - loss: 0.0273 - accuracy: 0.0229 - val_loss: 0.5244 - val_accuracy: 0.0070\n","Epoch 77/120\n","5/5 [==============================] - 0s 34ms/step - loss: 0.0265 - accuracy: 0.0246 - val_loss: 0.5244 - val_accuracy: 0.0211\n","Epoch 78/120\n","5/5 [==============================] - 0s 33ms/step - loss: 0.0264 - accuracy: 0.0194 - val_loss: 0.5690 - val_accuracy: 0.0070\n","Epoch 79/120\n","5/5 [==============================] - 0s 32ms/step - loss: 0.0265 - accuracy: 0.0176 - val_loss: 0.5627 - val_accuracy: 0.0000e+00\n","Epoch 80/120\n","5/5 [==============================] - 0s 34ms/step - loss: 0.0257 - accuracy: 0.0088 - val_loss: 0.6257 - val_accuracy: 0.0000e+00\n","Epoch 81/120\n","5/5 [==============================] - 0s 35ms/step - loss: 0.0254 - accuracy: 0.0229 - val_loss: 0.6068 - val_accuracy: 0.0000e+00\n","Epoch 82/120\n","5/5 [==============================] - 0s 33ms/step - loss: 0.0220 - accuracy: 0.0246 - val_loss: 0.5866 - val_accuracy: 0.0000e+00\n","Epoch 83/120\n","5/5 [==============================] - 0s 33ms/step - loss: 0.0229 - accuracy: 0.0158 - val_loss: 0.6024 - val_accuracy: 0.0000e+00\n","Epoch 84/120\n","5/5 [==============================] - 0s 32ms/step - loss: 0.0258 - accuracy: 0.0158 - val_loss: 0.6136 - val_accuracy: 0.0070\n","Epoch 85/120\n","5/5 [==============================] - 0s 34ms/step - loss: 0.0220 - accuracy: 0.0141 - val_loss: 0.6683 - val_accuracy: 0.0000e+00\n","Epoch 86/120\n","5/5 [==============================] - 0s 35ms/step - loss: 0.0223 - accuracy: 0.0335 - val_loss: 0.7396 - val_accuracy: 0.0141\n","Epoch 87/120\n","5/5 [==============================] - 0s 35ms/step - loss: 0.0245 - accuracy: 0.0264 - val_loss: 0.8023 - val_accuracy: 0.0352\n","Epoch 88/120\n","5/5 [==============================] - 0s 37ms/step - loss: 0.0207 - accuracy: 0.0211 - val_loss: 0.8318 - val_accuracy: 0.0352\n","Epoch 89/120\n","5/5 [==============================] - 0s 34ms/step - loss: 0.0185 - accuracy: 0.0211 - val_loss: 0.7408 - val_accuracy: 0.0352\n","Epoch 90/120\n","5/5 [==============================] - 0s 34ms/step - loss: 0.0230 - accuracy: 0.0264 - val_loss: 0.6733 - val_accuracy: 0.0070\n","Epoch 91/120\n","5/5 [==============================] - 0s 32ms/step - loss: 0.0202 - accuracy: 0.0246 - val_loss: 0.7305 - val_accuracy: 0.0000e+00\n","Epoch 92/120\n","5/5 [==============================] - 0s 33ms/step - loss: 0.0206 - accuracy: 0.0158 - val_loss: 0.7007 - val_accuracy: 0.0000e+00\n","Epoch 93/120\n","5/5 [==============================] - 0s 33ms/step - loss: 0.0181 - accuracy: 0.0088 - val_loss: 0.6518 - val_accuracy: 0.0000e+00\n","Epoch 94/120\n","5/5 [==============================] - 0s 34ms/step - loss: 0.0163 - accuracy: 0.0264 - val_loss: 0.6861 - val_accuracy: 0.0000e+00\n","Epoch 95/120\n","5/5 [==============================] - 0s 33ms/step - loss: 0.0216 - accuracy: 0.0194 - val_loss: 0.7353 - val_accuracy: 0.0000e+00\n","Epoch 96/120\n","5/5 [==============================] - 0s 34ms/step - loss: 0.0165 - accuracy: 0.0123 - val_loss: 0.6684 - val_accuracy: 0.0000e+00\n","Epoch 97/120\n","5/5 [==============================] - 0s 32ms/step - loss: 0.0195 - accuracy: 0.0352 - val_loss: 0.6240 - val_accuracy: 0.0000e+00\n","Epoch 98/120\n","5/5 [==============================] - 0s 33ms/step - loss: 0.0178 - accuracy: 0.0211 - val_loss: 0.6552 - val_accuracy: 0.0000e+00\n","Epoch 99/120\n","5/5 [==============================] - 0s 34ms/step - loss: 0.0163 - accuracy: 0.0211 - val_loss: 0.6976 - val_accuracy: 0.0000e+00\n","Epoch 100/120\n","5/5 [==============================] - 0s 40ms/step - loss: 0.0172 - accuracy: 0.0141 - val_loss: 0.7071 - val_accuracy: 0.0000e+00\n","Epoch 101/120\n","5/5 [==============================] - 0s 32ms/step - loss: 0.0148 - accuracy: 0.0158 - val_loss: 0.7123 - val_accuracy: 0.0000e+00\n","Epoch 102/120\n","5/5 [==============================] - 0s 32ms/step - loss: 0.0212 - accuracy: 0.0176 - val_loss: 0.6803 - val_accuracy: 0.0000e+00\n","Epoch 103/120\n","5/5 [==============================] - 0s 35ms/step - loss: 0.0180 - accuracy: 0.0246 - val_loss: 0.6680 - val_accuracy: 0.0000e+00\n","Epoch 104/120\n","5/5 [==============================] - 0s 37ms/step - loss: 0.0152 - accuracy: 0.0194 - val_loss: 0.7032 - val_accuracy: 0.0070\n","Epoch 105/120\n","5/5 [==============================] - 0s 32ms/step - loss: 0.0171 - accuracy: 0.0246 - val_loss: 0.6783 - val_accuracy: 0.0141\n","Epoch 106/120\n","5/5 [==============================] - 0s 33ms/step - loss: 0.0172 - accuracy: 0.0264 - val_loss: 0.6913 - val_accuracy: 0.0141\n","Epoch 107/120\n","5/5 [==============================] - 0s 33ms/step - loss: 0.0153 - accuracy: 0.0194 - val_loss: 0.7078 - val_accuracy: 0.0000e+00\n","Epoch 108/120\n","5/5 [==============================] - 0s 33ms/step - loss: 0.0172 - accuracy: 0.0282 - val_loss: 0.7353 - val_accuracy: 0.0000e+00\n","Epoch 109/120\n","5/5 [==============================] - 0s 33ms/step - loss: 0.0150 - accuracy: 0.0176 - val_loss: 0.7298 - val_accuracy: 0.0070\n","Epoch 110/120\n","5/5 [==============================] - 0s 34ms/step - loss: 0.0183 - accuracy: 0.0176 - val_loss: 0.7130 - val_accuracy: 0.0000e+00\n","Epoch 111/120\n","5/5 [==============================] - 0s 35ms/step - loss: 0.0183 - accuracy: 0.0176 - val_loss: 0.7580 - val_accuracy: 0.0000e+00\n","Epoch 112/120\n","5/5 [==============================] - 0s 36ms/step - loss: 0.0164 - accuracy: 0.0194 - val_loss: 0.8178 - val_accuracy: 0.0000e+00\n","Epoch 113/120\n","5/5 [==============================] - 0s 32ms/step - loss: 0.0163 - accuracy: 0.0246 - val_loss: 0.7956 - val_accuracy: 0.0000e+00\n","Epoch 114/120\n","5/5 [==============================] - 0s 33ms/step - loss: 0.0160 - accuracy: 0.0246 - val_loss: 0.7561 - val_accuracy: 0.0070\n","Epoch 115/120\n","5/5 [==============================] - 0s 36ms/step - loss: 0.0160 - accuracy: 0.0246 - val_loss: 0.7146 - val_accuracy: 0.0141\n","Epoch 116/120\n","5/5 [==============================] - 0s 33ms/step - loss: 0.0155 - accuracy: 0.0176 - val_loss: 0.8299 - val_accuracy: 0.0211\n","Epoch 117/120\n","5/5 [==============================] - 0s 33ms/step - loss: 0.0134 - accuracy: 0.0211 - val_loss: 0.8714 - val_accuracy: 0.0141\n","Epoch 118/120\n","5/5 [==============================] - 0s 37ms/step - loss: 0.0162 - accuracy: 0.0246 - val_loss: 0.8334 - val_accuracy: 0.0070\n","Epoch 119/120\n","5/5 [==============================] - 0s 33ms/step - loss: 0.0162 - accuracy: 0.0158 - val_loss: 0.7963 - val_accuracy: 0.0000e+00\n","Epoch 120/120\n","5/5 [==============================] - 0s 33ms/step - loss: 0.0183 - accuracy: 0.0194 - val_loss: 0.8150 - val_accuracy: 0.0000e+00\n","--------------------------------------------------------------------------------\n","--------------------------------------------------------------------------------\n","4 ------ Dog 319\n","X_train shape: \n","(510, 216, 13)\n","Model: \"sequential_4\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","conv2d_8 (Conv2D)            (None, 214, 11, 128)      1280      \n","_________________________________________________________________\n","max_pooling2d_8 (MaxPooling2 (None, 107, 6, 128)       0         \n","_________________________________________________________________\n","batch_normalization_8 (Batch (None, 107, 6, 128)       512       \n","_________________________________________________________________\n","conv2d_9 (Conv2D)            (None, 105, 4, 128)       147584    \n","_________________________________________________________________\n","max_pooling2d_9 (MaxPooling2 (None, 53, 2, 128)        0         \n","_________________________________________________________________\n","batch_normalization_9 (Batch (None, 53, 2, 128)        512       \n","_________________________________________________________________\n","flatten_4 (Flatten)          (None, 13568)             0         \n","_________________________________________________________________\n","dense_8 (Dense)              (None, 256)               3473664   \n","_________________________________________________________________\n","dropout_4 (Dropout)          (None, 256)               0         \n","_________________________________________________________________\n","dense_9 (Dense)              (None, 216)               55512     \n","=================================================================\n","Total params: 3,679,064\n","Trainable params: 3,678,552\n","Non-trainable params: 512\n","_________________________________________________________________\n","Epoch 1/120\n","4/4 [==============================] - 2s 452ms/step - loss: 0.7666 - accuracy: 0.0098 - val_loss: 0.9181 - val_accuracy: 0.0000e+00\n","Epoch 2/120\n","4/4 [==============================] - 0s 33ms/step - loss: 0.5689 - accuracy: 0.0074 - val_loss: 0.7871 - val_accuracy: 0.0000e+00\n","Epoch 3/120\n","4/4 [==============================] - 0s 37ms/step - loss: 0.4683 - accuracy: 0.0025 - val_loss: 0.9709 - val_accuracy: 0.0000e+00\n","Epoch 4/120\n","4/4 [==============================] - 0s 35ms/step - loss: 0.4038 - accuracy: 0.0000e+00 - val_loss: 0.8935 - val_accuracy: 0.0000e+00\n","Epoch 5/120\n","4/4 [==============================] - 0s 40ms/step - loss: 0.3635 - accuracy: 0.0074 - val_loss: 0.8457 - val_accuracy: 0.0000e+00\n","Epoch 6/120\n","4/4 [==============================] - 0s 34ms/step - loss: 0.3409 - accuracy: 0.0147 - val_loss: 0.7542 - val_accuracy: 0.0000e+00\n","Epoch 7/120\n","4/4 [==============================] - 0s 31ms/step - loss: 0.3207 - accuracy: 0.0049 - val_loss: 0.6917 - val_accuracy: 0.0000e+00\n","Epoch 8/120\n","4/4 [==============================] - 0s 38ms/step - loss: 0.3058 - accuracy: 0.0098 - val_loss: 0.5979 - val_accuracy: 0.0000e+00\n","Epoch 9/120\n","4/4 [==============================] - 0s 34ms/step - loss: 0.2896 - accuracy: 0.0074 - val_loss: 0.5679 - val_accuracy: 0.0000e+00\n","Epoch 10/120\n","4/4 [==============================] - 0s 31ms/step - loss: 0.2754 - accuracy: 0.0123 - val_loss: 0.5337 - val_accuracy: 0.0000e+00\n","Epoch 11/120\n","4/4 [==============================] - 0s 34ms/step - loss: 0.2653 - accuracy: 0.0098 - val_loss: 0.4859 - val_accuracy: 0.0000e+00\n","Epoch 12/120\n","4/4 [==============================] - 0s 32ms/step - loss: 0.2550 - accuracy: 0.0147 - val_loss: 0.3975 - val_accuracy: 0.0000e+00\n","Epoch 13/120\n","4/4 [==============================] - 0s 36ms/step - loss: 0.2403 - accuracy: 0.0074 - val_loss: 0.3932 - val_accuracy: 0.0000e+00\n","Epoch 14/120\n","4/4 [==============================] - 0s 34ms/step - loss: 0.2278 - accuracy: 0.0245 - val_loss: 0.3906 - val_accuracy: 0.0098\n","Epoch 15/120\n","4/4 [==============================] - 0s 34ms/step - loss: 0.2153 - accuracy: 0.0270 - val_loss: 0.3534 - val_accuracy: 0.0000e+00\n","Epoch 16/120\n","4/4 [==============================] - 0s 34ms/step - loss: 0.2083 - accuracy: 0.0172 - val_loss: 0.3515 - val_accuracy: 0.0000e+00\n","Epoch 17/120\n","4/4 [==============================] - 0s 36ms/step - loss: 0.1958 - accuracy: 0.0172 - val_loss: 0.3310 - val_accuracy: 0.0098\n","Epoch 18/120\n","4/4 [==============================] - 0s 33ms/step - loss: 0.1840 - accuracy: 0.0294 - val_loss: 0.3153 - val_accuracy: 0.0000e+00\n","Epoch 19/120\n","4/4 [==============================] - 0s 32ms/step - loss: 0.1745 - accuracy: 0.0098 - val_loss: 0.3332 - val_accuracy: 0.0098\n","Epoch 20/120\n","4/4 [==============================] - 0s 32ms/step - loss: 0.1710 - accuracy: 0.0319 - val_loss: 0.3244 - val_accuracy: 0.0196\n","Epoch 21/120\n","4/4 [==============================] - 0s 33ms/step - loss: 0.1612 - accuracy: 0.0245 - val_loss: 0.3235 - val_accuracy: 0.0098\n","Epoch 22/120\n","4/4 [==============================] - 0s 34ms/step - loss: 0.1584 - accuracy: 0.0294 - val_loss: 0.3055 - val_accuracy: 0.0196\n","Epoch 23/120\n","4/4 [==============================] - 0s 31ms/step - loss: 0.1494 - accuracy: 0.0270 - val_loss: 0.3038 - val_accuracy: 0.0098\n","Epoch 24/120\n","4/4 [==============================] - 0s 35ms/step - loss: 0.1475 - accuracy: 0.0172 - val_loss: 0.3083 - val_accuracy: 0.0196\n","Epoch 25/120\n","4/4 [==============================] - 0s 33ms/step - loss: 0.1504 - accuracy: 0.0294 - val_loss: 0.3318 - val_accuracy: 0.0098\n","Epoch 26/120\n","4/4 [==============================] - 0s 35ms/step - loss: 0.1475 - accuracy: 0.0098 - val_loss: 0.2910 - val_accuracy: 0.0098\n","Epoch 27/120\n","4/4 [==============================] - 0s 33ms/step - loss: 0.1337 - accuracy: 0.0147 - val_loss: 0.2983 - val_accuracy: 0.0000e+00\n","Epoch 28/120\n","4/4 [==============================] - 0s 31ms/step - loss: 0.1334 - accuracy: 0.0196 - val_loss: 0.2891 - val_accuracy: 0.0000e+00\n","Epoch 29/120\n","4/4 [==============================] - 0s 33ms/step - loss: 0.1305 - accuracy: 0.0147 - val_loss: 0.2860 - val_accuracy: 0.0098\n","Epoch 30/120\n","4/4 [==============================] - 0s 32ms/step - loss: 0.1258 - accuracy: 0.0245 - val_loss: 0.2903 - val_accuracy: 0.0098\n","Epoch 31/120\n","4/4 [==============================] - 0s 32ms/step - loss: 0.1217 - accuracy: 0.0417 - val_loss: 0.2899 - val_accuracy: 0.0000e+00\n","Epoch 32/120\n","4/4 [==============================] - 0s 35ms/step - loss: 0.1181 - accuracy: 0.0319 - val_loss: 0.2855 - val_accuracy: 0.0000e+00\n","Epoch 33/120\n","4/4 [==============================] - 0s 33ms/step - loss: 0.1149 - accuracy: 0.0245 - val_loss: 0.2895 - val_accuracy: 0.0098\n","Epoch 34/120\n","4/4 [==============================] - 0s 31ms/step - loss: 0.1099 - accuracy: 0.0245 - val_loss: 0.2891 - val_accuracy: 0.0000e+00\n","Epoch 35/120\n","4/4 [==============================] - 0s 36ms/step - loss: 0.1058 - accuracy: 0.0270 - val_loss: 0.2818 - val_accuracy: 0.0196\n","Epoch 36/120\n","4/4 [==============================] - 0s 33ms/step - loss: 0.1077 - accuracy: 0.0368 - val_loss: 0.2887 - val_accuracy: 0.0196\n","Epoch 37/120\n","4/4 [==============================] - 0s 33ms/step - loss: 0.1047 - accuracy: 0.0245 - val_loss: 0.2932 - val_accuracy: 0.0000e+00\n","Epoch 38/120\n","4/4 [==============================] - 0s 33ms/step - loss: 0.1025 - accuracy: 0.0221 - val_loss: 0.3005 - val_accuracy: 0.0098\n","Epoch 39/120\n","4/4 [==============================] - 0s 31ms/step - loss: 0.0962 - accuracy: 0.0172 - val_loss: 0.2926 - val_accuracy: 0.0098\n","Epoch 40/120\n","4/4 [==============================] - 0s 34ms/step - loss: 0.0982 - accuracy: 0.0172 - val_loss: 0.2916 - val_accuracy: 0.0000e+00\n","Epoch 41/120\n","4/4 [==============================] - 0s 32ms/step - loss: 0.0935 - accuracy: 0.0074 - val_loss: 0.2752 - val_accuracy: 0.0098\n","Epoch 42/120\n","4/4 [==============================] - 0s 32ms/step - loss: 0.0944 - accuracy: 0.0196 - val_loss: 0.2795 - val_accuracy: 0.0098\n","Epoch 43/120\n","4/4 [==============================] - 0s 32ms/step - loss: 0.0903 - accuracy: 0.0245 - val_loss: 0.2784 - val_accuracy: 0.0000e+00\n","Epoch 44/120\n","4/4 [==============================] - 0s 32ms/step - loss: 0.0876 - accuracy: 0.0147 - val_loss: 0.2834 - val_accuracy: 0.0000e+00\n","Epoch 45/120\n","4/4 [==============================] - 0s 32ms/step - loss: 0.0838 - accuracy: 0.0098 - val_loss: 0.2869 - val_accuracy: 0.0098\n","Epoch 46/120\n","4/4 [==============================] - 0s 31ms/step - loss: 0.0818 - accuracy: 0.0343 - val_loss: 0.2984 - val_accuracy: 0.0098\n","Epoch 47/120\n","4/4 [==============================] - 0s 32ms/step - loss: 0.0791 - accuracy: 0.0245 - val_loss: 0.3006 - val_accuracy: 0.0098\n","Epoch 48/120\n","4/4 [==============================] - 0s 31ms/step - loss: 0.0823 - accuracy: 0.0196 - val_loss: 0.2882 - val_accuracy: 0.0000e+00\n","Epoch 49/120\n","4/4 [==============================] - 0s 32ms/step - loss: 0.0799 - accuracy: 0.0098 - val_loss: 0.2899 - val_accuracy: 0.0098\n","Epoch 50/120\n","4/4 [==============================] - 0s 33ms/step - loss: 0.0795 - accuracy: 0.0172 - val_loss: 0.2968 - val_accuracy: 0.0000e+00\n","Epoch 51/120\n","4/4 [==============================] - 0s 33ms/step - loss: 0.0817 - accuracy: 0.0245 - val_loss: 0.2841 - val_accuracy: 0.0000e+00\n","Epoch 52/120\n","4/4 [==============================] - 0s 33ms/step - loss: 0.0763 - accuracy: 0.0221 - val_loss: 0.3048 - val_accuracy: 0.0196\n","Epoch 53/120\n","4/4 [==============================] - 0s 30ms/step - loss: 0.0753 - accuracy: 0.0270 - val_loss: 0.3523 - val_accuracy: 0.0294\n","Epoch 54/120\n","4/4 [==============================] - 0s 35ms/step - loss: 0.0726 - accuracy: 0.0343 - val_loss: 0.3341 - val_accuracy: 0.0196\n","Epoch 55/120\n","4/4 [==============================] - 0s 32ms/step - loss: 0.0725 - accuracy: 0.0172 - val_loss: 0.3281 - val_accuracy: 0.0196\n","Epoch 56/120\n","4/4 [==============================] - 0s 34ms/step - loss: 0.0650 - accuracy: 0.0221 - val_loss: 0.3181 - val_accuracy: 0.0098\n","Epoch 57/120\n","4/4 [==============================] - 0s 37ms/step - loss: 0.0653 - accuracy: 0.0147 - val_loss: 0.3209 - val_accuracy: 0.0196\n","Epoch 58/120\n","4/4 [==============================] - 0s 37ms/step - loss: 0.0675 - accuracy: 0.0172 - val_loss: 0.3307 - val_accuracy: 0.0196\n","Epoch 59/120\n","4/4 [==============================] - 0s 40ms/step - loss: 0.0651 - accuracy: 0.0270 - val_loss: 0.3544 - val_accuracy: 0.0098\n","Epoch 60/120\n","4/4 [==============================] - 0s 34ms/step - loss: 0.0649 - accuracy: 0.0319 - val_loss: 0.3236 - val_accuracy: 0.0196\n","Epoch 61/120\n","4/4 [==============================] - 0s 31ms/step - loss: 0.0652 - accuracy: 0.0294 - val_loss: 0.3138 - val_accuracy: 0.0294\n","Epoch 62/120\n","4/4 [==============================] - 0s 32ms/step - loss: 0.0625 - accuracy: 0.0172 - val_loss: 0.3166 - val_accuracy: 0.0196\n","Epoch 63/120\n","4/4 [==============================] - 0s 34ms/step - loss: 0.0637 - accuracy: 0.0343 - val_loss: 0.3810 - val_accuracy: 0.0392\n","Epoch 64/120\n","4/4 [==============================] - 0s 33ms/step - loss: 0.0586 - accuracy: 0.0196 - val_loss: 0.3353 - val_accuracy: 0.0196\n","Epoch 65/120\n","4/4 [==============================] - 0s 31ms/step - loss: 0.0587 - accuracy: 0.0196 - val_loss: 0.3539 - val_accuracy: 0.0294\n","Epoch 66/120\n","4/4 [==============================] - 0s 32ms/step - loss: 0.0539 - accuracy: 0.0221 - val_loss: 0.3736 - val_accuracy: 0.0392\n","Epoch 67/120\n","4/4 [==============================] - 0s 36ms/step - loss: 0.0558 - accuracy: 0.0196 - val_loss: 0.3808 - val_accuracy: 0.0294\n","Epoch 68/120\n","4/4 [==============================] - 0s 33ms/step - loss: 0.0597 - accuracy: 0.0221 - val_loss: 0.3245 - val_accuracy: 0.0196\n","Epoch 69/120\n","4/4 [==============================] - 0s 34ms/step - loss: 0.0505 - accuracy: 0.0196 - val_loss: 0.3377 - val_accuracy: 0.0098\n","Epoch 70/120\n","4/4 [==============================] - 0s 32ms/step - loss: 0.0542 - accuracy: 0.0172 - val_loss: 0.4259 - val_accuracy: 0.0294\n","Epoch 71/120\n","4/4 [==============================] - 0s 34ms/step - loss: 0.0544 - accuracy: 0.0245 - val_loss: 0.3945 - val_accuracy: 0.0294\n","Epoch 72/120\n","4/4 [==============================] - 0s 32ms/step - loss: 0.0551 - accuracy: 0.0147 - val_loss: 0.3653 - val_accuracy: 0.0294\n","Epoch 73/120\n","4/4 [==============================] - 0s 32ms/step - loss: 0.0489 - accuracy: 0.0172 - val_loss: 0.3366 - val_accuracy: 0.0294\n","Epoch 74/120\n","4/4 [==============================] - 0s 35ms/step - loss: 0.0497 - accuracy: 0.0270 - val_loss: 0.3296 - val_accuracy: 0.0294\n","Epoch 75/120\n","4/4 [==============================] - 0s 33ms/step - loss: 0.0471 - accuracy: 0.0196 - val_loss: 0.3545 - val_accuracy: 0.0000e+00\n","Epoch 76/120\n","4/4 [==============================] - 0s 31ms/step - loss: 0.0429 - accuracy: 0.0172 - val_loss: 0.4056 - val_accuracy: 0.0098\n","Epoch 77/120\n","4/4 [==============================] - 0s 33ms/step - loss: 0.0469 - accuracy: 0.0172 - val_loss: 0.3763 - val_accuracy: 0.0000e+00\n","Epoch 78/120\n","4/4 [==============================] - 0s 33ms/step - loss: 0.0512 - accuracy: 0.0172 - val_loss: 0.3759 - val_accuracy: 0.0196\n","Epoch 79/120\n","4/4 [==============================] - 0s 32ms/step - loss: 0.0506 - accuracy: 0.0098 - val_loss: 0.3828 - val_accuracy: 0.0098\n","Epoch 80/120\n","4/4 [==============================] - 0s 32ms/step - loss: 0.0435 - accuracy: 0.0221 - val_loss: 0.3794 - val_accuracy: 0.0098\n","Epoch 81/120\n","4/4 [==============================] - 0s 34ms/step - loss: 0.0470 - accuracy: 0.0245 - val_loss: 0.4283 - val_accuracy: 0.0098\n","Epoch 82/120\n","4/4 [==============================] - 0s 33ms/step - loss: 0.0528 - accuracy: 0.0123 - val_loss: 0.3991 - val_accuracy: 0.0098\n","Epoch 83/120\n","4/4 [==============================] - 0s 34ms/step - loss: 0.0537 - accuracy: 0.0147 - val_loss: 0.3405 - val_accuracy: 0.0098\n","Epoch 84/120\n","4/4 [==============================] - 0s 31ms/step - loss: 0.0491 - accuracy: 0.0147 - val_loss: 0.3721 - val_accuracy: 0.0098\n","Epoch 85/120\n","4/4 [==============================] - 0s 36ms/step - loss: 0.0475 - accuracy: 0.0196 - val_loss: 0.3928 - val_accuracy: 0.0196\n","Epoch 86/120\n","4/4 [==============================] - 0s 33ms/step - loss: 0.0449 - accuracy: 0.0123 - val_loss: 0.3817 - val_accuracy: 0.0098\n","Epoch 87/120\n","4/4 [==============================] - 0s 34ms/step - loss: 0.0410 - accuracy: 0.0270 - val_loss: 0.3386 - val_accuracy: 0.0098\n","Epoch 88/120\n","4/4 [==============================] - 0s 33ms/step - loss: 0.0457 - accuracy: 0.0147 - val_loss: 0.3238 - val_accuracy: 0.0000e+00\n","Epoch 89/120\n","4/4 [==============================] - 0s 32ms/step - loss: 0.0463 - accuracy: 0.0074 - val_loss: 0.3393 - val_accuracy: 0.0000e+00\n","Epoch 90/120\n","4/4 [==============================] - 0s 33ms/step - loss: 0.0373 - accuracy: 0.0123 - val_loss: 0.3914 - val_accuracy: 0.0000e+00\n","Epoch 91/120\n","4/4 [==============================] - 0s 35ms/step - loss: 0.0487 - accuracy: 0.0147 - val_loss: 0.3952 - val_accuracy: 0.0098\n","Epoch 92/120\n","4/4 [==============================] - 0s 35ms/step - loss: 0.0402 - accuracy: 0.0123 - val_loss: 0.3713 - val_accuracy: 0.0196\n","Epoch 93/120\n","4/4 [==============================] - 0s 33ms/step - loss: 0.0377 - accuracy: 0.0172 - val_loss: 0.3941 - val_accuracy: 0.0196\n","Epoch 94/120\n","4/4 [==============================] - 0s 32ms/step - loss: 0.0419 - accuracy: 0.0123 - val_loss: 0.4576 - val_accuracy: 0.0196\n","Epoch 95/120\n","4/4 [==============================] - 0s 31ms/step - loss: 0.0431 - accuracy: 0.0049 - val_loss: 0.4769 - val_accuracy: 0.0294\n","Epoch 96/120\n","4/4 [==============================] - 0s 34ms/step - loss: 0.0409 - accuracy: 0.0196 - val_loss: 0.4400 - val_accuracy: 0.0294\n","Epoch 97/120\n","4/4 [==============================] - 0s 33ms/step - loss: 0.0347 - accuracy: 0.0172 - val_loss: 0.4279 - val_accuracy: 0.0294\n","Epoch 98/120\n","4/4 [==============================] - 0s 34ms/step - loss: 0.0347 - accuracy: 0.0123 - val_loss: 0.4455 - val_accuracy: 0.0196\n","Epoch 99/120\n","4/4 [==============================] - 0s 35ms/step - loss: 0.0382 - accuracy: 0.0270 - val_loss: 0.5398 - val_accuracy: 0.0294\n","Epoch 100/120\n","4/4 [==============================] - 0s 39ms/step - loss: 0.0351 - accuracy: 0.0196 - val_loss: 0.5060 - val_accuracy: 0.0294\n","Epoch 101/120\n","4/4 [==============================] - 0s 33ms/step - loss: 0.0315 - accuracy: 0.0294 - val_loss: 0.4787 - val_accuracy: 0.0392\n","Epoch 102/120\n","4/4 [==============================] - 0s 34ms/step - loss: 0.0390 - accuracy: 0.0270 - val_loss: 0.4370 - val_accuracy: 0.0294\n","Epoch 103/120\n","4/4 [==============================] - 0s 31ms/step - loss: 0.0361 - accuracy: 0.0245 - val_loss: 0.4004 - val_accuracy: 0.0098\n","Epoch 104/120\n","4/4 [==============================] - 0s 33ms/step - loss: 0.0313 - accuracy: 0.0172 - val_loss: 0.3868 - val_accuracy: 0.0000e+00\n","Epoch 105/120\n","4/4 [==============================] - 0s 33ms/step - loss: 0.0317 - accuracy: 0.0270 - val_loss: 0.4904 - val_accuracy: 0.0098\n","Epoch 106/120\n","4/4 [==============================] - 0s 33ms/step - loss: 0.0354 - accuracy: 0.0221 - val_loss: 0.4526 - val_accuracy: 0.0098\n","Epoch 107/120\n","4/4 [==============================] - 0s 33ms/step - loss: 0.0342 - accuracy: 0.0196 - val_loss: 0.3905 - val_accuracy: 0.0098\n","Epoch 108/120\n","4/4 [==============================] - 0s 36ms/step - loss: 0.0396 - accuracy: 0.0074 - val_loss: 0.3668 - val_accuracy: 0.0196\n","Epoch 109/120\n","4/4 [==============================] - 0s 32ms/step - loss: 0.0348 - accuracy: 0.0074 - val_loss: 0.3582 - val_accuracy: 0.0196\n","Epoch 110/120\n","4/4 [==============================] - 0s 32ms/step - loss: 0.0305 - accuracy: 0.0172 - val_loss: 0.3608 - val_accuracy: 0.0196\n","Epoch 111/120\n","4/4 [==============================] - 0s 33ms/step - loss: 0.0319 - accuracy: 0.0074 - val_loss: 0.3626 - val_accuracy: 0.0196\n","Epoch 112/120\n","4/4 [==============================] - 0s 35ms/step - loss: 0.0287 - accuracy: 0.0123 - val_loss: 0.3601 - val_accuracy: 0.0294\n","Epoch 113/120\n","4/4 [==============================] - 0s 30ms/step - loss: 0.0261 - accuracy: 0.0172 - val_loss: 0.3555 - val_accuracy: 0.0196\n","Epoch 114/120\n","4/4 [==============================] - 0s 32ms/step - loss: 0.0317 - accuracy: 0.0123 - val_loss: 0.3549 - val_accuracy: 0.0196\n","Epoch 115/120\n","4/4 [==============================] - 0s 34ms/step - loss: 0.0356 - accuracy: 0.0172 - val_loss: 0.3708 - val_accuracy: 0.0196\n","Epoch 116/120\n","4/4 [==============================] - 0s 32ms/step - loss: 0.0252 - accuracy: 0.0196 - val_loss: 0.4056 - val_accuracy: 0.0196\n","Epoch 117/120\n","4/4 [==============================] - 0s 32ms/step - loss: 0.0337 - accuracy: 0.0172 - val_loss: 0.4493 - val_accuracy: 0.0196\n","Epoch 118/120\n","4/4 [==============================] - 0s 32ms/step - loss: 0.0291 - accuracy: 0.0074 - val_loss: 0.4587 - val_accuracy: 0.0000e+00\n","Epoch 119/120\n","4/4 [==============================] - 0s 32ms/step - loss: 0.0309 - accuracy: 0.0196 - val_loss: 0.4374 - val_accuracy: 0.0000e+00\n","Epoch 120/120\n","4/4 [==============================] - 0s 32ms/step - loss: 0.0287 - accuracy: 0.0221 - val_loss: 0.4051 - val_accuracy: 0.0098\n","--------------------------------------------------------------------------------\n","--------------------------------------------------------------------------------\n","5 ------ Electric_shaver_toothbrush 221\n","X_train shape: \n","(352, 216, 13)\n","Model: \"sequential_5\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","conv2d_10 (Conv2D)           (None, 214, 11, 128)      1280      \n","_________________________________________________________________\n","max_pooling2d_10 (MaxPooling (None, 107, 6, 128)       0         \n","_________________________________________________________________\n","batch_normalization_10 (Batc (None, 107, 6, 128)       512       \n","_________________________________________________________________\n","conv2d_11 (Conv2D)           (None, 105, 4, 128)       147584    \n","_________________________________________________________________\n","max_pooling2d_11 (MaxPooling (None, 53, 2, 128)        0         \n","_________________________________________________________________\n","batch_normalization_11 (Batc (None, 53, 2, 128)        512       \n","_________________________________________________________________\n","flatten_5 (Flatten)          (None, 13568)             0         \n","_________________________________________________________________\n","dense_10 (Dense)             (None, 256)               3473664   \n","_________________________________________________________________\n","dropout_5 (Dropout)          (None, 256)               0         \n","_________________________________________________________________\n","dense_11 (Dense)             (None, 216)               55512     \n","=================================================================\n","Total params: 3,679,064\n","Trainable params: 3,678,552\n","Non-trainable params: 512\n","_________________________________________________________________\n","Epoch 1/120\n","3/3 [==============================] - 2s 564ms/step - loss: 0.7836 - accuracy: 0.0000e+00 - val_loss: 2.9890 - val_accuracy: 0.0000e+00\n","Epoch 2/120\n","3/3 [==============================] - 0s 28ms/step - loss: 0.6100 - accuracy: 0.0036 - val_loss: 4.5456 - val_accuracy: 0.0000e+00\n","Epoch 3/120\n","3/3 [==============================] - 0s 32ms/step - loss: 0.5212 - accuracy: 0.0036 - val_loss: 5.6062 - val_accuracy: 0.0000e+00\n","Epoch 4/120\n","3/3 [==============================] - 0s 29ms/step - loss: 0.4315 - accuracy: 0.0036 - val_loss: 7.6495 - val_accuracy: 0.0000e+00\n","Epoch 5/120\n","3/3 [==============================] - 0s 31ms/step - loss: 0.3485 - accuracy: 0.0000e+00 - val_loss: 8.5477 - val_accuracy: 0.0000e+00\n","Epoch 6/120\n","3/3 [==============================] - 0s 31ms/step - loss: 0.2962 - accuracy: 0.0036 - val_loss: 9.0201 - val_accuracy: 0.0000e+00\n","Epoch 7/120\n","3/3 [==============================] - 0s 32ms/step - loss: 0.2480 - accuracy: 0.0036 - val_loss: 7.9303 - val_accuracy: 0.0000e+00\n","Epoch 8/120\n","3/3 [==============================] - 0s 31ms/step - loss: 0.2120 - accuracy: 0.0000e+00 - val_loss: 7.5268 - val_accuracy: 0.0000e+00\n","Epoch 9/120\n","3/3 [==============================] - 0s 32ms/step - loss: 0.1913 - accuracy: 0.0036 - val_loss: 6.2895 - val_accuracy: 0.0000e+00\n","Epoch 10/120\n","3/3 [==============================] - 0s 30ms/step - loss: 0.1664 - accuracy: 0.0036 - val_loss: 5.4238 - val_accuracy: 0.0000e+00\n","Epoch 11/120\n","3/3 [==============================] - 0s 32ms/step - loss: 0.1474 - accuracy: 0.0000e+00 - val_loss: 5.0279 - val_accuracy: 0.0000e+00\n","Epoch 12/120\n","3/3 [==============================] - 0s 34ms/step - loss: 0.1428 - accuracy: 0.0000e+00 - val_loss: 4.1856 - val_accuracy: 0.0000e+00\n","Epoch 13/120\n","3/3 [==============================] - 0s 33ms/step - loss: 0.1269 - accuracy: 0.0107 - val_loss: 3.3792 - val_accuracy: 0.0000e+00\n","Epoch 14/120\n","3/3 [==============================] - 0s 33ms/step - loss: 0.1179 - accuracy: 0.0107 - val_loss: 3.1602 - val_accuracy: 0.0000e+00\n","Epoch 15/120\n","3/3 [==============================] - 0s 33ms/step - loss: 0.1100 - accuracy: 0.0036 - val_loss: 2.2919 - val_accuracy: 0.0000e+00\n","Epoch 16/120\n","3/3 [==============================] - 0s 29ms/step - loss: 0.1012 - accuracy: 0.0000e+00 - val_loss: 2.1690 - val_accuracy: 0.0000e+00\n","Epoch 17/120\n","3/3 [==============================] - 0s 34ms/step - loss: 0.0967 - accuracy: 0.0036 - val_loss: 2.0936 - val_accuracy: 0.0000e+00\n","Epoch 18/120\n","3/3 [==============================] - 0s 33ms/step - loss: 0.0830 - accuracy: 0.0000e+00 - val_loss: 2.0311 - val_accuracy: 0.0000e+00\n","Epoch 19/120\n","3/3 [==============================] - 0s 33ms/step - loss: 0.0767 - accuracy: 0.0036 - val_loss: 2.1325 - val_accuracy: 0.0000e+00\n","Epoch 20/120\n","3/3 [==============================] - 0s 29ms/step - loss: 0.0786 - accuracy: 0.0071 - val_loss: 1.4831 - val_accuracy: 0.0000e+00\n","Epoch 21/120\n","3/3 [==============================] - 0s 32ms/step - loss: 0.0719 - accuracy: 0.0000e+00 - val_loss: 1.2493 - val_accuracy: 0.0000e+00\n","Epoch 22/120\n","3/3 [==============================] - 0s 32ms/step - loss: 0.0678 - accuracy: 0.0000e+00 - val_loss: 1.7302 - val_accuracy: 0.0000e+00\n","Epoch 23/120\n","3/3 [==============================] - 0s 31ms/step - loss: 0.0709 - accuracy: 0.0000e+00 - val_loss: 2.0326 - val_accuracy: 0.0000e+00\n","Epoch 24/120\n","3/3 [==============================] - 0s 31ms/step - loss: 0.0692 - accuracy: 0.0000e+00 - val_loss: 1.2762 - val_accuracy: 0.0000e+00\n","Epoch 25/120\n","3/3 [==============================] - 0s 30ms/step - loss: 0.0658 - accuracy: 0.0071 - val_loss: 1.0301 - val_accuracy: 0.0000e+00\n","Epoch 26/120\n","3/3 [==============================] - 0s 31ms/step - loss: 0.0560 - accuracy: 0.0036 - val_loss: 1.1498 - val_accuracy: 0.0000e+00\n","Epoch 27/120\n","3/3 [==============================] - 0s 34ms/step - loss: 0.0643 - accuracy: 0.0071 - val_loss: 0.9527 - val_accuracy: 0.0000e+00\n","Epoch 28/120\n","3/3 [==============================] - 0s 30ms/step - loss: 0.0527 - accuracy: 0.0071 - val_loss: 0.7246 - val_accuracy: 0.0000e+00\n","Epoch 29/120\n","3/3 [==============================] - 0s 30ms/step - loss: 0.0551 - accuracy: 0.0036 - val_loss: 0.8091 - val_accuracy: 0.0000e+00\n","Epoch 30/120\n","3/3 [==============================] - 0s 29ms/step - loss: 0.0523 - accuracy: 0.0036 - val_loss: 0.7116 - val_accuracy: 0.0000e+00\n","Epoch 31/120\n","3/3 [==============================] - 0s 31ms/step - loss: 0.0522 - accuracy: 0.0036 - val_loss: 0.4675 - val_accuracy: 0.0000e+00\n","Epoch 32/120\n","3/3 [==============================] - 0s 30ms/step - loss: 0.0492 - accuracy: 0.0036 - val_loss: 0.4663 - val_accuracy: 0.0000e+00\n","Epoch 33/120\n","3/3 [==============================] - 0s 33ms/step - loss: 0.0477 - accuracy: 0.0036 - val_loss: 0.5809 - val_accuracy: 0.0000e+00\n","Epoch 34/120\n","3/3 [==============================] - 0s 31ms/step - loss: 0.0486 - accuracy: 0.0071 - val_loss: 0.7273 - val_accuracy: 0.0000e+00\n","Epoch 35/120\n","3/3 [==============================] - 0s 33ms/step - loss: 0.0419 - accuracy: 0.0000e+00 - val_loss: 0.6200 - val_accuracy: 0.0000e+00\n","Epoch 36/120\n","3/3 [==============================] - 0s 30ms/step - loss: 0.0413 - accuracy: 0.0000e+00 - val_loss: 0.4625 - val_accuracy: 0.0000e+00\n","Epoch 37/120\n","3/3 [==============================] - 0s 33ms/step - loss: 0.0413 - accuracy: 0.0036 - val_loss: 0.3671 - val_accuracy: 0.0000e+00\n","Epoch 38/120\n","3/3 [==============================] - 0s 35ms/step - loss: 0.0394 - accuracy: 0.0000e+00 - val_loss: 0.3091 - val_accuracy: 0.0000e+00\n","Epoch 39/120\n","3/3 [==============================] - 0s 32ms/step - loss: 0.0374 - accuracy: 0.0000e+00 - val_loss: 0.2547 - val_accuracy: 0.0000e+00\n","Epoch 40/120\n","3/3 [==============================] - 0s 29ms/step - loss: 0.0359 - accuracy: 0.0036 - val_loss: 0.2868 - val_accuracy: 0.0000e+00\n","Epoch 41/120\n","3/3 [==============================] - 0s 31ms/step - loss: 0.0376 - accuracy: 0.0036 - val_loss: 0.2211 - val_accuracy: 0.0000e+00\n","Epoch 42/120\n","3/3 [==============================] - 0s 31ms/step - loss: 0.0365 - accuracy: 0.0036 - val_loss: 0.1505 - val_accuracy: 0.0000e+00\n","Epoch 43/120\n","3/3 [==============================] - 0s 30ms/step - loss: 0.0366 - accuracy: 0.0000e+00 - val_loss: 0.1683 - val_accuracy: 0.0000e+00\n","Epoch 44/120\n","3/3 [==============================] - 0s 29ms/step - loss: 0.0329 - accuracy: 0.0071 - val_loss: 0.1993 - val_accuracy: 0.0000e+00\n","Epoch 45/120\n","3/3 [==============================] - 0s 32ms/step - loss: 0.0368 - accuracy: 0.0000e+00 - val_loss: 0.1430 - val_accuracy: 0.0000e+00\n","Epoch 46/120\n","3/3 [==============================] - 0s 29ms/step - loss: 0.0312 - accuracy: 0.0036 - val_loss: 0.1220 - val_accuracy: 0.0000e+00\n","Epoch 47/120\n","3/3 [==============================] - 0s 33ms/step - loss: 0.0294 - accuracy: 0.0000e+00 - val_loss: 0.1328 - val_accuracy: 0.0000e+00\n","Epoch 48/120\n","3/3 [==============================] - 0s 31ms/step - loss: 0.0331 - accuracy: 0.0071 - val_loss: 0.1646 - val_accuracy: 0.0000e+00\n","Epoch 49/120\n","3/3 [==============================] - 0s 30ms/step - loss: 0.0293 - accuracy: 0.0071 - val_loss: 0.1724 - val_accuracy: 0.0000e+00\n","Epoch 50/120\n","3/3 [==============================] - 0s 29ms/step - loss: 0.0274 - accuracy: 0.0071 - val_loss: 0.1516 - val_accuracy: 0.0000e+00\n","Epoch 51/120\n","3/3 [==============================] - 0s 31ms/step - loss: 0.0236 - accuracy: 0.0036 - val_loss: 0.1517 - val_accuracy: 0.0000e+00\n","Epoch 52/120\n","3/3 [==============================] - 0s 32ms/step - loss: 0.0260 - accuracy: 0.0071 - val_loss: 0.1520 - val_accuracy: 0.0000e+00\n","Epoch 53/120\n","3/3 [==============================] - 0s 32ms/step - loss: 0.0252 - accuracy: 0.0036 - val_loss: 0.1492 - val_accuracy: 0.0000e+00\n","Epoch 54/120\n","3/3 [==============================] - 0s 31ms/step - loss: 0.0221 - accuracy: 0.0036 - val_loss: 0.1415 - val_accuracy: 0.0000e+00\n","Epoch 55/120\n","3/3 [==============================] - 0s 31ms/step - loss: 0.0222 - accuracy: 0.0071 - val_loss: 0.1038 - val_accuracy: 0.0000e+00\n","Epoch 56/120\n","3/3 [==============================] - 0s 30ms/step - loss: 0.0283 - accuracy: 0.0000e+00 - val_loss: 0.1394 - val_accuracy: 0.0000e+00\n","Epoch 57/120\n","3/3 [==============================] - 0s 36ms/step - loss: 0.0273 - accuracy: 0.0107 - val_loss: 0.5356 - val_accuracy: 0.0000e+00\n","Epoch 58/120\n","3/3 [==============================] - 0s 31ms/step - loss: 0.0333 - accuracy: 0.0071 - val_loss: 0.6069 - val_accuracy: 0.0000e+00\n","Epoch 59/120\n","3/3 [==============================] - 0s 31ms/step - loss: 0.0333 - accuracy: 0.0071 - val_loss: 0.4715 - val_accuracy: 0.0000e+00\n","Epoch 60/120\n","3/3 [==============================] - 0s 29ms/step - loss: 0.0303 - accuracy: 0.0071 - val_loss: 0.3945 - val_accuracy: 0.0000e+00\n","Epoch 61/120\n","3/3 [==============================] - 0s 30ms/step - loss: 0.0257 - accuracy: 0.0036 - val_loss: 0.3458 - val_accuracy: 0.0000e+00\n","Epoch 62/120\n","3/3 [==============================] - 0s 32ms/step - loss: 0.0237 - accuracy: 0.0036 - val_loss: 0.3454 - val_accuracy: 0.0000e+00\n","Epoch 63/120\n","3/3 [==============================] - 0s 33ms/step - loss: 0.0283 - accuracy: 0.0000e+00 - val_loss: 0.3066 - val_accuracy: 0.0000e+00\n","Epoch 64/120\n","3/3 [==============================] - 0s 29ms/step - loss: 0.0246 - accuracy: 0.0071 - val_loss: 0.2051 - val_accuracy: 0.0000e+00\n","Epoch 65/120\n","3/3 [==============================] - 0s 34ms/step - loss: 0.0210 - accuracy: 0.0036 - val_loss: 0.1381 - val_accuracy: 0.0000e+00\n","Epoch 66/120\n","3/3 [==============================] - 0s 32ms/step - loss: 0.0259 - accuracy: 0.0036 - val_loss: 0.1673 - val_accuracy: 0.0000e+00\n","Epoch 67/120\n","3/3 [==============================] - 0s 31ms/step - loss: 0.0222 - accuracy: 0.0000e+00 - val_loss: 0.2462 - val_accuracy: 0.0000e+00\n","Epoch 68/120\n","3/3 [==============================] - 0s 31ms/step - loss: 0.0202 - accuracy: 0.0036 - val_loss: 0.2345 - val_accuracy: 0.0000e+00\n","Epoch 69/120\n","3/3 [==============================] - 0s 31ms/step - loss: 0.0210 - accuracy: 0.0000e+00 - val_loss: 0.1681 - val_accuracy: 0.0000e+00\n","Epoch 70/120\n","3/3 [==============================] - 0s 35ms/step - loss: 0.0186 - accuracy: 0.0036 - val_loss: 0.1472 - val_accuracy: 0.0000e+00\n","Epoch 71/120\n","3/3 [==============================] - 0s 36ms/step - loss: 0.0192 - accuracy: 0.0000e+00 - val_loss: 0.1482 - val_accuracy: 0.0000e+00\n","Epoch 72/120\n","3/3 [==============================] - 0s 30ms/step - loss: 0.0178 - accuracy: 0.0000e+00 - val_loss: 0.1479 - val_accuracy: 0.0000e+00\n","Epoch 73/120\n","3/3 [==============================] - 0s 30ms/step - loss: 0.0184 - accuracy: 0.0071 - val_loss: 0.1440 - val_accuracy: 0.0000e+00\n","Epoch 74/120\n","3/3 [==============================] - 0s 30ms/step - loss: 0.0174 - accuracy: 0.0036 - val_loss: 0.1399 - val_accuracy: 0.0000e+00\n","Epoch 75/120\n","3/3 [==============================] - 0s 32ms/step - loss: 0.0181 - accuracy: 0.0036 - val_loss: 0.1391 - val_accuracy: 0.0000e+00\n","Epoch 76/120\n","3/3 [==============================] - 0s 30ms/step - loss: 0.0157 - accuracy: 0.0000e+00 - val_loss: 0.1454 - val_accuracy: 0.0000e+00\n","Epoch 77/120\n","3/3 [==============================] - 0s 34ms/step - loss: 0.0143 - accuracy: 0.0071 - val_loss: 0.1449 - val_accuracy: 0.0000e+00\n","Epoch 78/120\n","3/3 [==============================] - 0s 28ms/step - loss: 0.0165 - accuracy: 0.0000e+00 - val_loss: 0.1477 - val_accuracy: 0.0000e+00\n","Epoch 79/120\n","3/3 [==============================] - 0s 29ms/step - loss: 0.0156 - accuracy: 0.0036 - val_loss: 0.1374 - val_accuracy: 0.0000e+00\n","Epoch 80/120\n","3/3 [==============================] - 0s 31ms/step - loss: 0.0126 - accuracy: 0.0036 - val_loss: 0.1124 - val_accuracy: 0.0000e+00\n","Epoch 81/120\n","3/3 [==============================] - 0s 53ms/step - loss: 0.0155 - accuracy: 0.0000e+00 - val_loss: 0.0887 - val_accuracy: 0.0000e+00\n","Epoch 82/120\n","3/3 [==============================] - 0s 37ms/step - loss: 0.0149 - accuracy: 0.0036 - val_loss: 0.0806 - val_accuracy: 0.0000e+00\n","Epoch 83/120\n","3/3 [==============================] - 0s 34ms/step - loss: 0.0144 - accuracy: 0.0036 - val_loss: 0.0805 - val_accuracy: 0.0000e+00\n","Epoch 84/120\n","3/3 [==============================] - 0s 39ms/step - loss: 0.0132 - accuracy: 0.0000e+00 - val_loss: 0.0858 - val_accuracy: 0.0000e+00\n","Epoch 85/120\n","3/3 [==============================] - 0s 34ms/step - loss: 0.0126 - accuracy: 0.0036 - val_loss: 0.0941 - val_accuracy: 0.0000e+00\n","Epoch 86/120\n","3/3 [==============================] - 0s 30ms/step - loss: 0.0121 - accuracy: 0.0036 - val_loss: 0.0960 - val_accuracy: 0.0000e+00\n","Epoch 87/120\n","3/3 [==============================] - 0s 31ms/step - loss: 0.0123 - accuracy: 0.0036 - val_loss: 0.0977 - val_accuracy: 0.0000e+00\n","Epoch 88/120\n","3/3 [==============================] - 0s 30ms/step - loss: 0.0147 - accuracy: 0.0000e+00 - val_loss: 0.0910 - val_accuracy: 0.0000e+00\n","Epoch 89/120\n","3/3 [==============================] - 0s 31ms/step - loss: 0.0138 - accuracy: 0.0036 - val_loss: 0.0903 - val_accuracy: 0.0000e+00\n","Epoch 90/120\n","3/3 [==============================] - 0s 32ms/step - loss: 0.0140 - accuracy: 0.0071 - val_loss: 0.0940 - val_accuracy: 0.0000e+00\n","Epoch 91/120\n","3/3 [==============================] - 0s 34ms/step - loss: 0.0125 - accuracy: 0.0000e+00 - val_loss: 0.0901 - val_accuracy: 0.0000e+00\n","Epoch 92/120\n","3/3 [==============================] - 0s 33ms/step - loss: 0.0086 - accuracy: 0.0036 - val_loss: 0.0859 - val_accuracy: 0.0000e+00\n","Epoch 93/120\n","3/3 [==============================] - 0s 30ms/step - loss: 0.0119 - accuracy: 0.0036 - val_loss: 0.0822 - val_accuracy: 0.0000e+00\n","Epoch 94/120\n","3/3 [==============================] - 0s 30ms/step - loss: 0.0095 - accuracy: 0.0036 - val_loss: 0.0946 - val_accuracy: 0.0000e+00\n","Epoch 95/120\n","3/3 [==============================] - 0s 30ms/step - loss: 0.0121 - accuracy: 0.0000e+00 - val_loss: 0.1015 - val_accuracy: 0.0000e+00\n","Epoch 96/120\n","3/3 [==============================] - 0s 30ms/step - loss: 0.0100 - accuracy: 0.0036 - val_loss: 0.0979 - val_accuracy: 0.0000e+00\n","Epoch 97/120\n","3/3 [==============================] - 0s 32ms/step - loss: 0.0104 - accuracy: 0.0036 - val_loss: 0.0861 - val_accuracy: 0.0000e+00\n","Epoch 98/120\n","3/3 [==============================] - 0s 30ms/step - loss: 0.0100 - accuracy: 0.0036 - val_loss: 0.0782 - val_accuracy: 0.0000e+00\n","Epoch 99/120\n","3/3 [==============================] - 0s 32ms/step - loss: 0.0099 - accuracy: 0.0071 - val_loss: 0.0781 - val_accuracy: 0.0000e+00\n","Epoch 100/120\n","3/3 [==============================] - 0s 33ms/step - loss: 0.0103 - accuracy: 0.0071 - val_loss: 0.0810 - val_accuracy: 0.0000e+00\n","Epoch 101/120\n","3/3 [==============================] - 0s 34ms/step - loss: 0.0093 - accuracy: 0.0071 - val_loss: 0.0829 - val_accuracy: 0.0000e+00\n","Epoch 102/120\n","3/3 [==============================] - 0s 30ms/step - loss: 0.0105 - accuracy: 0.0036 - val_loss: 0.0862 - val_accuracy: 0.0000e+00\n","Epoch 103/120\n","3/3 [==============================] - 0s 36ms/step - loss: 0.0087 - accuracy: 0.0000e+00 - val_loss: 0.0867 - val_accuracy: 0.0000e+00\n","Epoch 104/120\n","3/3 [==============================] - 0s 32ms/step - loss: 0.0099 - accuracy: 0.0036 - val_loss: 0.0832 - val_accuracy: 0.0000e+00\n","Epoch 105/120\n","3/3 [==============================] - 0s 31ms/step - loss: 0.0079 - accuracy: 0.0071 - val_loss: 0.0777 - val_accuracy: 0.0000e+00\n","Epoch 106/120\n","3/3 [==============================] - 0s 29ms/step - loss: 0.0100 - accuracy: 0.0000e+00 - val_loss: 0.0671 - val_accuracy: 0.0000e+00\n","Epoch 107/120\n","3/3 [==============================] - 0s 35ms/step - loss: 0.0107 - accuracy: 0.0000e+00 - val_loss: 0.0650 - val_accuracy: 0.0000e+00\n","Epoch 108/120\n","3/3 [==============================] - 0s 32ms/step - loss: 0.0105 - accuracy: 0.0107 - val_loss: 0.0663 - val_accuracy: 0.0000e+00\n","Epoch 109/120\n","3/3 [==============================] - 0s 33ms/step - loss: 0.0092 - accuracy: 0.0036 - val_loss: 0.0696 - val_accuracy: 0.0000e+00\n","Epoch 110/120\n","3/3 [==============================] - 0s 31ms/step - loss: 0.0091 - accuracy: 0.0036 - val_loss: 0.0723 - val_accuracy: 0.0000e+00\n","Epoch 111/120\n","3/3 [==============================] - 0s 31ms/step - loss: 0.0091 - accuracy: 0.0036 - val_loss: 0.0730 - val_accuracy: 0.0000e+00\n","Epoch 112/120\n","3/3 [==============================] - 0s 32ms/step - loss: 0.0087 - accuracy: 0.0071 - val_loss: 0.0713 - val_accuracy: 0.0000e+00\n","Epoch 113/120\n","3/3 [==============================] - 0s 31ms/step - loss: 0.0077 - accuracy: 0.0142 - val_loss: 0.0731 - val_accuracy: 0.0000e+00\n","Epoch 114/120\n","3/3 [==============================] - 0s 32ms/step - loss: 0.0082 - accuracy: 0.0071 - val_loss: 0.0759 - val_accuracy: 0.0000e+00\n","Epoch 115/120\n","3/3 [==============================] - 0s 31ms/step - loss: 0.0139 - accuracy: 0.0000e+00 - val_loss: 0.0685 - val_accuracy: 0.0000e+00\n","Epoch 116/120\n","3/3 [==============================] - 0s 33ms/step - loss: 0.0083 - accuracy: 0.0071 - val_loss: 0.0676 - val_accuracy: 0.0000e+00\n","Epoch 117/120\n","3/3 [==============================] - 0s 34ms/step - loss: 0.0167 - accuracy: 0.0036 - val_loss: 0.0714 - val_accuracy: 0.0000e+00\n","Epoch 118/120\n","3/3 [==============================] - 0s 31ms/step - loss: 0.0116 - accuracy: 0.0071 - val_loss: 0.0852 - val_accuracy: 0.0000e+00\n","Epoch 119/120\n","3/3 [==============================] - 0s 34ms/step - loss: 0.0114 - accuracy: 0.0036 - val_loss: 0.0934 - val_accuracy: 0.0000e+00\n","Epoch 120/120\n","3/3 [==============================] - 0s 32ms/step - loss: 0.0090 - accuracy: 0.0036 - val_loss: 0.0940 - val_accuracy: 0.0000e+00\n","--------------------------------------------------------------------------------\n","--------------------------------------------------------------------------------\n","6 ------ Frying 130\n","X_train shape: \n","(208, 216, 13)\n","Model: \"sequential_6\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","conv2d_12 (Conv2D)           (None, 214, 11, 128)      1280      \n","_________________________________________________________________\n","max_pooling2d_12 (MaxPooling (None, 107, 6, 128)       0         \n","_________________________________________________________________\n","batch_normalization_12 (Batc (None, 107, 6, 128)       512       \n","_________________________________________________________________\n","conv2d_13 (Conv2D)           (None, 105, 4, 128)       147584    \n","_________________________________________________________________\n","max_pooling2d_13 (MaxPooling (None, 53, 2, 128)        0         \n","_________________________________________________________________\n","batch_normalization_13 (Batc (None, 53, 2, 128)        512       \n","_________________________________________________________________\n","flatten_6 (Flatten)          (None, 13568)             0         \n","_________________________________________________________________\n","dense_12 (Dense)             (None, 256)               3473664   \n","_________________________________________________________________\n","dropout_6 (Dropout)          (None, 256)               0         \n","_________________________________________________________________\n","dense_13 (Dense)             (None, 216)               55512     \n","=================================================================\n","Total params: 3,679,064\n","Trainable params: 3,678,552\n","Non-trainable params: 512\n","_________________________________________________________________\n","Epoch 1/120\n","2/2 [==============================] - 2s 1s/step - loss: 0.8334 - accuracy: 0.0120 - val_loss: 3.4203 - val_accuracy: 0.0000e+00\n","Epoch 2/120\n","2/2 [==============================] - 0s 38ms/step - loss: 0.6545 - accuracy: 0.0000e+00 - val_loss: 3.4522 - val_accuracy: 0.0000e+00\n","Epoch 3/120\n","2/2 [==============================] - 0s 37ms/step - loss: 0.6127 - accuracy: 0.0060 - val_loss: 4.5453 - val_accuracy: 0.0000e+00\n","Epoch 4/120\n","2/2 [==============================] - 0s 38ms/step - loss: 0.5702 - accuracy: 0.0000e+00 - val_loss: 4.7713 - val_accuracy: 0.0000e+00\n","Epoch 5/120\n","2/2 [==============================] - 0s 41ms/step - loss: 0.5173 - accuracy: 0.0060 - val_loss: 4.6989 - val_accuracy: 0.0000e+00\n","Epoch 6/120\n","2/2 [==============================] - 0s 37ms/step - loss: 0.4596 - accuracy: 0.0000e+00 - val_loss: 5.0147 - val_accuracy: 0.0000e+00\n","Epoch 7/120\n","2/2 [==============================] - 0s 43ms/step - loss: 0.4161 - accuracy: 0.0000e+00 - val_loss: 4.7251 - val_accuracy: 0.0000e+00\n","Epoch 8/120\n","2/2 [==============================] - 0s 41ms/step - loss: 0.3705 - accuracy: 0.0060 - val_loss: 4.3702 - val_accuracy: 0.0000e+00\n","Epoch 9/120\n","2/2 [==============================] - 0s 41ms/step - loss: 0.3401 - accuracy: 0.0000e+00 - val_loss: 4.9776 - val_accuracy: 0.0000e+00\n","Epoch 10/120\n","2/2 [==============================] - 0s 36ms/step - loss: 0.2984 - accuracy: 0.0060 - val_loss: 5.6318 - val_accuracy: 0.0000e+00\n","Epoch 11/120\n","2/2 [==============================] - 0s 40ms/step - loss: 0.2816 - accuracy: 0.0120 - val_loss: 5.5875 - val_accuracy: 0.0000e+00\n","Epoch 12/120\n","2/2 [==============================] - 0s 40ms/step - loss: 0.2408 - accuracy: 0.0000e+00 - val_loss: 5.3020 - val_accuracy: 0.0000e+00\n","Epoch 13/120\n","2/2 [==============================] - 0s 36ms/step - loss: 0.2207 - accuracy: 0.0000e+00 - val_loss: 5.0603 - val_accuracy: 0.0000e+00\n","Epoch 14/120\n","2/2 [==============================] - 0s 40ms/step - loss: 0.2012 - accuracy: 0.0000e+00 - val_loss: 4.9169 - val_accuracy: 0.0000e+00\n","Epoch 15/120\n","2/2 [==============================] - 0s 36ms/step - loss: 0.1880 - accuracy: 0.0060 - val_loss: 4.7568 - val_accuracy: 0.0000e+00\n","Epoch 16/120\n","2/2 [==============================] - 0s 37ms/step - loss: 0.1712 - accuracy: 0.0000e+00 - val_loss: 3.9253 - val_accuracy: 0.0000e+00\n","Epoch 17/120\n","2/2 [==============================] - 0s 42ms/step - loss: 0.1558 - accuracy: 0.0000e+00 - val_loss: 3.5197 - val_accuracy: 0.0000e+00\n","Epoch 18/120\n","2/2 [==============================] - 0s 37ms/step - loss: 0.1396 - accuracy: 0.0060 - val_loss: 3.7294 - val_accuracy: 0.0000e+00\n","Epoch 19/120\n","2/2 [==============================] - 0s 37ms/step - loss: 0.1419 - accuracy: 0.0000e+00 - val_loss: 3.3641 - val_accuracy: 0.0000e+00\n","Epoch 20/120\n","2/2 [==============================] - 0s 39ms/step - loss: 0.1260 - accuracy: 0.0000e+00 - val_loss: 2.4504 - val_accuracy: 0.0000e+00\n","Epoch 21/120\n","2/2 [==============================] - 0s 39ms/step - loss: 0.1290 - accuracy: 0.0000e+00 - val_loss: 1.7841 - val_accuracy: 0.0000e+00\n","Epoch 22/120\n","2/2 [==============================] - 0s 38ms/step - loss: 0.1132 - accuracy: 0.0120 - val_loss: 1.9481 - val_accuracy: 0.0000e+00\n","Epoch 23/120\n","2/2 [==============================] - 0s 42ms/step - loss: 0.1123 - accuracy: 0.0000e+00 - val_loss: 2.5488 - val_accuracy: 0.0000e+00\n","Epoch 24/120\n","2/2 [==============================] - 0s 35ms/step - loss: 0.1004 - accuracy: 0.0000e+00 - val_loss: 2.7068 - val_accuracy: 0.0000e+00\n","Epoch 25/120\n","2/2 [==============================] - 0s 40ms/step - loss: 0.0967 - accuracy: 0.0000e+00 - val_loss: 2.2060 - val_accuracy: 0.0000e+00\n","Epoch 26/120\n","2/2 [==============================] - 0s 35ms/step - loss: 0.0828 - accuracy: 0.0000e+00 - val_loss: 1.6671 - val_accuracy: 0.0000e+00\n","Epoch 27/120\n","2/2 [==============================] - 0s 36ms/step - loss: 0.0884 - accuracy: 0.0060 - val_loss: 1.5545 - val_accuracy: 0.0000e+00\n","Epoch 28/120\n","2/2 [==============================] - 0s 38ms/step - loss: 0.0836 - accuracy: 0.0060 - val_loss: 1.2826 - val_accuracy: 0.0000e+00\n","Epoch 29/120\n","2/2 [==============================] - 0s 36ms/step - loss: 0.0753 - accuracy: 0.0060 - val_loss: 1.0857 - val_accuracy: 0.0000e+00\n","Epoch 30/120\n","2/2 [==============================] - 0s 38ms/step - loss: 0.0755 - accuracy: 0.0000e+00 - val_loss: 1.0215 - val_accuracy: 0.0000e+00\n","Epoch 31/120\n","2/2 [==============================] - 0s 64ms/step - loss: 0.0715 - accuracy: 0.0120 - val_loss: 0.9997 - val_accuracy: 0.0000e+00\n","Epoch 32/120\n","2/2 [==============================] - 0s 38ms/step - loss: 0.0706 - accuracy: 0.0000e+00 - val_loss: 1.0694 - val_accuracy: 0.0000e+00\n","Epoch 33/120\n","2/2 [==============================] - 0s 46ms/step - loss: 0.0644 - accuracy: 0.0060 - val_loss: 1.1529 - val_accuracy: 0.0000e+00\n","Epoch 34/120\n","2/2 [==============================] - 0s 40ms/step - loss: 0.0632 - accuracy: 0.0000e+00 - val_loss: 1.2404 - val_accuracy: 0.0000e+00\n","Epoch 35/120\n","2/2 [==============================] - 0s 44ms/step - loss: 0.0658 - accuracy: 0.0000e+00 - val_loss: 1.1049 - val_accuracy: 0.0000e+00\n","Epoch 36/120\n","2/2 [==============================] - 0s 39ms/step - loss: 0.0581 - accuracy: 0.0000e+00 - val_loss: 1.0460 - val_accuracy: 0.0000e+00\n","Epoch 37/120\n","2/2 [==============================] - 0s 39ms/step - loss: 0.0624 - accuracy: 0.0060 - val_loss: 1.0873 - val_accuracy: 0.0000e+00\n","Epoch 38/120\n","2/2 [==============================] - 0s 40ms/step - loss: 0.0540 - accuracy: 0.0060 - val_loss: 1.2127 - val_accuracy: 0.0000e+00\n","Epoch 39/120\n","2/2 [==============================] - 0s 36ms/step - loss: 0.0607 - accuracy: 0.0060 - val_loss: 1.0106 - val_accuracy: 0.0000e+00\n","Epoch 40/120\n","2/2 [==============================] - 0s 41ms/step - loss: 0.0547 - accuracy: 0.0060 - val_loss: 0.7135 - val_accuracy: 0.0000e+00\n","Epoch 41/120\n","2/2 [==============================] - 0s 39ms/step - loss: 0.0545 - accuracy: 0.0000e+00 - val_loss: 0.6051 - val_accuracy: 0.0000e+00\n","Epoch 42/120\n","2/2 [==============================] - 0s 40ms/step - loss: 0.0514 - accuracy: 0.0000e+00 - val_loss: 0.6402 - val_accuracy: 0.0000e+00\n","Epoch 43/120\n","2/2 [==============================] - 0s 41ms/step - loss: 0.0541 - accuracy: 0.0060 - val_loss: 0.7484 - val_accuracy: 0.0000e+00\n","Epoch 44/120\n","2/2 [==============================] - 0s 40ms/step - loss: 0.0457 - accuracy: 0.0000e+00 - val_loss: 0.9213 - val_accuracy: 0.0000e+00\n","Epoch 45/120\n","2/2 [==============================] - 0s 39ms/step - loss: 0.0529 - accuracy: 0.0120 - val_loss: 0.9514 - val_accuracy: 0.0000e+00\n","Epoch 46/120\n","2/2 [==============================] - 0s 44ms/step - loss: 0.0474 - accuracy: 0.0060 - val_loss: 0.7966 - val_accuracy: 0.0000e+00\n","Epoch 47/120\n","2/2 [==============================] - 0s 42ms/step - loss: 0.0456 - accuracy: 0.0000e+00 - val_loss: 0.6841 - val_accuracy: 0.0000e+00\n","Epoch 48/120\n","2/2 [==============================] - 0s 39ms/step - loss: 0.0505 - accuracy: 0.0000e+00 - val_loss: 0.6690 - val_accuracy: 0.0000e+00\n","Epoch 49/120\n","2/2 [==============================] - 0s 41ms/step - loss: 0.0512 - accuracy: 0.0060 - val_loss: 0.6677 - val_accuracy: 0.0000e+00\n","Epoch 50/120\n","2/2 [==============================] - 0s 41ms/step - loss: 0.0430 - accuracy: 0.0120 - val_loss: 0.7444 - val_accuracy: 0.0000e+00\n","Epoch 51/120\n","2/2 [==============================] - 0s 54ms/step - loss: 0.0428 - accuracy: 0.0060 - val_loss: 0.8800 - val_accuracy: 0.0000e+00\n","Epoch 52/120\n","2/2 [==============================] - 0s 36ms/step - loss: 0.0441 - accuracy: 0.0000e+00 - val_loss: 0.9755 - val_accuracy: 0.0000e+00\n","Epoch 53/120\n","2/2 [==============================] - 0s 40ms/step - loss: 0.0449 - accuracy: 0.0060 - val_loss: 0.8695 - val_accuracy: 0.0000e+00\n","Epoch 54/120\n","2/2 [==============================] - 0s 37ms/step - loss: 0.0418 - accuracy: 0.0120 - val_loss: 0.6749 - val_accuracy: 0.0000e+00\n","Epoch 55/120\n","2/2 [==============================] - 0s 44ms/step - loss: 0.0404 - accuracy: 0.0000e+00 - val_loss: 0.5896 - val_accuracy: 0.0000e+00\n","Epoch 56/120\n","2/2 [==============================] - 0s 51ms/step - loss: 0.0369 - accuracy: 0.0000e+00 - val_loss: 0.5954 - val_accuracy: 0.0000e+00\n","Epoch 57/120\n","2/2 [==============================] - 0s 40ms/step - loss: 0.0422 - accuracy: 0.0120 - val_loss: 0.6592 - val_accuracy: 0.0000e+00\n","Epoch 58/120\n","2/2 [==============================] - 0s 57ms/step - loss: 0.0376 - accuracy: 0.0000e+00 - val_loss: 0.6974 - val_accuracy: 0.0000e+00\n","Epoch 59/120\n","2/2 [==============================] - 0s 40ms/step - loss: 0.0331 - accuracy: 0.0000e+00 - val_loss: 0.6634 - val_accuracy: 0.0000e+00\n","Epoch 60/120\n","2/2 [==============================] - 0s 43ms/step - loss: 0.0351 - accuracy: 0.0060 - val_loss: 0.5860 - val_accuracy: 0.0000e+00\n","Epoch 61/120\n","2/2 [==============================] - 0s 45ms/step - loss: 0.0381 - accuracy: 0.0000e+00 - val_loss: 0.4922 - val_accuracy: 0.0000e+00\n","Epoch 62/120\n","2/2 [==============================] - 0s 41ms/step - loss: 0.0330 - accuracy: 0.0000e+00 - val_loss: 0.4301 - val_accuracy: 0.0000e+00\n","Epoch 63/120\n","2/2 [==============================] - 0s 38ms/step - loss: 0.0382 - accuracy: 0.0181 - val_loss: 0.4466 - val_accuracy: 0.0000e+00\n","Epoch 64/120\n","2/2 [==============================] - 0s 39ms/step - loss: 0.0317 - accuracy: 0.0000e+00 - val_loss: 0.4818 - val_accuracy: 0.0000e+00\n","Epoch 65/120\n","2/2 [==============================] - 0s 41ms/step - loss: 0.0358 - accuracy: 0.0000e+00 - val_loss: 0.4858 - val_accuracy: 0.0000e+00\n","Epoch 66/120\n","2/2 [==============================] - 0s 39ms/step - loss: 0.0325 - accuracy: 0.0120 - val_loss: 0.4417 - val_accuracy: 0.0000e+00\n","Epoch 67/120\n","2/2 [==============================] - 0s 43ms/step - loss: 0.0292 - accuracy: 0.0060 - val_loss: 0.4079 - val_accuracy: 0.0000e+00\n","Epoch 68/120\n","2/2 [==============================] - 0s 39ms/step - loss: 0.0347 - accuracy: 0.0060 - val_loss: 0.3948 - val_accuracy: 0.0000e+00\n","Epoch 69/120\n","2/2 [==============================] - 0s 49ms/step - loss: 0.0349 - accuracy: 0.0000e+00 - val_loss: 0.3982 - val_accuracy: 0.0000e+00\n","Epoch 70/120\n","2/2 [==============================] - 0s 44ms/step - loss: 0.0271 - accuracy: 0.0000e+00 - val_loss: 0.3870 - val_accuracy: 0.0000e+00\n","Epoch 71/120\n","2/2 [==============================] - 0s 41ms/step - loss: 0.0294 - accuracy: 0.0120 - val_loss: 0.3582 - val_accuracy: 0.0000e+00\n","Epoch 72/120\n","2/2 [==============================] - 0s 42ms/step - loss: 0.0285 - accuracy: 0.0000e+00 - val_loss: 0.3393 - val_accuracy: 0.0000e+00\n","Epoch 73/120\n","2/2 [==============================] - 0s 41ms/step - loss: 0.0287 - accuracy: 0.0000e+00 - val_loss: 0.3326 - val_accuracy: 0.0000e+00\n","Epoch 74/120\n","2/2 [==============================] - 0s 40ms/step - loss: 0.0287 - accuracy: 0.0060 - val_loss: 0.3370 - val_accuracy: 0.0000e+00\n","Epoch 75/120\n","2/2 [==============================] - 0s 41ms/step - loss: 0.0296 - accuracy: 0.0000e+00 - val_loss: 0.3494 - val_accuracy: 0.0000e+00\n","Epoch 76/120\n","2/2 [==============================] - 0s 38ms/step - loss: 0.0278 - accuracy: 0.0000e+00 - val_loss: 0.3640 - val_accuracy: 0.0000e+00\n","Epoch 77/120\n","2/2 [==============================] - 0s 42ms/step - loss: 0.0255 - accuracy: 0.0060 - val_loss: 0.3603 - val_accuracy: 0.0000e+00\n","Epoch 78/120\n","2/2 [==============================] - 0s 39ms/step - loss: 0.0323 - accuracy: 0.0120 - val_loss: 0.3575 - val_accuracy: 0.0000e+00\n","Epoch 79/120\n","2/2 [==============================] - 0s 37ms/step - loss: 0.0290 - accuracy: 0.0000e+00 - val_loss: 0.3466 - val_accuracy: 0.0000e+00\n","Epoch 80/120\n","2/2 [==============================] - 0s 42ms/step - loss: 0.0214 - accuracy: 0.0060 - val_loss: 0.3507 - val_accuracy: 0.0000e+00\n","Epoch 81/120\n","2/2 [==============================] - 0s 37ms/step - loss: 0.0252 - accuracy: 0.0060 - val_loss: 0.3508 - val_accuracy: 0.0000e+00\n","Epoch 82/120\n","2/2 [==============================] - 0s 40ms/step - loss: 0.0236 - accuracy: 0.0000e+00 - val_loss: 0.3322 - val_accuracy: 0.0000e+00\n","Epoch 83/120\n","2/2 [==============================] - 0s 39ms/step - loss: 0.0224 - accuracy: 0.0060 - val_loss: 0.3156 - val_accuracy: 0.0000e+00\n","Epoch 84/120\n","2/2 [==============================] - 0s 43ms/step - loss: 0.0206 - accuracy: 0.0120 - val_loss: 0.3051 - val_accuracy: 0.0000e+00\n","Epoch 85/120\n","2/2 [==============================] - 0s 43ms/step - loss: 0.0241 - accuracy: 0.0120 - val_loss: 0.3022 - val_accuracy: 0.0000e+00\n","Epoch 86/120\n","2/2 [==============================] - 0s 36ms/step - loss: 0.0244 - accuracy: 0.0000e+00 - val_loss: 0.3191 - val_accuracy: 0.0000e+00\n","Epoch 87/120\n","2/2 [==============================] - 0s 39ms/step - loss: 0.0240 - accuracy: 0.0060 - val_loss: 0.3368 - val_accuracy: 0.0000e+00\n","Epoch 88/120\n","2/2 [==============================] - 0s 39ms/step - loss: 0.0268 - accuracy: 0.0120 - val_loss: 0.3431 - val_accuracy: 0.0000e+00\n","Epoch 89/120\n","2/2 [==============================] - 0s 40ms/step - loss: 0.0253 - accuracy: 0.0000e+00 - val_loss: 0.3338 - val_accuracy: 0.0000e+00\n","Epoch 90/120\n","2/2 [==============================] - 0s 39ms/step - loss: 0.0174 - accuracy: 0.0060 - val_loss: 0.3463 - val_accuracy: 0.0000e+00\n","Epoch 91/120\n","2/2 [==============================] - 0s 42ms/step - loss: 0.0182 - accuracy: 0.0000e+00 - val_loss: 0.3789 - val_accuracy: 0.0000e+00\n","Epoch 92/120\n","2/2 [==============================] - 0s 40ms/step - loss: 0.0198 - accuracy: 0.0060 - val_loss: 0.3976 - val_accuracy: 0.0000e+00\n","Epoch 93/120\n","2/2 [==============================] - 0s 42ms/step - loss: 0.0208 - accuracy: 0.0060 - val_loss: 0.3806 - val_accuracy: 0.0000e+00\n","Epoch 94/120\n","2/2 [==============================] - 0s 40ms/step - loss: 0.0241 - accuracy: 0.0060 - val_loss: 0.3548 - val_accuracy: 0.0000e+00\n","Epoch 95/120\n","2/2 [==============================] - 0s 44ms/step - loss: 0.0220 - accuracy: 0.0060 - val_loss: 0.3385 - val_accuracy: 0.0000e+00\n","Epoch 96/120\n","2/2 [==============================] - 0s 41ms/step - loss: 0.0208 - accuracy: 0.0060 - val_loss: 0.3302 - val_accuracy: 0.0000e+00\n","Epoch 97/120\n","2/2 [==============================] - 0s 40ms/step - loss: 0.0193 - accuracy: 0.0000e+00 - val_loss: 0.3298 - val_accuracy: 0.0000e+00\n","Epoch 98/120\n","2/2 [==============================] - 0s 42ms/step - loss: 0.0193 - accuracy: 0.0000e+00 - val_loss: 0.3197 - val_accuracy: 0.0000e+00\n","Epoch 99/120\n","2/2 [==============================] - 0s 43ms/step - loss: 0.0240 - accuracy: 0.0060 - val_loss: 0.3119 - val_accuracy: 0.0000e+00\n","Epoch 100/120\n","2/2 [==============================] - 0s 41ms/step - loss: 0.0184 - accuracy: 0.0060 - val_loss: 0.3222 - val_accuracy: 0.0000e+00\n","Epoch 101/120\n","2/2 [==============================] - 0s 42ms/step - loss: 0.0198 - accuracy: 0.0060 - val_loss: 0.3381 - val_accuracy: 0.0000e+00\n","Epoch 102/120\n","2/2 [==============================] - 0s 40ms/step - loss: 0.0217 - accuracy: 0.0060 - val_loss: 0.3462 - val_accuracy: 0.0000e+00\n","Epoch 103/120\n","2/2 [==============================] - 0s 77ms/step - loss: 0.0199 - accuracy: 0.0060 - val_loss: 0.3397 - val_accuracy: 0.0000e+00\n","Epoch 104/120\n","2/2 [==============================] - 0s 66ms/step - loss: 0.0198 - accuracy: 0.0000e+00 - val_loss: 0.3329 - val_accuracy: 0.0000e+00\n","Epoch 105/120\n","2/2 [==============================] - 0s 54ms/step - loss: 0.0191 - accuracy: 0.0060 - val_loss: 0.3233 - val_accuracy: 0.0000e+00\n","Epoch 106/120\n","2/2 [==============================] - 0s 53ms/step - loss: 0.0184 - accuracy: 0.0060 - val_loss: 0.3214 - val_accuracy: 0.0000e+00\n","Epoch 107/120\n","2/2 [==============================] - 0s 44ms/step - loss: 0.0179 - accuracy: 0.0060 - val_loss: 0.3336 - val_accuracy: 0.0000e+00\n","Epoch 108/120\n","2/2 [==============================] - 0s 41ms/step - loss: 0.0171 - accuracy: 0.0060 - val_loss: 0.3454 - val_accuracy: 0.0000e+00\n","Epoch 109/120\n","2/2 [==============================] - 0s 43ms/step - loss: 0.0170 - accuracy: 0.0000e+00 - val_loss: 0.3543 - val_accuracy: 0.0000e+00\n","Epoch 110/120\n","2/2 [==============================] - 0s 40ms/step - loss: 0.0169 - accuracy: 0.0060 - val_loss: 0.3570 - val_accuracy: 0.0000e+00\n","Epoch 111/120\n","2/2 [==============================] - 0s 39ms/step - loss: 0.0133 - accuracy: 0.0000e+00 - val_loss: 0.3343 - val_accuracy: 0.0000e+00\n","Epoch 112/120\n","2/2 [==============================] - 0s 38ms/step - loss: 0.0166 - accuracy: 0.0060 - val_loss: 0.3155 - val_accuracy: 0.0000e+00\n","Epoch 113/120\n","2/2 [==============================] - 0s 44ms/step - loss: 0.0138 - accuracy: 0.0000e+00 - val_loss: 0.3094 - val_accuracy: 0.0000e+00\n","Epoch 114/120\n","2/2 [==============================] - 0s 37ms/step - loss: 0.0171 - accuracy: 0.0000e+00 - val_loss: 0.3094 - val_accuracy: 0.0000e+00\n","Epoch 115/120\n","2/2 [==============================] - 0s 40ms/step - loss: 0.0146 - accuracy: 0.0000e+00 - val_loss: 0.3112 - val_accuracy: 0.0000e+00\n","Epoch 116/120\n","2/2 [==============================] - 0s 41ms/step - loss: 0.0155 - accuracy: 0.0000e+00 - val_loss: 0.3143 - val_accuracy: 0.0000e+00\n","Epoch 117/120\n","2/2 [==============================] - 0s 38ms/step - loss: 0.0126 - accuracy: 0.0060 - val_loss: 0.3153 - val_accuracy: 0.0000e+00\n","Epoch 118/120\n","2/2 [==============================] - 0s 43ms/step - loss: 0.0156 - accuracy: 0.0120 - val_loss: 0.3199 - val_accuracy: 0.0000e+00\n","Epoch 119/120\n","2/2 [==============================] - 0s 41ms/step - loss: 0.0141 - accuracy: 0.0120 - val_loss: 0.3360 - val_accuracy: 0.0000e+00\n","Epoch 120/120\n","2/2 [==============================] - 0s 38ms/step - loss: 0.0186 - accuracy: 0.0060 - val_loss: 0.3445 - val_accuracy: 0.0000e+00\n","--------------------------------------------------------------------------------\n","--------------------------------------------------------------------------------\n","7 ------ Running_water 143\n","X_train shape: \n","(228, 216, 13)\n","Model: \"sequential_7\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","conv2d_14 (Conv2D)           (None, 214, 11, 128)      1280      \n","_________________________________________________________________\n","max_pooling2d_14 (MaxPooling (None, 107, 6, 128)       0         \n","_________________________________________________________________\n","batch_normalization_14 (Batc (None, 107, 6, 128)       512       \n","_________________________________________________________________\n","conv2d_15 (Conv2D)           (None, 105, 4, 128)       147584    \n","_________________________________________________________________\n","max_pooling2d_15 (MaxPooling (None, 53, 2, 128)        0         \n","_________________________________________________________________\n","batch_normalization_15 (Batc (None, 53, 2, 128)        512       \n","_________________________________________________________________\n","flatten_7 (Flatten)          (None, 13568)             0         \n","_________________________________________________________________\n","dense_14 (Dense)             (None, 256)               3473664   \n","_________________________________________________________________\n","dropout_7 (Dropout)          (None, 256)               0         \n","_________________________________________________________________\n","dense_15 (Dense)             (None, 216)               55512     \n","=================================================================\n","Total params: 3,679,064\n","Trainable params: 3,678,552\n","Non-trainable params: 512\n","_________________________________________________________________\n","Epoch 1/120\n","2/2 [==============================] - 2s 2s/step - loss: 0.8268 - accuracy: 0.0110 - val_loss: 2.2576 - val_accuracy: 0.0000e+00\n","Epoch 2/120\n","2/2 [==============================] - 0s 45ms/step - loss: 0.6806 - accuracy: 0.0000e+00 - val_loss: 1.7050 - val_accuracy: 0.0000e+00\n","Epoch 3/120\n","2/2 [==============================] - 0s 42ms/step - loss: 0.6382 - accuracy: 0.0055 - val_loss: 2.0052 - val_accuracy: 0.0217\n","Epoch 4/120\n","2/2 [==============================] - 0s 44ms/step - loss: 0.6030 - accuracy: 0.0055 - val_loss: 2.0722 - val_accuracy: 0.0000e+00\n","Epoch 5/120\n","2/2 [==============================] - 0s 42ms/step - loss: 0.5482 - accuracy: 0.0000e+00 - val_loss: 2.4985 - val_accuracy: 0.0000e+00\n","Epoch 6/120\n","2/2 [==============================] - 0s 43ms/step - loss: 0.5036 - accuracy: 0.0000e+00 - val_loss: 2.9224 - val_accuracy: 0.0000e+00\n","Epoch 7/120\n","2/2 [==============================] - 0s 40ms/step - loss: 0.4546 - accuracy: 0.0000e+00 - val_loss: 3.8704 - val_accuracy: 0.0000e+00\n","Epoch 8/120\n","2/2 [==============================] - 0s 41ms/step - loss: 0.4001 - accuracy: 0.0000e+00 - val_loss: 3.8323 - val_accuracy: 0.0000e+00\n","Epoch 9/120\n","2/2 [==============================] - 0s 42ms/step - loss: 0.3591 - accuracy: 0.0000e+00 - val_loss: 4.4450 - val_accuracy: 0.0000e+00\n","Epoch 10/120\n","2/2 [==============================] - 0s 40ms/step - loss: 0.3142 - accuracy: 0.0055 - val_loss: 4.6589 - val_accuracy: 0.0217\n","Epoch 11/120\n","2/2 [==============================] - 0s 39ms/step - loss: 0.2778 - accuracy: 0.0000e+00 - val_loss: 4.6432 - val_accuracy: 0.0000e+00\n","Epoch 12/120\n","2/2 [==============================] - 0s 41ms/step - loss: 0.2520 - accuracy: 0.0000e+00 - val_loss: 5.0052 - val_accuracy: 0.0000e+00\n","Epoch 13/120\n","2/2 [==============================] - 0s 40ms/step - loss: 0.2207 - accuracy: 0.0000e+00 - val_loss: 5.1519 - val_accuracy: 0.0000e+00\n","Epoch 14/120\n","2/2 [==============================] - 0s 41ms/step - loss: 0.2047 - accuracy: 0.0000e+00 - val_loss: 4.7080 - val_accuracy: 0.0000e+00\n","Epoch 15/120\n","2/2 [==============================] - 0s 44ms/step - loss: 0.1793 - accuracy: 0.0000e+00 - val_loss: 4.1998 - val_accuracy: 0.0000e+00\n","Epoch 16/120\n","2/2 [==============================] - 0s 41ms/step - loss: 0.1739 - accuracy: 0.0000e+00 - val_loss: 4.8325 - val_accuracy: 0.0000e+00\n","Epoch 17/120\n","2/2 [==============================] - 0s 44ms/step - loss: 0.1494 - accuracy: 0.0110 - val_loss: 5.6479 - val_accuracy: 0.0000e+00\n","Epoch 18/120\n","2/2 [==============================] - 0s 43ms/step - loss: 0.1561 - accuracy: 0.0000e+00 - val_loss: 5.0215 - val_accuracy: 0.0000e+00\n","Epoch 19/120\n","2/2 [==============================] - 0s 43ms/step - loss: 0.1318 - accuracy: 0.0000e+00 - val_loss: 4.7944 - val_accuracy: 0.0000e+00\n","Epoch 20/120\n","2/2 [==============================] - 0s 46ms/step - loss: 0.1259 - accuracy: 0.0110 - val_loss: 5.0131 - val_accuracy: 0.0000e+00\n","Epoch 21/120\n","2/2 [==============================] - 0s 42ms/step - loss: 0.1167 - accuracy: 0.0110 - val_loss: 4.9931 - val_accuracy: 0.0000e+00\n","Epoch 22/120\n","2/2 [==============================] - 0s 45ms/step - loss: 0.1079 - accuracy: 0.0000e+00 - val_loss: 4.7837 - val_accuracy: 0.0000e+00\n","Epoch 23/120\n","2/2 [==============================] - 0s 49ms/step - loss: 0.0954 - accuracy: 0.0000e+00 - val_loss: 4.5242 - val_accuracy: 0.0000e+00\n","Epoch 24/120\n","2/2 [==============================] - 0s 44ms/step - loss: 0.0952 - accuracy: 0.0110 - val_loss: 4.1689 - val_accuracy: 0.0000e+00\n","Epoch 25/120\n","2/2 [==============================] - 0s 40ms/step - loss: 0.0850 - accuracy: 0.0110 - val_loss: 4.1684 - val_accuracy: 0.0000e+00\n","Epoch 26/120\n","2/2 [==============================] - 0s 41ms/step - loss: 0.0791 - accuracy: 0.0220 - val_loss: 4.4075 - val_accuracy: 0.0000e+00\n","Epoch 27/120\n","2/2 [==============================] - 0s 51ms/step - loss: 0.0767 - accuracy: 0.0110 - val_loss: 4.0773 - val_accuracy: 0.0000e+00\n","Epoch 28/120\n","2/2 [==============================] - 0s 41ms/step - loss: 0.0736 - accuracy: 0.0110 - val_loss: 3.6439 - val_accuracy: 0.0000e+00\n","Epoch 29/120\n","2/2 [==============================] - 0s 44ms/step - loss: 0.0744 - accuracy: 0.0110 - val_loss: 3.7014 - val_accuracy: 0.0000e+00\n","Epoch 30/120\n","2/2 [==============================] - 0s 41ms/step - loss: 0.0648 - accuracy: 0.0000e+00 - val_loss: 3.7344 - val_accuracy: 0.0000e+00\n","Epoch 31/120\n","2/2 [==============================] - 0s 40ms/step - loss: 0.0674 - accuracy: 0.0110 - val_loss: 3.4097 - val_accuracy: 0.0000e+00\n","Epoch 32/120\n","2/2 [==============================] - 0s 44ms/step - loss: 0.0574 - accuracy: 0.0110 - val_loss: 2.9808 - val_accuracy: 0.0000e+00\n","Epoch 33/120\n","2/2 [==============================] - 0s 42ms/step - loss: 0.0596 - accuracy: 0.0000e+00 - val_loss: 2.9391 - val_accuracy: 0.0000e+00\n","Epoch 34/120\n","2/2 [==============================] - 0s 39ms/step - loss: 0.0562 - accuracy: 0.0055 - val_loss: 3.2104 - val_accuracy: 0.0000e+00\n","Epoch 35/120\n","2/2 [==============================] - 0s 43ms/step - loss: 0.0515 - accuracy: 0.0220 - val_loss: 3.0627 - val_accuracy: 0.0000e+00\n","Epoch 36/120\n","2/2 [==============================] - 0s 42ms/step - loss: 0.0580 - accuracy: 0.0110 - val_loss: 2.3414 - val_accuracy: 0.0000e+00\n","Epoch 37/120\n","2/2 [==============================] - 0s 45ms/step - loss: 0.0514 - accuracy: 0.0220 - val_loss: 2.0517 - val_accuracy: 0.0000e+00\n","Epoch 38/120\n","2/2 [==============================] - 0s 54ms/step - loss: 0.0499 - accuracy: 0.0220 - val_loss: 2.2547 - val_accuracy: 0.0000e+00\n","Epoch 39/120\n","2/2 [==============================] - 0s 43ms/step - loss: 0.0455 - accuracy: 0.0055 - val_loss: 2.3689 - val_accuracy: 0.0000e+00\n","Epoch 40/120\n","2/2 [==============================] - 0s 39ms/step - loss: 0.0462 - accuracy: 0.0165 - val_loss: 2.4353 - val_accuracy: 0.0000e+00\n","Epoch 41/120\n","2/2 [==============================] - 0s 44ms/step - loss: 0.0408 - accuracy: 0.0110 - val_loss: 2.4508 - val_accuracy: 0.0000e+00\n","Epoch 42/120\n","2/2 [==============================] - 0s 48ms/step - loss: 0.0419 - accuracy: 0.0000e+00 - val_loss: 2.2117 - val_accuracy: 0.0000e+00\n","Epoch 43/120\n","2/2 [==============================] - 0s 43ms/step - loss: 0.0355 - accuracy: 0.0110 - val_loss: 1.9290 - val_accuracy: 0.0000e+00\n","Epoch 44/120\n","2/2 [==============================] - 0s 41ms/step - loss: 0.0401 - accuracy: 0.0110 - val_loss: 1.6950 - val_accuracy: 0.0000e+00\n","Epoch 45/120\n","2/2 [==============================] - 0s 43ms/step - loss: 0.0341 - accuracy: 0.0220 - val_loss: 1.7271 - val_accuracy: 0.0000e+00\n","Epoch 46/120\n","2/2 [==============================] - 0s 45ms/step - loss: 0.0331 - accuracy: 0.0330 - val_loss: 1.9048 - val_accuracy: 0.0000e+00\n","Epoch 47/120\n","2/2 [==============================] - 0s 40ms/step - loss: 0.0362 - accuracy: 0.0110 - val_loss: 1.8942 - val_accuracy: 0.0000e+00\n","Epoch 48/120\n","2/2 [==============================] - 0s 42ms/step - loss: 0.0290 - accuracy: 0.0110 - val_loss: 1.5968 - val_accuracy: 0.0000e+00\n","Epoch 49/120\n","2/2 [==============================] - 0s 39ms/step - loss: 0.0288 - accuracy: 0.0110 - val_loss: 1.3118 - val_accuracy: 0.0000e+00\n","Epoch 50/120\n","2/2 [==============================] - 0s 43ms/step - loss: 0.0247 - accuracy: 0.0110 - val_loss: 1.1859 - val_accuracy: 0.0000e+00\n","Epoch 51/120\n","2/2 [==============================] - 0s 44ms/step - loss: 0.0269 - accuracy: 0.0165 - val_loss: 1.2326 - val_accuracy: 0.0000e+00\n","Epoch 52/120\n","2/2 [==============================] - 0s 47ms/step - loss: 0.0231 - accuracy: 0.0110 - val_loss: 1.3364 - val_accuracy: 0.0000e+00\n","Epoch 53/120\n","2/2 [==============================] - 0s 47ms/step - loss: 0.0247 - accuracy: 0.0110 - val_loss: 1.4391 - val_accuracy: 0.0000e+00\n","Epoch 54/120\n","2/2 [==============================] - 0s 43ms/step - loss: 0.0241 - accuracy: 0.0055 - val_loss: 1.4298 - val_accuracy: 0.0000e+00\n","Epoch 55/120\n","2/2 [==============================] - 0s 42ms/step - loss: 0.0230 - accuracy: 0.0000e+00 - val_loss: 1.3014 - val_accuracy: 0.0000e+00\n","Epoch 56/120\n","2/2 [==============================] - 0s 41ms/step - loss: 0.0220 - accuracy: 0.0055 - val_loss: 1.1123 - val_accuracy: 0.0000e+00\n","Epoch 57/120\n","2/2 [==============================] - 0s 42ms/step - loss: 0.0215 - accuracy: 0.0055 - val_loss: 0.9823 - val_accuracy: 0.0000e+00\n","Epoch 58/120\n","2/2 [==============================] - 0s 41ms/step - loss: 0.0215 - accuracy: 0.0165 - val_loss: 0.9614 - val_accuracy: 0.0000e+00\n","Epoch 59/120\n","2/2 [==============================] - 0s 41ms/step - loss: 0.0197 - accuracy: 0.0275 - val_loss: 1.0193 - val_accuracy: 0.0000e+00\n","Epoch 60/120\n","2/2 [==============================] - 0s 40ms/step - loss: 0.0197 - accuracy: 0.0110 - val_loss: 1.0183 - val_accuracy: 0.0000e+00\n","Epoch 61/120\n","2/2 [==============================] - 0s 43ms/step - loss: 0.0173 - accuracy: 0.0165 - val_loss: 1.0061 - val_accuracy: 0.0000e+00\n","Epoch 62/120\n","2/2 [==============================] - 0s 39ms/step - loss: 0.0224 - accuracy: 0.0220 - val_loss: 1.0094 - val_accuracy: 0.0000e+00\n","Epoch 63/120\n","2/2 [==============================] - 0s 41ms/step - loss: 0.0178 - accuracy: 0.0220 - val_loss: 0.9976 - val_accuracy: 0.0000e+00\n","Epoch 64/120\n","2/2 [==============================] - 0s 40ms/step - loss: 0.0190 - accuracy: 0.0165 - val_loss: 0.9776 - val_accuracy: 0.0000e+00\n","Epoch 65/120\n","2/2 [==============================] - 0s 50ms/step - loss: 0.0180 - accuracy: 0.0055 - val_loss: 0.9901 - val_accuracy: 0.0000e+00\n","Epoch 66/120\n","2/2 [==============================] - 0s 42ms/step - loss: 0.0166 - accuracy: 0.0275 - val_loss: 0.9942 - val_accuracy: 0.0000e+00\n","Epoch 67/120\n","2/2 [==============================] - 0s 41ms/step - loss: 0.0177 - accuracy: 0.0275 - val_loss: 1.0131 - val_accuracy: 0.0000e+00\n","Epoch 68/120\n","2/2 [==============================] - 0s 41ms/step - loss: 0.0134 - accuracy: 0.0000e+00 - val_loss: 1.0529 - val_accuracy: 0.0000e+00\n","Epoch 69/120\n","2/2 [==============================] - 0s 44ms/step - loss: 0.0193 - accuracy: 0.0110 - val_loss: 1.0972 - val_accuracy: 0.0000e+00\n","Epoch 70/120\n","2/2 [==============================] - 0s 43ms/step - loss: 0.0156 - accuracy: 0.0055 - val_loss: 1.1054 - val_accuracy: 0.0000e+00\n","Epoch 71/120\n","2/2 [==============================] - 0s 40ms/step - loss: 0.0132 - accuracy: 0.0165 - val_loss: 1.1008 - val_accuracy: 0.0000e+00\n","Epoch 72/120\n","2/2 [==============================] - 0s 41ms/step - loss: 0.0159 - accuracy: 0.0220 - val_loss: 1.0787 - val_accuracy: 0.0000e+00\n","Epoch 73/120\n","2/2 [==============================] - 0s 40ms/step - loss: 0.0128 - accuracy: 0.0055 - val_loss: 1.0068 - val_accuracy: 0.0000e+00\n","Epoch 74/120\n","2/2 [==============================] - 0s 46ms/step - loss: 0.0135 - accuracy: 0.0165 - val_loss: 0.9356 - val_accuracy: 0.0000e+00\n","Epoch 75/120\n","2/2 [==============================] - 0s 43ms/step - loss: 0.0169 - accuracy: 0.0220 - val_loss: 0.8708 - val_accuracy: 0.0000e+00\n","Epoch 76/120\n","2/2 [==============================] - 0s 44ms/step - loss: 0.0147 - accuracy: 0.0055 - val_loss: 0.8210 - val_accuracy: 0.0000e+00\n","Epoch 77/120\n","2/2 [==============================] - 0s 41ms/step - loss: 0.0120 - accuracy: 0.0220 - val_loss: 0.8069 - val_accuracy: 0.0000e+00\n","Epoch 78/120\n","2/2 [==============================] - 0s 47ms/step - loss: 0.0134 - accuracy: 0.0110 - val_loss: 0.7966 - val_accuracy: 0.0000e+00\n","Epoch 79/120\n","2/2 [==============================] - 0s 43ms/step - loss: 0.0123 - accuracy: 0.0385 - val_loss: 0.8260 - val_accuracy: 0.0000e+00\n","Epoch 80/120\n","2/2 [==============================] - 0s 43ms/step - loss: 0.0125 - accuracy: 0.0275 - val_loss: 0.8423 - val_accuracy: 0.0000e+00\n","Epoch 81/120\n","2/2 [==============================] - 0s 43ms/step - loss: 0.0118 - accuracy: 0.0110 - val_loss: 0.8182 - val_accuracy: 0.0000e+00\n","Epoch 82/120\n","2/2 [==============================] - 0s 39ms/step - loss: 0.0112 - accuracy: 0.0055 - val_loss: 0.7707 - val_accuracy: 0.0000e+00\n","Epoch 83/120\n","2/2 [==============================] - 0s 42ms/step - loss: 0.0109 - accuracy: 0.0385 - val_loss: 0.7245 - val_accuracy: 0.0000e+00\n","Epoch 84/120\n","2/2 [==============================] - 0s 42ms/step - loss: 0.0107 - accuracy: 0.0165 - val_loss: 0.7305 - val_accuracy: 0.0000e+00\n","Epoch 85/120\n","2/2 [==============================] - 0s 40ms/step - loss: 0.0146 - accuracy: 0.0275 - val_loss: 0.7964 - val_accuracy: 0.0000e+00\n","Epoch 86/120\n","2/2 [==============================] - 0s 47ms/step - loss: 0.0113 - accuracy: 0.0330 - val_loss: 0.8474 - val_accuracy: 0.0000e+00\n","Epoch 87/120\n","2/2 [==============================] - 0s 48ms/step - loss: 0.0114 - accuracy: 0.0110 - val_loss: 0.8517 - val_accuracy: 0.0000e+00\n","Epoch 88/120\n","2/2 [==============================] - 0s 44ms/step - loss: 0.0103 - accuracy: 0.0165 - val_loss: 0.8472 - val_accuracy: 0.0000e+00\n","Epoch 89/120\n","2/2 [==============================] - 0s 41ms/step - loss: 0.0141 - accuracy: 0.0165 - val_loss: 0.8170 - val_accuracy: 0.0000e+00\n","Epoch 90/120\n","2/2 [==============================] - 0s 43ms/step - loss: 0.0127 - accuracy: 0.0220 - val_loss: 0.8362 - val_accuracy: 0.0000e+00\n","Epoch 91/120\n","2/2 [==============================] - 0s 47ms/step - loss: 0.0128 - accuracy: 0.0165 - val_loss: 0.8159 - val_accuracy: 0.0000e+00\n","Epoch 92/120\n","2/2 [==============================] - 0s 48ms/step - loss: 0.0104 - accuracy: 0.0165 - val_loss: 0.7750 - val_accuracy: 0.0000e+00\n","Epoch 93/120\n","2/2 [==============================] - 0s 46ms/step - loss: 0.0100 - accuracy: 0.0110 - val_loss: 0.7009 - val_accuracy: 0.0000e+00\n","Epoch 94/120\n","2/2 [==============================] - 0s 44ms/step - loss: 0.0118 - accuracy: 0.0165 - val_loss: 0.6155 - val_accuracy: 0.0000e+00\n","Epoch 95/120\n","2/2 [==============================] - 0s 64ms/step - loss: 0.0078 - accuracy: 0.0275 - val_loss: 0.5532 - val_accuracy: 0.0217\n","Epoch 96/120\n","2/2 [==============================] - 0s 48ms/step - loss: 0.0125 - accuracy: 0.0055 - val_loss: 0.5140 - val_accuracy: 0.0217\n","Epoch 97/120\n","2/2 [==============================] - 0s 76ms/step - loss: 0.0098 - accuracy: 0.0220 - val_loss: 0.4966 - val_accuracy: 0.0217\n","Epoch 98/120\n","2/2 [==============================] - 0s 55ms/step - loss: 0.0106 - accuracy: 0.0165 - val_loss: 0.5080 - val_accuracy: 0.0000e+00\n","Epoch 99/120\n","2/2 [==============================] - 0s 58ms/step - loss: 0.0110 - accuracy: 0.0549 - val_loss: 0.5413 - val_accuracy: 0.0000e+00\n","Epoch 100/120\n","2/2 [==============================] - 0s 52ms/step - loss: 0.0093 - accuracy: 0.0165 - val_loss: 0.5994 - val_accuracy: 0.0000e+00\n","Epoch 101/120\n","2/2 [==============================] - 0s 46ms/step - loss: 0.0092 - accuracy: 0.0165 - val_loss: 0.6442 - val_accuracy: 0.0000e+00\n","Epoch 102/120\n","2/2 [==============================] - 0s 44ms/step - loss: 0.0097 - accuracy: 0.0220 - val_loss: 0.6408 - val_accuracy: 0.0000e+00\n","Epoch 103/120\n","2/2 [==============================] - 0s 46ms/step - loss: 0.0109 - accuracy: 0.0110 - val_loss: 0.6150 - val_accuracy: 0.0000e+00\n","Epoch 104/120\n","2/2 [==============================] - 0s 43ms/step - loss: 0.0085 - accuracy: 0.0165 - val_loss: 0.5978 - val_accuracy: 0.0000e+00\n","Epoch 105/120\n","2/2 [==============================] - 0s 39ms/step - loss: 0.0090 - accuracy: 0.0165 - val_loss: 0.5850 - val_accuracy: 0.0000e+00\n","Epoch 106/120\n","2/2 [==============================] - 0s 42ms/step - loss: 0.0065 - accuracy: 0.0330 - val_loss: 0.5803 - val_accuracy: 0.0000e+00\n","Epoch 107/120\n","2/2 [==============================] - 0s 40ms/step - loss: 0.0075 - accuracy: 0.0055 - val_loss: 0.5985 - val_accuracy: 0.0000e+00\n","Epoch 108/120\n","2/2 [==============================] - 0s 49ms/step - loss: 0.0086 - accuracy: 0.0110 - val_loss: 0.6099 - val_accuracy: 0.0000e+00\n","Epoch 109/120\n","2/2 [==============================] - 0s 46ms/step - loss: 0.0091 - accuracy: 0.0165 - val_loss: 0.6314 - val_accuracy: 0.0000e+00\n","Epoch 110/120\n","2/2 [==============================] - 0s 44ms/step - loss: 0.0091 - accuracy: 0.0165 - val_loss: 0.6418 - val_accuracy: 0.0000e+00\n","Epoch 111/120\n","2/2 [==============================] - 0s 43ms/step - loss: 0.0096 - accuracy: 0.0055 - val_loss: 0.6413 - val_accuracy: 0.0000e+00\n","Epoch 112/120\n","2/2 [==============================] - 0s 47ms/step - loss: 0.0072 - accuracy: 0.0220 - val_loss: 0.6625 - val_accuracy: 0.0000e+00\n","Epoch 113/120\n","2/2 [==============================] - 0s 44ms/step - loss: 0.0068 - accuracy: 0.0055 - val_loss: 0.6581 - val_accuracy: 0.0000e+00\n","Epoch 114/120\n","2/2 [==============================] - 0s 45ms/step - loss: 0.0060 - accuracy: 0.0110 - val_loss: 0.6401 - val_accuracy: 0.0000e+00\n","Epoch 115/120\n","2/2 [==============================] - 0s 52ms/step - loss: 0.0076 - accuracy: 0.0110 - val_loss: 0.6403 - val_accuracy: 0.0000e+00\n","Epoch 116/120\n","2/2 [==============================] - 0s 47ms/step - loss: 0.0057 - accuracy: 0.0165 - val_loss: 0.6430 - val_accuracy: 0.0000e+00\n","Epoch 117/120\n","2/2 [==============================] - 0s 47ms/step - loss: 0.0086 - accuracy: 0.0055 - val_loss: 0.6352 - val_accuracy: 0.0000e+00\n","Epoch 118/120\n","2/2 [==============================] - 0s 44ms/step - loss: 0.0070 - accuracy: 0.0055 - val_loss: 0.6292 - val_accuracy: 0.0000e+00\n","Epoch 119/120\n","2/2 [==============================] - 0s 45ms/step - loss: 0.0068 - accuracy: 0.0220 - val_loss: 0.6265 - val_accuracy: 0.0000e+00\n","Epoch 120/120\n","2/2 [==============================] - 0s 44ms/step - loss: 0.0056 - accuracy: 0.0110 - val_loss: 0.6236 - val_accuracy: 0.0000e+00\n","--------------------------------------------------------------------------------\n","--------------------------------------------------------------------------------\n","8 ------ Speech 1272\n","X_train shape: \n","(2034, 216, 13)\n","Model: \"sequential_8\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","conv2d_16 (Conv2D)           (None, 214, 11, 128)      1280      \n","_________________________________________________________________\n","max_pooling2d_16 (MaxPooling (None, 107, 6, 128)       0         \n","_________________________________________________________________\n","batch_normalization_16 (Batc (None, 107, 6, 128)       512       \n","_________________________________________________________________\n","conv2d_17 (Conv2D)           (None, 105, 4, 128)       147584    \n","_________________________________________________________________\n","max_pooling2d_17 (MaxPooling (None, 53, 2, 128)        0         \n","_________________________________________________________________\n","batch_normalization_17 (Batc (None, 53, 2, 128)        512       \n","_________________________________________________________________\n","flatten_8 (Flatten)          (None, 13568)             0         \n","_________________________________________________________________\n","dense_16 (Dense)             (None, 256)               3473664   \n","_________________________________________________________________\n","dropout_8 (Dropout)          (None, 256)               0         \n","_________________________________________________________________\n","dense_17 (Dense)             (None, 216)               55512     \n","=================================================================\n","Total params: 3,679,064\n","Trainable params: 3,678,552\n","Non-trainable params: 512\n","_________________________________________________________________\n","Epoch 1/120\n","13/13 [==============================] - 2s 145ms/step - loss: 0.6335 - accuracy: 0.0055 - val_loss: 2.0188 - val_accuracy: 0.0000e+00\n","Epoch 2/120\n","13/13 [==============================] - 0s 37ms/step - loss: 0.4553 - accuracy: 0.0098 - val_loss: 0.9147 - val_accuracy: 0.0025\n","Epoch 3/120\n","13/13 [==============================] - 0s 33ms/step - loss: 0.3810 - accuracy: 0.0086 - val_loss: 0.7507 - val_accuracy: 0.0074\n","Epoch 4/120\n","13/13 [==============================] - 0s 33ms/step - loss: 0.3201 - accuracy: 0.0074 - val_loss: 0.4179 - val_accuracy: 0.0049\n","Epoch 5/120\n","13/13 [==============================] - 0s 34ms/step - loss: 0.2790 - accuracy: 0.0080 - val_loss: 0.3428 - val_accuracy: 0.0049\n","Epoch 6/120\n","13/13 [==============================] - 0s 34ms/step - loss: 0.2405 - accuracy: 0.0111 - val_loss: 0.3047 - val_accuracy: 0.0025\n","Epoch 7/120\n","13/13 [==============================] - 0s 36ms/step - loss: 0.2082 - accuracy: 0.0098 - val_loss: 0.2845 - val_accuracy: 0.0049\n","Epoch 8/120\n","13/13 [==============================] - 0s 34ms/step - loss: 0.1842 - accuracy: 0.0129 - val_loss: 0.2667 - val_accuracy: 0.0025\n","Epoch 9/120\n","13/13 [==============================] - 0s 35ms/step - loss: 0.1649 - accuracy: 0.0092 - val_loss: 0.2613 - val_accuracy: 0.0025\n","Epoch 10/120\n","13/13 [==============================] - 0s 32ms/step - loss: 0.1463 - accuracy: 0.0117 - val_loss: 0.2705 - val_accuracy: 0.0049\n","Epoch 11/120\n","13/13 [==============================] - 0s 34ms/step - loss: 0.1346 - accuracy: 0.0098 - val_loss: 0.2460 - val_accuracy: 0.0025\n","Epoch 12/120\n","13/13 [==============================] - 0s 32ms/step - loss: 0.1207 - accuracy: 0.0092 - val_loss: 0.2572 - val_accuracy: 0.0049\n","Epoch 13/120\n","13/13 [==============================] - 0s 35ms/step - loss: 0.1096 - accuracy: 0.0154 - val_loss: 0.2442 - val_accuracy: 0.0098\n","Epoch 14/120\n","13/13 [==============================] - 0s 35ms/step - loss: 0.1001 - accuracy: 0.0123 - val_loss: 0.2381 - val_accuracy: 0.0147\n","Epoch 15/120\n","13/13 [==============================] - 0s 34ms/step - loss: 0.0924 - accuracy: 0.0129 - val_loss: 0.2462 - val_accuracy: 0.0025\n","Epoch 16/120\n","13/13 [==============================] - 0s 35ms/step - loss: 0.0872 - accuracy: 0.0111 - val_loss: 0.2279 - val_accuracy: 0.0000e+00\n","Epoch 17/120\n","13/13 [==============================] - 0s 33ms/step - loss: 0.0816 - accuracy: 0.0166 - val_loss: 0.2406 - val_accuracy: 0.0025\n","Epoch 18/120\n","13/13 [==============================] - 0s 36ms/step - loss: 0.0791 - accuracy: 0.0148 - val_loss: 0.2336 - val_accuracy: 0.0049\n","Epoch 19/120\n","13/13 [==============================] - 0s 35ms/step - loss: 0.0751 - accuracy: 0.0080 - val_loss: 0.2423 - val_accuracy: 0.0025\n","Epoch 20/120\n","13/13 [==============================] - 0s 35ms/step - loss: 0.0717 - accuracy: 0.0135 - val_loss: 0.2543 - val_accuracy: 0.0000e+00\n","Epoch 21/120\n","13/13 [==============================] - 0s 32ms/step - loss: 0.0671 - accuracy: 0.0148 - val_loss: 0.2497 - val_accuracy: 0.0049\n","Epoch 22/120\n","13/13 [==============================] - 0s 35ms/step - loss: 0.0629 - accuracy: 0.0166 - val_loss: 0.2444 - val_accuracy: 0.0049\n","Epoch 23/120\n","13/13 [==============================] - 0s 37ms/step - loss: 0.0632 - accuracy: 0.0172 - val_loss: 0.2632 - val_accuracy: 0.0098\n","Epoch 24/120\n","13/13 [==============================] - 0s 33ms/step - loss: 0.0618 - accuracy: 0.0184 - val_loss: 0.2474 - val_accuracy: 0.0049\n","Epoch 25/120\n","13/13 [==============================] - 0s 34ms/step - loss: 0.0576 - accuracy: 0.0148 - val_loss: 0.2608 - val_accuracy: 0.0025\n","Epoch 26/120\n","13/13 [==============================] - 0s 34ms/step - loss: 0.0559 - accuracy: 0.0178 - val_loss: 0.2760 - val_accuracy: 0.0123\n","Epoch 27/120\n","13/13 [==============================] - 0s 34ms/step - loss: 0.0542 - accuracy: 0.0203 - val_loss: 0.2802 - val_accuracy: 0.0074\n","Epoch 28/120\n","13/13 [==============================] - 0s 34ms/step - loss: 0.0546 - accuracy: 0.0129 - val_loss: 0.2708 - val_accuracy: 0.0000e+00\n","Epoch 29/120\n","13/13 [==============================] - 0s 34ms/step - loss: 0.0513 - accuracy: 0.0117 - val_loss: 0.2939 - val_accuracy: 0.0000e+00\n","Epoch 30/120\n","13/13 [==============================] - 0s 35ms/step - loss: 0.0483 - accuracy: 0.0074 - val_loss: 0.2778 - val_accuracy: 0.0246\n","Epoch 31/120\n","13/13 [==============================] - 0s 34ms/step - loss: 0.0492 - accuracy: 0.0154 - val_loss: 0.2648 - val_accuracy: 0.0221\n","Epoch 32/120\n","13/13 [==============================] - 0s 33ms/step - loss: 0.0470 - accuracy: 0.0111 - val_loss: 0.2734 - val_accuracy: 0.0074\n","Epoch 33/120\n","13/13 [==============================] - 0s 34ms/step - loss: 0.0465 - accuracy: 0.0135 - val_loss: 0.2682 - val_accuracy: 0.0418\n","Epoch 34/120\n","13/13 [==============================] - 0s 34ms/step - loss: 0.0428 - accuracy: 0.0191 - val_loss: 0.2630 - val_accuracy: 0.0172\n","Epoch 35/120\n","13/13 [==============================] - 0s 34ms/step - loss: 0.0421 - accuracy: 0.0154 - val_loss: 0.3097 - val_accuracy: 0.0295\n","Epoch 36/120\n","13/13 [==============================] - 0s 35ms/step - loss: 0.0417 - accuracy: 0.0123 - val_loss: 0.2832 - val_accuracy: 0.0049\n","Epoch 37/120\n","13/13 [==============================] - 0s 35ms/step - loss: 0.0407 - accuracy: 0.0129 - val_loss: 0.2882 - val_accuracy: 0.0049\n","Epoch 38/120\n","13/13 [==============================] - 0s 35ms/step - loss: 0.0373 - accuracy: 0.0098 - val_loss: 0.2908 - val_accuracy: 0.0025\n","Epoch 39/120\n","13/13 [==============================] - 0s 33ms/step - loss: 0.0375 - accuracy: 0.0104 - val_loss: 0.3084 - val_accuracy: 0.0025\n","Epoch 40/120\n","13/13 [==============================] - 0s 33ms/step - loss: 0.0378 - accuracy: 0.0148 - val_loss: 0.3097 - val_accuracy: 0.0319\n","Epoch 41/120\n","13/13 [==============================] - 0s 34ms/step - loss: 0.0360 - accuracy: 0.0234 - val_loss: 0.2804 - val_accuracy: 0.0123\n","Epoch 42/120\n","13/13 [==============================] - 0s 34ms/step - loss: 0.0371 - accuracy: 0.0148 - val_loss: 0.2988 - val_accuracy: 0.0123\n","Epoch 43/120\n","13/13 [==============================] - 0s 34ms/step - loss: 0.0338 - accuracy: 0.0166 - val_loss: 0.2998 - val_accuracy: 0.0147\n","Epoch 44/120\n","13/13 [==============================] - 0s 34ms/step - loss: 0.0341 - accuracy: 0.0141 - val_loss: 0.3316 - val_accuracy: 0.0197\n","Epoch 45/120\n","13/13 [==============================] - 0s 33ms/step - loss: 0.0343 - accuracy: 0.0098 - val_loss: 0.2936 - val_accuracy: 0.0025\n","Epoch 46/120\n","13/13 [==============================] - 0s 34ms/step - loss: 0.0322 - accuracy: 0.0111 - val_loss: 0.3290 - val_accuracy: 0.0098\n","Epoch 47/120\n","13/13 [==============================] - 0s 34ms/step - loss: 0.0312 - accuracy: 0.0301 - val_loss: 0.3081 - val_accuracy: 0.0025\n","Epoch 48/120\n","13/13 [==============================] - 0s 34ms/step - loss: 0.0315 - accuracy: 0.0123 - val_loss: 0.3165 - val_accuracy: 0.0000e+00\n","Epoch 49/120\n","13/13 [==============================] - 0s 32ms/step - loss: 0.0304 - accuracy: 0.0061 - val_loss: 0.3145 - val_accuracy: 0.0000e+00\n","Epoch 50/120\n","13/13 [==============================] - 0s 34ms/step - loss: 0.0295 - accuracy: 0.0098 - val_loss: 0.3243 - val_accuracy: 0.0123\n","Epoch 51/120\n","13/13 [==============================] - 0s 32ms/step - loss: 0.0295 - accuracy: 0.0184 - val_loss: 0.3325 - val_accuracy: 0.0246\n","Epoch 52/120\n","13/13 [==============================] - 0s 34ms/step - loss: 0.0281 - accuracy: 0.0172 - val_loss: 0.3172 - val_accuracy: 0.0098\n","Epoch 53/120\n","13/13 [==============================] - 0s 35ms/step - loss: 0.0295 - accuracy: 0.0178 - val_loss: 0.3294 - val_accuracy: 0.0074\n","Epoch 54/120\n","13/13 [==============================] - 0s 37ms/step - loss: 0.0281 - accuracy: 0.0160 - val_loss: 0.3260 - val_accuracy: 0.0098\n","Epoch 55/120\n","13/13 [==============================] - 0s 36ms/step - loss: 0.0282 - accuracy: 0.0154 - val_loss: 0.3388 - val_accuracy: 0.0049\n","Epoch 56/120\n","13/13 [==============================] - 0s 35ms/step - loss: 0.0261 - accuracy: 0.0148 - val_loss: 0.3604 - val_accuracy: 0.0025\n","Epoch 57/120\n","13/13 [==============================] - 0s 34ms/step - loss: 0.0260 - accuracy: 0.0111 - val_loss: 0.3289 - val_accuracy: 0.0049\n","Epoch 58/120\n","13/13 [==============================] - 0s 33ms/step - loss: 0.0253 - accuracy: 0.0184 - val_loss: 0.3301 - val_accuracy: 0.0221\n","Epoch 59/120\n","13/13 [==============================] - 0s 33ms/step - loss: 0.0247 - accuracy: 0.0117 - val_loss: 0.3579 - val_accuracy: 0.0221\n","Epoch 60/120\n","13/13 [==============================] - 0s 34ms/step - loss: 0.0257 - accuracy: 0.0172 - val_loss: 0.3186 - val_accuracy: 0.0221\n","Epoch 61/120\n","13/13 [==============================] - 0s 34ms/step - loss: 0.0272 - accuracy: 0.0252 - val_loss: 0.3665 - val_accuracy: 0.0270\n","Epoch 62/120\n","13/13 [==============================] - 0s 35ms/step - loss: 0.0262 - accuracy: 0.0203 - val_loss: 0.3613 - val_accuracy: 0.0123\n","Epoch 63/120\n","13/13 [==============================] - 0s 32ms/step - loss: 0.0280 - accuracy: 0.0148 - val_loss: 0.3221 - val_accuracy: 0.0049\n","Epoch 64/120\n","13/13 [==============================] - 0s 33ms/step - loss: 0.0255 - accuracy: 0.0154 - val_loss: 0.3251 - val_accuracy: 0.0123\n","Epoch 65/120\n","13/13 [==============================] - 0s 35ms/step - loss: 0.0266 - accuracy: 0.0148 - val_loss: 0.3061 - val_accuracy: 0.0074\n","Epoch 66/120\n","13/13 [==============================] - 0s 33ms/step - loss: 0.0244 - accuracy: 0.0104 - val_loss: 0.3337 - val_accuracy: 0.0172\n","Epoch 67/120\n","13/13 [==============================] - 0s 34ms/step - loss: 0.0248 - accuracy: 0.0270 - val_loss: 0.3269 - val_accuracy: 0.0344\n","Epoch 68/120\n","13/13 [==============================] - 0s 35ms/step - loss: 0.0222 - accuracy: 0.0129 - val_loss: 0.3689 - val_accuracy: 0.0074\n","Epoch 69/120\n","13/13 [==============================] - 0s 35ms/step - loss: 0.0235 - accuracy: 0.0111 - val_loss: 0.3506 - val_accuracy: 0.0369\n","Epoch 70/120\n","13/13 [==============================] - 0s 34ms/step - loss: 0.0220 - accuracy: 0.0117 - val_loss: 0.3436 - val_accuracy: 0.0049\n","Epoch 71/120\n","13/13 [==============================] - 0s 32ms/step - loss: 0.0211 - accuracy: 0.0080 - val_loss: 0.3534 - val_accuracy: 0.0000e+00\n","Epoch 72/120\n","13/13 [==============================] - 0s 33ms/step - loss: 0.0219 - accuracy: 0.0098 - val_loss: 0.3729 - val_accuracy: 0.0147\n","Epoch 73/120\n","13/13 [==============================] - 0s 32ms/step - loss: 0.0221 - accuracy: 0.0123 - val_loss: 0.3190 - val_accuracy: 0.0123\n","Epoch 74/120\n","13/13 [==============================] - 0s 34ms/step - loss: 0.0211 - accuracy: 0.0141 - val_loss: 0.3350 - val_accuracy: 0.0123\n","Epoch 75/120\n","13/13 [==============================] - 0s 34ms/step - loss: 0.0207 - accuracy: 0.0104 - val_loss: 0.3159 - val_accuracy: 0.0074\n","Epoch 76/120\n","13/13 [==============================] - 0s 34ms/step - loss: 0.0218 - accuracy: 0.0117 - val_loss: 0.3473 - val_accuracy: 0.0147\n","Epoch 77/120\n","13/13 [==============================] - 0s 33ms/step - loss: 0.0217 - accuracy: 0.0154 - val_loss: 0.3256 - val_accuracy: 0.0197\n","Epoch 78/120\n","13/13 [==============================] - 0s 35ms/step - loss: 0.0204 - accuracy: 0.0086 - val_loss: 0.3332 - val_accuracy: 0.0025\n","Epoch 79/120\n","13/13 [==============================] - 0s 34ms/step - loss: 0.0191 - accuracy: 0.0055 - val_loss: 0.3290 - val_accuracy: 0.0049\n","Epoch 80/120\n","13/13 [==============================] - 0s 34ms/step - loss: 0.0200 - accuracy: 0.0117 - val_loss: 0.3615 - val_accuracy: 0.0049\n","Epoch 81/120\n","13/13 [==============================] - 0s 33ms/step - loss: 0.0201 - accuracy: 0.0178 - val_loss: 0.3786 - val_accuracy: 0.0098\n","Epoch 82/120\n","13/13 [==============================] - 0s 35ms/step - loss: 0.0200 - accuracy: 0.0197 - val_loss: 0.3855 - val_accuracy: 0.0393\n","Epoch 83/120\n","13/13 [==============================] - 0s 34ms/step - loss: 0.0214 - accuracy: 0.0178 - val_loss: 0.3341 - val_accuracy: 0.0147\n","Epoch 84/120\n","13/13 [==============================] - 0s 34ms/step - loss: 0.0202 - accuracy: 0.0104 - val_loss: 0.3640 - val_accuracy: 0.0049\n","Epoch 85/120\n","13/13 [==============================] - 0s 35ms/step - loss: 0.0213 - accuracy: 0.0135 - val_loss: 0.3793 - val_accuracy: 0.0074\n","Epoch 86/120\n","13/13 [==============================] - 0s 34ms/step - loss: 0.0194 - accuracy: 0.0141 - val_loss: 0.3779 - val_accuracy: 0.0074\n","Epoch 87/120\n","13/13 [==============================] - 0s 33ms/step - loss: 0.0190 - accuracy: 0.0043 - val_loss: 0.4000 - val_accuracy: 0.0025\n","Epoch 88/120\n","13/13 [==============================] - 0s 34ms/step - loss: 0.0201 - accuracy: 0.0111 - val_loss: 0.3765 - val_accuracy: 0.0025\n","Epoch 89/120\n","13/13 [==============================] - 0s 33ms/step - loss: 0.0190 - accuracy: 0.0074 - val_loss: 0.3591 - val_accuracy: 0.0074\n","Epoch 90/120\n","13/13 [==============================] - 0s 35ms/step - loss: 0.0193 - accuracy: 0.0129 - val_loss: 0.3516 - val_accuracy: 0.0025\n","Epoch 91/120\n","13/13 [==============================] - 0s 34ms/step - loss: 0.0187 - accuracy: 0.0117 - val_loss: 0.3549 - val_accuracy: 0.0049\n","Epoch 92/120\n","13/13 [==============================] - 0s 33ms/step - loss: 0.0179 - accuracy: 0.0215 - val_loss: 0.3479 - val_accuracy: 0.0221\n","Epoch 93/120\n","13/13 [==============================] - 0s 32ms/step - loss: 0.0169 - accuracy: 0.0184 - val_loss: 0.3623 - val_accuracy: 0.0123\n","Epoch 94/120\n","13/13 [==============================] - 0s 33ms/step - loss: 0.0182 - accuracy: 0.0129 - val_loss: 0.3539 - val_accuracy: 0.0074\n","Epoch 95/120\n","13/13 [==============================] - 0s 35ms/step - loss: 0.0182 - accuracy: 0.0098 - val_loss: 0.3764 - val_accuracy: 0.0049\n","Epoch 96/120\n","13/13 [==============================] - 0s 35ms/step - loss: 0.0182 - accuracy: 0.0068 - val_loss: 0.3961 - val_accuracy: 0.0074\n","Epoch 97/120\n","13/13 [==============================] - 0s 35ms/step - loss: 0.0169 - accuracy: 0.0123 - val_loss: 0.3705 - val_accuracy: 0.0025\n","Epoch 98/120\n","13/13 [==============================] - 0s 34ms/step - loss: 0.0183 - accuracy: 0.0092 - val_loss: 0.3443 - val_accuracy: 0.0123\n","Epoch 99/120\n","13/13 [==============================] - 0s 34ms/step - loss: 0.0183 - accuracy: 0.0129 - val_loss: 0.4040 - val_accuracy: 0.0270\n","Epoch 100/120\n","13/13 [==============================] - 0s 33ms/step - loss: 0.0175 - accuracy: 0.0160 - val_loss: 0.3693 - val_accuracy: 0.0393\n","Epoch 101/120\n","13/13 [==============================] - 0s 36ms/step - loss: 0.0181 - accuracy: 0.0160 - val_loss: 0.4076 - val_accuracy: 0.0172\n","Epoch 102/120\n","13/13 [==============================] - 0s 34ms/step - loss: 0.0173 - accuracy: 0.0117 - val_loss: 0.3972 - val_accuracy: 0.0074\n","Epoch 103/120\n","13/13 [==============================] - 0s 34ms/step - loss: 0.0164 - accuracy: 0.0123 - val_loss: 0.3898 - val_accuracy: 0.0074\n","Epoch 104/120\n","13/13 [==============================] - 0s 34ms/step - loss: 0.0172 - accuracy: 0.0160 - val_loss: 0.3884 - val_accuracy: 0.0074\n","Epoch 105/120\n","13/13 [==============================] - 0s 34ms/step - loss: 0.0178 - accuracy: 0.0203 - val_loss: 0.3683 - val_accuracy: 0.0098\n","Epoch 106/120\n","13/13 [==============================] - 0s 35ms/step - loss: 0.0173 - accuracy: 0.0129 - val_loss: 0.3668 - val_accuracy: 0.0123\n","Epoch 107/120\n","13/13 [==============================] - 0s 34ms/step - loss: 0.0163 - accuracy: 0.0086 - val_loss: 0.3943 - val_accuracy: 0.0172\n","Epoch 108/120\n","13/13 [==============================] - 0s 35ms/step - loss: 0.0173 - accuracy: 0.0104 - val_loss: 0.4058 - val_accuracy: 0.0074\n","Epoch 109/120\n","13/13 [==============================] - 0s 34ms/step - loss: 0.0168 - accuracy: 0.0129 - val_loss: 0.3604 - val_accuracy: 0.0197\n","Epoch 110/120\n","13/13 [==============================] - 0s 32ms/step - loss: 0.0162 - accuracy: 0.0148 - val_loss: 0.3600 - val_accuracy: 0.0098\n","Epoch 111/120\n","13/13 [==============================] - 0s 31ms/step - loss: 0.0175 - accuracy: 0.0240 - val_loss: 0.4013 - val_accuracy: 0.0295\n","Epoch 112/120\n","13/13 [==============================] - 0s 37ms/step - loss: 0.0158 - accuracy: 0.0129 - val_loss: 0.3612 - val_accuracy: 0.0221\n","Epoch 113/120\n","13/13 [==============================] - 0s 33ms/step - loss: 0.0162 - accuracy: 0.0184 - val_loss: 0.3693 - val_accuracy: 0.0098\n","Epoch 114/120\n","13/13 [==============================] - 0s 35ms/step - loss: 0.0151 - accuracy: 0.0129 - val_loss: 0.3932 - val_accuracy: 0.0074\n","Epoch 115/120\n","13/13 [==============================] - 0s 33ms/step - loss: 0.0158 - accuracy: 0.0092 - val_loss: 0.3844 - val_accuracy: 0.0098\n","Epoch 116/120\n","13/13 [==============================] - 0s 34ms/step - loss: 0.0154 - accuracy: 0.0221 - val_loss: 0.3558 - val_accuracy: 0.0197\n","Epoch 117/120\n","13/13 [==============================] - 0s 33ms/step - loss: 0.0165 - accuracy: 0.0160 - val_loss: 0.3682 - val_accuracy: 0.0098\n","Epoch 118/120\n","13/13 [==============================] - 0s 33ms/step - loss: 0.0152 - accuracy: 0.0111 - val_loss: 0.3704 - val_accuracy: 0.0098\n","Epoch 119/120\n","13/13 [==============================] - 0s 35ms/step - loss: 0.0148 - accuracy: 0.0166 - val_loss: 0.4184 - val_accuracy: 0.0221\n","Epoch 120/120\n","13/13 [==============================] - 0s 34ms/step - loss: 0.0156 - accuracy: 0.0129 - val_loss: 0.3805 - val_accuracy: 0.0197\n","--------------------------------------------------------------------------------\n","--------------------------------------------------------------------------------\n","9 ------ Vacuum_cleaner 196\n","X_train shape: \n","(312, 216, 13)\n","Model: \"sequential_9\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","conv2d_18 (Conv2D)           (None, 214, 11, 128)      1280      \n","_________________________________________________________________\n","max_pooling2d_18 (MaxPooling (None, 107, 6, 128)       0         \n","_________________________________________________________________\n","batch_normalization_18 (Batc (None, 107, 6, 128)       512       \n","_________________________________________________________________\n","conv2d_19 (Conv2D)           (None, 105, 4, 128)       147584    \n","_________________________________________________________________\n","max_pooling2d_19 (MaxPooling (None, 53, 2, 128)        0         \n","_________________________________________________________________\n","batch_normalization_19 (Batc (None, 53, 2, 128)        512       \n","_________________________________________________________________\n","flatten_9 (Flatten)          (None, 13568)             0         \n","_________________________________________________________________\n","dense_18 (Dense)             (None, 256)               3473664   \n","_________________________________________________________________\n","dropout_9 (Dropout)          (None, 256)               0         \n","_________________________________________________________________\n","dense_19 (Dense)             (None, 216)               55512     \n","=================================================================\n","Total params: 3,679,064\n","Trainable params: 3,678,552\n","Non-trainable params: 512\n","_________________________________________________________________\n","Epoch 1/120\n","2/2 [==============================] - 2s 2s/step - loss: 0.7977 - accuracy: 0.0000e+00 - val_loss: 2.1455 - val_accuracy: 0.0000e+00\n","Epoch 2/120\n","2/2 [==============================] - 0s 52ms/step - loss: 0.6455 - accuracy: 0.0040 - val_loss: 1.8223 - val_accuracy: 0.0159\n","Epoch 3/120\n","2/2 [==============================] - 0s 53ms/step - loss: 0.5941 - accuracy: 0.0000e+00 - val_loss: 2.3645 - val_accuracy: 0.0000e+00\n","Epoch 4/120\n","2/2 [==============================] - 0s 57ms/step - loss: 0.5393 - accuracy: 0.0000e+00 - val_loss: 2.6561 - val_accuracy: 0.0000e+00\n","Epoch 5/120\n","2/2 [==============================] - 0s 60ms/step - loss: 0.4914 - accuracy: 0.0040 - val_loss: 3.2380 - val_accuracy: 0.0000e+00\n","Epoch 6/120\n","2/2 [==============================] - 0s 51ms/step - loss: 0.4408 - accuracy: 0.0000e+00 - val_loss: 3.7533 - val_accuracy: 0.0000e+00\n","Epoch 7/120\n","2/2 [==============================] - 0s 56ms/step - loss: 0.4010 - accuracy: 0.0000e+00 - val_loss: 3.8462 - val_accuracy: 0.0000e+00\n","Epoch 8/120\n","2/2 [==============================] - 0s 58ms/step - loss: 0.3562 - accuracy: 0.0000e+00 - val_loss: 3.8428 - val_accuracy: 0.0000e+00\n","Epoch 9/120\n","2/2 [==============================] - 0s 55ms/step - loss: 0.3143 - accuracy: 0.0000e+00 - val_loss: 4.2747 - val_accuracy: 0.0000e+00\n","Epoch 10/120\n","2/2 [==============================] - 0s 52ms/step - loss: 0.2854 - accuracy: 0.0000e+00 - val_loss: 4.2297 - val_accuracy: 0.0000e+00\n","Epoch 11/120\n","2/2 [==============================] - 0s 57ms/step - loss: 0.2612 - accuracy: 0.0000e+00 - val_loss: 4.1358 - val_accuracy: 0.0000e+00\n","Epoch 12/120\n","2/2 [==============================] - 0s 55ms/step - loss: 0.2257 - accuracy: 0.0040 - val_loss: 4.4851 - val_accuracy: 0.0000e+00\n","Epoch 13/120\n","2/2 [==============================] - 0s 57ms/step - loss: 0.2064 - accuracy: 0.0040 - val_loss: 4.2683 - val_accuracy: 0.0000e+00\n","Epoch 14/120\n","2/2 [==============================] - 0s 51ms/step - loss: 0.1882 - accuracy: 0.0040 - val_loss: 3.7428 - val_accuracy: 0.0000e+00\n","Epoch 15/120\n","2/2 [==============================] - 0s 56ms/step - loss: 0.1609 - accuracy: 0.0000e+00 - val_loss: 3.8771 - val_accuracy: 0.0000e+00\n","Epoch 16/120\n","2/2 [==============================] - 0s 61ms/step - loss: 0.1553 - accuracy: 0.0040 - val_loss: 3.6893 - val_accuracy: 0.0000e+00\n","Epoch 17/120\n","2/2 [==============================] - 0s 64ms/step - loss: 0.1359 - accuracy: 0.0080 - val_loss: 3.4511 - val_accuracy: 0.0000e+00\n","Epoch 18/120\n","2/2 [==============================] - 0s 58ms/step - loss: 0.1240 - accuracy: 0.0120 - val_loss: 3.5916 - val_accuracy: 0.0159\n","Epoch 19/120\n","2/2 [==============================] - 0s 56ms/step - loss: 0.1161 - accuracy: 0.0080 - val_loss: 3.3129 - val_accuracy: 0.0159\n","Epoch 20/120\n","2/2 [==============================] - 0s 51ms/step - loss: 0.1073 - accuracy: 0.0201 - val_loss: 2.6101 - val_accuracy: 0.0159\n","Epoch 21/120\n","2/2 [==============================] - 0s 49ms/step - loss: 0.1006 - accuracy: 0.0040 - val_loss: 2.8145 - val_accuracy: 0.0159\n","Epoch 22/120\n","2/2 [==============================] - 0s 54ms/step - loss: 0.0902 - accuracy: 0.0201 - val_loss: 3.1412 - val_accuracy: 0.0317\n","Epoch 23/120\n","2/2 [==============================] - 0s 56ms/step - loss: 0.0904 - accuracy: 0.0040 - val_loss: 2.8849 - val_accuracy: 0.0317\n","Epoch 24/120\n","2/2 [==============================] - 0s 58ms/step - loss: 0.0836 - accuracy: 0.0361 - val_loss: 2.8607 - val_accuracy: 0.0159\n","Epoch 25/120\n","2/2 [==============================] - 0s 53ms/step - loss: 0.0717 - accuracy: 0.0161 - val_loss: 2.9437 - val_accuracy: 0.0000e+00\n","Epoch 26/120\n","2/2 [==============================] - 0s 52ms/step - loss: 0.0770 - accuracy: 0.0080 - val_loss: 2.5028 - val_accuracy: 0.0000e+00\n","Epoch 27/120\n","2/2 [==============================] - 0s 57ms/step - loss: 0.0676 - accuracy: 0.0040 - val_loss: 2.4652 - val_accuracy: 0.0000e+00\n","Epoch 28/120\n","2/2 [==============================] - 0s 51ms/step - loss: 0.0634 - accuracy: 0.0040 - val_loss: 2.5779 - val_accuracy: 0.0159\n","Epoch 29/120\n","2/2 [==============================] - 0s 54ms/step - loss: 0.0608 - accuracy: 0.0080 - val_loss: 2.6233 - val_accuracy: 0.0159\n","Epoch 30/120\n","2/2 [==============================] - 0s 54ms/step - loss: 0.0637 - accuracy: 0.0120 - val_loss: 2.5256 - val_accuracy: 0.0000e+00\n","Epoch 31/120\n","2/2 [==============================] - 0s 54ms/step - loss: 0.0537 - accuracy: 0.0120 - val_loss: 2.6034 - val_accuracy: 0.0000e+00\n","Epoch 32/120\n","2/2 [==============================] - 0s 55ms/step - loss: 0.0512 - accuracy: 0.0000e+00 - val_loss: 2.3463 - val_accuracy: 0.0000e+00\n","Epoch 33/120\n","2/2 [==============================] - 0s 53ms/step - loss: 0.0491 - accuracy: 0.0040 - val_loss: 2.1471 - val_accuracy: 0.0000e+00\n","Epoch 34/120\n","2/2 [==============================] - 0s 51ms/step - loss: 0.0474 - accuracy: 0.0080 - val_loss: 2.1715 - val_accuracy: 0.0000e+00\n","Epoch 35/120\n","2/2 [==============================] - 0s 53ms/step - loss: 0.0445 - accuracy: 0.0040 - val_loss: 2.1382 - val_accuracy: 0.0159\n","Epoch 36/120\n","2/2 [==============================] - 0s 56ms/step - loss: 0.0447 - accuracy: 0.0040 - val_loss: 1.9764 - val_accuracy: 0.0159\n","Epoch 37/120\n","2/2 [==============================] - 0s 55ms/step - loss: 0.0360 - accuracy: 0.0080 - val_loss: 1.8087 - val_accuracy: 0.0159\n","Epoch 38/120\n","2/2 [==============================] - 0s 54ms/step - loss: 0.0399 - accuracy: 0.0000e+00 - val_loss: 1.7703 - val_accuracy: 0.0159\n","Epoch 39/120\n","2/2 [==============================] - 0s 49ms/step - loss: 0.0348 - accuracy: 0.0201 - val_loss: 1.8248 - val_accuracy: 0.0159\n","Epoch 40/120\n","2/2 [==============================] - 0s 59ms/step - loss: 0.0359 - accuracy: 0.0040 - val_loss: 1.7859 - val_accuracy: 0.0159\n","Epoch 41/120\n","2/2 [==============================] - 0s 59ms/step - loss: 0.0345 - accuracy: 0.0120 - val_loss: 1.5742 - val_accuracy: 0.0159\n","Epoch 42/120\n","2/2 [==============================] - 0s 50ms/step - loss: 0.0332 - accuracy: 0.0201 - val_loss: 1.3404 - val_accuracy: 0.0159\n","Epoch 43/120\n","2/2 [==============================] - 0s 50ms/step - loss: 0.0302 - accuracy: 0.0040 - val_loss: 1.2678 - val_accuracy: 0.0159\n","Epoch 44/120\n","2/2 [==============================] - 0s 54ms/step - loss: 0.0285 - accuracy: 0.0161 - val_loss: 1.1634 - val_accuracy: 0.0159\n","Epoch 45/120\n","2/2 [==============================] - 0s 53ms/step - loss: 0.0274 - accuracy: 0.0000e+00 - val_loss: 1.1607 - val_accuracy: 0.0000e+00\n","Epoch 46/120\n","2/2 [==============================] - 0s 51ms/step - loss: 0.0259 - accuracy: 0.0161 - val_loss: 1.1801 - val_accuracy: 0.0000e+00\n","Epoch 47/120\n","2/2 [==============================] - 0s 54ms/step - loss: 0.0272 - accuracy: 0.0120 - val_loss: 1.1795 - val_accuracy: 0.0000e+00\n","Epoch 48/120\n","2/2 [==============================] - 0s 53ms/step - loss: 0.0281 - accuracy: 0.0000e+00 - val_loss: 1.1244 - val_accuracy: 0.0159\n","Epoch 49/120\n","2/2 [==============================] - 0s 63ms/step - loss: 0.0263 - accuracy: 0.0080 - val_loss: 1.1561 - val_accuracy: 0.0159\n","Epoch 50/120\n","2/2 [==============================] - 0s 52ms/step - loss: 0.0257 - accuracy: 0.0040 - val_loss: 1.0737 - val_accuracy: 0.0159\n","Epoch 51/120\n","2/2 [==============================] - 0s 51ms/step - loss: 0.0254 - accuracy: 0.0080 - val_loss: 1.0068 - val_accuracy: 0.0476\n","Epoch 52/120\n","2/2 [==============================] - 0s 55ms/step - loss: 0.0214 - accuracy: 0.0080 - val_loss: 1.0591 - val_accuracy: 0.0635\n","Epoch 53/120\n","2/2 [==============================] - 0s 50ms/step - loss: 0.0218 - accuracy: 0.0241 - val_loss: 1.0163 - val_accuracy: 0.0476\n","Epoch 54/120\n","2/2 [==============================] - 0s 52ms/step - loss: 0.0223 - accuracy: 0.0120 - val_loss: 0.8950 - val_accuracy: 0.0476\n","Epoch 55/120\n","2/2 [==============================] - 0s 54ms/step - loss: 0.0215 - accuracy: 0.0201 - val_loss: 0.9025 - val_accuracy: 0.0476\n","Epoch 56/120\n","2/2 [==============================] - 0s 51ms/step - loss: 0.0218 - accuracy: 0.0120 - val_loss: 0.9474 - val_accuracy: 0.0159\n","Epoch 57/120\n","2/2 [==============================] - 0s 52ms/step - loss: 0.0211 - accuracy: 0.0120 - val_loss: 0.9837 - val_accuracy: 0.0159\n","Epoch 58/120\n","2/2 [==============================] - 0s 50ms/step - loss: 0.0194 - accuracy: 0.0120 - val_loss: 0.9009 - val_accuracy: 0.0000e+00\n","Epoch 59/120\n","2/2 [==============================] - 0s 53ms/step - loss: 0.0201 - accuracy: 0.0080 - val_loss: 0.8117 - val_accuracy: 0.0000e+00\n","Epoch 60/120\n","2/2 [==============================] - 0s 53ms/step - loss: 0.0213 - accuracy: 0.0000e+00 - val_loss: 0.7797 - val_accuracy: 0.0000e+00\n","Epoch 61/120\n","2/2 [==============================] - 0s 55ms/step - loss: 0.0186 - accuracy: 0.0120 - val_loss: 0.9163 - val_accuracy: 0.0159\n","Epoch 62/120\n","2/2 [==============================] - 0s 51ms/step - loss: 0.0192 - accuracy: 0.0120 - val_loss: 0.9689 - val_accuracy: 0.0159\n","Epoch 63/120\n","2/2 [==============================] - 0s 49ms/step - loss: 0.0185 - accuracy: 0.0080 - val_loss: 0.8585 - val_accuracy: 0.0159\n","Epoch 64/120\n","2/2 [==============================] - 0s 55ms/step - loss: 0.0175 - accuracy: 0.0120 - val_loss: 0.7038 - val_accuracy: 0.0159\n","Epoch 65/120\n","2/2 [==============================] - 0s 51ms/step - loss: 0.0180 - accuracy: 0.0080 - val_loss: 0.6587 - val_accuracy: 0.0159\n","Epoch 66/120\n","2/2 [==============================] - 0s 50ms/step - loss: 0.0153 - accuracy: 0.0120 - val_loss: 0.7257 - val_accuracy: 0.0159\n","Epoch 67/120\n","2/2 [==============================] - 0s 53ms/step - loss: 0.0160 - accuracy: 0.0120 - val_loss: 0.8142 - val_accuracy: 0.0159\n","Epoch 68/120\n","2/2 [==============================] - 0s 52ms/step - loss: 0.0146 - accuracy: 0.0080 - val_loss: 0.8372 - val_accuracy: 0.0000e+00\n","Epoch 69/120\n","2/2 [==============================] - 0s 50ms/step - loss: 0.0150 - accuracy: 0.0161 - val_loss: 0.7886 - val_accuracy: 0.0000e+00\n","Epoch 70/120\n","2/2 [==============================] - 0s 52ms/step - loss: 0.0159 - accuracy: 0.0080 - val_loss: 0.7423 - val_accuracy: 0.0000e+00\n","Epoch 71/120\n","2/2 [==============================] - 0s 53ms/step - loss: 0.0149 - accuracy: 0.0040 - val_loss: 0.7210 - val_accuracy: 0.0000e+00\n","Epoch 72/120\n","2/2 [==============================] - 0s 56ms/step - loss: 0.0124 - accuracy: 0.0080 - val_loss: 0.7593 - val_accuracy: 0.0000e+00\n","Epoch 73/120\n","2/2 [==============================] - 0s 51ms/step - loss: 0.0161 - accuracy: 0.0080 - val_loss: 0.7308 - val_accuracy: 0.0000e+00\n","Epoch 74/120\n","2/2 [==============================] - 0s 55ms/step - loss: 0.0124 - accuracy: 0.0040 - val_loss: 0.6366 - val_accuracy: 0.0000e+00\n","Epoch 75/120\n","2/2 [==============================] - 0s 53ms/step - loss: 0.0172 - accuracy: 0.0241 - val_loss: 0.5974 - val_accuracy: 0.0159\n","Epoch 76/120\n","2/2 [==============================] - 0s 53ms/step - loss: 0.0132 - accuracy: 0.0201 - val_loss: 0.6643 - val_accuracy: 0.0000e+00\n","Epoch 77/120\n","2/2 [==============================] - 0s 55ms/step - loss: 0.0104 - accuracy: 0.0080 - val_loss: 0.7274 - val_accuracy: 0.0000e+00\n","Epoch 78/120\n","2/2 [==============================] - 0s 51ms/step - loss: 0.0126 - accuracy: 0.0241 - val_loss: 0.7415 - val_accuracy: 0.0000e+00\n","Epoch 79/120\n","2/2 [==============================] - 0s 54ms/step - loss: 0.0130 - accuracy: 0.0000e+00 - val_loss: 0.6442 - val_accuracy: 0.0000e+00\n","Epoch 80/120\n","2/2 [==============================] - 0s 54ms/step - loss: 0.0112 - accuracy: 0.0201 - val_loss: 0.5597 - val_accuracy: 0.0000e+00\n","Epoch 81/120\n","2/2 [==============================] - 0s 66ms/step - loss: 0.0102 - accuracy: 0.0120 - val_loss: 0.5546 - val_accuracy: 0.0000e+00\n","Epoch 82/120\n","2/2 [==============================] - 0s 67ms/step - loss: 0.0116 - accuracy: 0.0120 - val_loss: 0.6047 - val_accuracy: 0.0000e+00\n","Epoch 83/120\n","2/2 [==============================] - 0s 75ms/step - loss: 0.0130 - accuracy: 0.0120 - val_loss: 0.6309 - val_accuracy: 0.0000e+00\n","Epoch 84/120\n","2/2 [==============================] - 0s 56ms/step - loss: 0.0116 - accuracy: 0.0201 - val_loss: 0.6506 - val_accuracy: 0.0000e+00\n","Epoch 85/120\n","2/2 [==============================] - 0s 73ms/step - loss: 0.0116 - accuracy: 0.0201 - val_loss: 0.6523 - val_accuracy: 0.0000e+00\n","Epoch 86/120\n","2/2 [==============================] - 0s 65ms/step - loss: 0.0123 - accuracy: 0.0120 - val_loss: 0.5982 - val_accuracy: 0.0159\n","Epoch 87/120\n","2/2 [==============================] - 0s 54ms/step - loss: 0.0113 - accuracy: 0.0120 - val_loss: 0.5768 - val_accuracy: 0.0317\n","Epoch 88/120\n","2/2 [==============================] - 0s 53ms/step - loss: 0.0147 - accuracy: 0.0040 - val_loss: 0.5774 - val_accuracy: 0.0476\n","Epoch 89/120\n","2/2 [==============================] - 0s 53ms/step - loss: 0.0109 - accuracy: 0.0120 - val_loss: 0.6329 - val_accuracy: 0.0317\n","Epoch 90/120\n","2/2 [==============================] - 0s 59ms/step - loss: 0.0114 - accuracy: 0.0120 - val_loss: 0.6440 - val_accuracy: 0.0000e+00\n","Epoch 91/120\n","2/2 [==============================] - 0s 55ms/step - loss: 0.0115 - accuracy: 0.0361 - val_loss: 0.6078 - val_accuracy: 0.0000e+00\n","Epoch 92/120\n","2/2 [==============================] - 0s 55ms/step - loss: 0.0093 - accuracy: 0.0241 - val_loss: 0.5651 - val_accuracy: 0.0000e+00\n","Epoch 93/120\n","2/2 [==============================] - 0s 55ms/step - loss: 0.0100 - accuracy: 0.0120 - val_loss: 0.5411 - val_accuracy: 0.0159\n","Epoch 94/120\n","2/2 [==============================] - 0s 51ms/step - loss: 0.0087 - accuracy: 0.0080 - val_loss: 0.5257 - val_accuracy: 0.0000e+00\n","Epoch 95/120\n","2/2 [==============================] - 0s 53ms/step - loss: 0.0091 - accuracy: 0.0161 - val_loss: 0.5311 - val_accuracy: 0.0000e+00\n","Epoch 96/120\n","2/2 [==============================] - 0s 52ms/step - loss: 0.0089 - accuracy: 0.0201 - val_loss: 0.5379 - val_accuracy: 0.0000e+00\n","Epoch 97/120\n","2/2 [==============================] - 0s 56ms/step - loss: 0.0090 - accuracy: 0.0080 - val_loss: 0.5415 - val_accuracy: 0.0000e+00\n","Epoch 98/120\n","2/2 [==============================] - 0s 50ms/step - loss: 0.0082 - accuracy: 0.0201 - val_loss: 0.5378 - val_accuracy: 0.0159\n","Epoch 99/120\n","2/2 [==============================] - 0s 56ms/step - loss: 0.0067 - accuracy: 0.0080 - val_loss: 0.5412 - val_accuracy: 0.0159\n","Epoch 100/120\n","2/2 [==============================] - 0s 55ms/step - loss: 0.0078 - accuracy: 0.0161 - val_loss: 0.5606 - val_accuracy: 0.0159\n","Epoch 101/120\n","2/2 [==============================] - 0s 58ms/step - loss: 0.0067 - accuracy: 0.0080 - val_loss: 0.5722 - val_accuracy: 0.0159\n","Epoch 102/120\n","2/2 [==============================] - 0s 57ms/step - loss: 0.0098 - accuracy: 0.0201 - val_loss: 0.5777 - val_accuracy: 0.0000e+00\n","Epoch 103/120\n","2/2 [==============================] - 0s 58ms/step - loss: 0.0078 - accuracy: 0.0120 - val_loss: 0.5882 - val_accuracy: 0.0000e+00\n","Epoch 104/120\n","2/2 [==============================] - 0s 58ms/step - loss: 0.0085 - accuracy: 0.0161 - val_loss: 0.5983 - val_accuracy: 0.0000e+00\n","Epoch 105/120\n","2/2 [==============================] - 0s 55ms/step - loss: 0.0070 - accuracy: 0.0080 - val_loss: 0.6086 - val_accuracy: 0.0000e+00\n","Epoch 106/120\n","2/2 [==============================] - 0s 54ms/step - loss: 0.0071 - accuracy: 0.0161 - val_loss: 0.6275 - val_accuracy: 0.0000e+00\n","Epoch 107/120\n","2/2 [==============================] - 0s 53ms/step - loss: 0.0063 - accuracy: 0.0201 - val_loss: 0.6442 - val_accuracy: 0.0000e+00\n","Epoch 108/120\n","2/2 [==============================] - 0s 57ms/step - loss: 0.0061 - accuracy: 0.0080 - val_loss: 0.6503 - val_accuracy: 0.0000e+00\n","Epoch 109/120\n","2/2 [==============================] - 0s 51ms/step - loss: 0.0078 - accuracy: 0.0080 - val_loss: 0.6229 - val_accuracy: 0.0000e+00\n","Epoch 110/120\n","2/2 [==============================] - 0s 53ms/step - loss: 0.0075 - accuracy: 0.0161 - val_loss: 0.6073 - val_accuracy: 0.0000e+00\n","Epoch 111/120\n","2/2 [==============================] - 0s 56ms/step - loss: 0.0067 - accuracy: 0.0120 - val_loss: 0.6044 - val_accuracy: 0.0000e+00\n","Epoch 112/120\n","2/2 [==============================] - 0s 56ms/step - loss: 0.0064 - accuracy: 0.0040 - val_loss: 0.6075 - val_accuracy: 0.0000e+00\n","Epoch 113/120\n","2/2 [==============================] - 0s 53ms/step - loss: 0.0065 - accuracy: 0.0080 - val_loss: 0.6065 - val_accuracy: 0.0159\n","Epoch 114/120\n","2/2 [==============================] - 0s 54ms/step - loss: 0.0059 - accuracy: 0.0201 - val_loss: 0.6090 - val_accuracy: 0.0317\n","Epoch 115/120\n","2/2 [==============================] - 0s 65ms/step - loss: 0.0061 - accuracy: 0.0120 - val_loss: 0.6276 - val_accuracy: 0.0159\n","Epoch 116/120\n","2/2 [==============================] - 0s 51ms/step - loss: 0.0063 - accuracy: 0.0201 - val_loss: 0.6447 - val_accuracy: 0.0159\n","Epoch 117/120\n","2/2 [==============================] - 0s 55ms/step - loss: 0.0066 - accuracy: 0.0161 - val_loss: 0.6682 - val_accuracy: 0.0159\n","Epoch 118/120\n","2/2 [==============================] - 0s 51ms/step - loss: 0.0053 - accuracy: 0.0120 - val_loss: 0.6585 - val_accuracy: 0.0000e+00\n","Epoch 119/120\n","2/2 [==============================] - 0s 53ms/step - loss: 0.0050 - accuracy: 0.0161 - val_loss: 0.6267 - val_accuracy: 0.0000e+00\n","Epoch 120/120\n","2/2 [==============================] - 0s 54ms/step - loss: 0.0067 - accuracy: 0.0201 - val_loss: 0.5917 - val_accuracy: 0.0000e+00\n","--------------------------------------------------------------------------------\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1rFd0rM-cAmL","executionInfo":{"status":"ok","timestamp":1624912942687,"user_tz":-120,"elapsed":27300,"user":{"displayName":"Mihajlo Perendija","photoUrl":"","userId":"04858557923362990038"}},"outputId":"055647b5-1658-4ab7-f500-c111635d9372"},"source":["# RESULTS LOOK OK\n","# ANALYZE HOW IT BEHAVES WITH OVERLAPING EVENTS\n","combined_references = []\n","combined_estimations = []\n","\n","for index, event in enumerate(unique_events):\n","  training = data[data['event_label'] == event]\n","\n","  X = np.array(training.mfccs.tolist())\n","  y = np.array(training.combine_squence_per_filename_and_event.tolist())\n","\n","  X = np.einsum('ijk->ikj', X)\n","\n","  indices = np.arange(X.shape[0])\n","  X_train, X_test, y_train, y_test, I_train, I_test = train_test_split(X, y, indices, test_size=0.2, random_state = 42)\n","\n","  X_train, y_train = split_sequences_into_seconds(X_train, y_train, 5)\n","  X_test, y_test = split_sequences_into_seconds(X_test, y_test, 5)\n","  X_train = np.expand_dims(X_train, axis=-1)\n","  X_test = np.expand_dims(X_test, axis=-1) \n","\n","  print(\"-\"*80)\n","  print(str(index) + \" ------ \" + event + \" \" + str(len(X)))\n","  model = keras.models.load_model('/content/drive/MyDrive/neuronske/models/' + 'CNN_splitted_seq' + str(event) + '.h5', compile=True)\n","  y_pred = model.predict(X_test, batch_size=64, verbose=1)\n","  y_pred = (y_pred > 0.5)\n","  simple_evaluation(y_pred, y_test)\n","  print(\"-\"*80)\n","\n","  combined_y_pred = combine_predicted_to_original(y_pred, 5, 431)\n","  combined_y_test = combine_predicted_to_original(y_test, 5, 431)\n","\n","  simple_evaluation(combined_y_pred, combined_y_test)\n","  print(\"-\"*80)\n","\n","  references, estimations = prepare_predicted_sequences_for_evaluation_and_evaluate(event, combined_y_pred, I_test, training, events, 1)\n","  combined_references.extend(references)\n","  combined_estimations.extend(estimations)\n","\n","\n","print(\"-\"*80)\n","print(\"-\"*80)\n","\n","print(\"FINAL EVALUATION: \")\n","print(\"-\"*80)\n","evaluate_and_print_results(combined_references, combined_estimations)\n","print(\"-\"*80)"],"execution_count":15,"outputs":[{"output_type":"stream","text":["--------------------------------------------------------------------------------\n","0 ------ Alarm_bell_ringing 392\n","3/3 [==============================] - 0s 5ms/step\n","PRECISION: 0.7817971906869348\n","RECALL: 0.543327092805563\n","F1: 0.641104536489152\n","--------------------\n","tp: 4063\n","tn: 25516\n","fp: 1134\n","fn: 3415\n","--------------------------------------------------------------------------------\n","2\n","79\n","2\n","79\n","PRECISION: 0.7817971906869348\n","RECALL: 0.543327092805563\n","F1: 0.641104536489152\n","--------------------\n","tp: 4063\n","tn: 25516\n","fp: 1134\n","fn: 3415\n","--------------------------------------------------------------------------------\n","Accuracy: 0.7937219730941704\n","Segment based metrics\n","========================================\n","  Evaluated length                  : 642.91 sec\n","  Evaluated files                   : 79 \n","  Segment length                    : 1.00 sec\n","\n","  Overall metrics (micro-average)\n","  ======================================\n","  F-measure\n","    F-measure (F1)                  : 76.37 %\n","    Precision                       : 79.64 %\n","    Recall                          : 73.36 %\n","  Error rate\n","    Error rate (ER)                 : 0.45 \n","    Substitution rate               : 0.00 \n","    Deletion rate                   : 0.27 \n","    Insertion rate                  : 0.19 \n","  Accuracy\n","    Sensitivity                     : 73.36 %\n","    Specificity                     : 84.38 %\n","    Balanced accuracy               : 78.87 %\n","    Accuracy                        : 79.37 %\n","\n","  Class-wise average metrics (macro-average)\n","  ======================================\n","  F-measure\n","    F-measure (F1)                  : 76.37 %\n","    Precision                       : 79.64 %\n","    Recall                          : 73.36 %\n","  Error rate\n","    Error rate (ER)                 : 0.45 \n","    Deletion rate                   : 0.27 \n","    Insertion rate                  : 0.19 \n","  Accuracy\n","    Sensitivity                     : 73.36 %\n","    Specificity                     : 84.38 %\n","    Balanced accuracy               : 78.87 %\n","    Accuracy                        : 79.37 %\n","  \n","\n","  Class-wise metrics\n","  ======================================\n","    Event label  | Nref    Nsys  | F        Pre      Rec    | ER       Del      Ins    | Sens     Spec     Bacc     Acc     \n","    ------------ | -----   ----- | ------   ------   ------ | ------   ------   ------ | ------   ------   ------   ------  \n","    Alarm_bell.. | 304     280   | 76.4%    79.6%    73.4%  | 0.45     0.27     0.19   | 73.4%    84.4%    78.9%    79.4%   \n","\n","\n","Event based metrics (onset-offset)\n","========================================\n","  Evaluated length                  : 617.59 sec\n","  Evaluated files                   : 79 \n","  Evaluate onset                    : True \n","  Evaluate offset                   : True \n","  T collar                          : 250.00 ms\n","  Offset (length)                   : 50.00 %\n","\n","  Overall metrics (micro-average)\n","  ======================================\n","  F-measure\n","    F-measure (F1)                  : 43.14 %\n","    Precision                       : 37.75 %\n","    Recall                          : 50.33 %\n","  Error rate\n","    Error rate (ER)                 : 1.33 \n","    Substitution rate               : 0.00 \n","    Deletion rate                   : 0.50 \n","    Insertion rate                  : 0.83 \n","\n","  Class-wise average metrics (macro-average)\n","  ======================================\n","  F-measure\n","    F-measure (F1)                  : 43.14 %\n","    Precision                       : 37.75 %\n","    Recall                          : 50.33 %\n","  Error rate\n","    Error rate (ER)                 : 1.33 \n","    Deletion rate                   : 0.50 \n","    Insertion rate                  : 0.83 \n","  \n","\n","  Class-wise metrics\n","  ======================================\n","    Event label  | Nref    Nsys  | F        Pre      Rec    | ER       Del      Ins    |\n","    ------------ | -----   ----- | ------   ------   ------ | ------   ------   ------ |\n","    Alarm_bell.. | 153     204   | 43.1%    37.7%    50.3%  | 1.33     0.50     0.83   |\n","\n","\n","--------------------------------------------------------------------------------\n","1 ------ Blender 436\n","3/3 [==============================] - 0s 197ms/step\n","PRECISION: 0.9271118262268705\n","RECALL: 0.9148209891243947\n","F1: 0.9209254005673873\n","--------------------\n","tp: 11524\n","tn: 24513\n","fp: 906\n","fn: 1073\n","--------------------------------------------------------------------------------\n","2\n","88\n","2\n","88\n","PRECISION: 0.9271118262268705\n","RECALL: 0.9148209891243947\n","F1: 0.9209254005673873\n","--------------------\n","tp: 11524\n","tn: 24513\n","fp: 906\n","fn: 1073\n","--------------------------------------------------------------------------------\n","Accuracy: 0.9281045751633987\n","Segment based metrics\n","========================================\n","  Evaluated length                  : 745.52 sec\n","  Evaluated files                   : 88 \n","  Segment length                    : 1.00 sec\n","\n","  Overall metrics (micro-average)\n","  ======================================\n","  F-measure\n","    F-measure (F1)                  : 92.64 %\n","    Precision                       : 91.05 %\n","    Recall                          : 94.28 %\n","  Error rate\n","    Error rate (ER)                 : 0.15 \n","    Substitution rate               : 0.00 \n","    Deletion rate                   : 0.06 \n","    Insertion rate                  : 0.09 \n","  Accuracy\n","    Sensitivity                     : 94.28 %\n","    Specificity                     : 91.46 %\n","    Balanced accuracy               : 92.87 %\n","    Accuracy                        : 92.81 %\n","\n","  Class-wise average metrics (macro-average)\n","  ======================================\n","  F-measure\n","    F-measure (F1)                  : 92.64 %\n","    Precision                       : 91.05 %\n","    Recall                          : 94.28 %\n","  Error rate\n","    Error rate (ER)                 : 0.15 \n","    Deletion rate                   : 0.06 \n","    Insertion rate                  : 0.09 \n","  Accuracy\n","    Sensitivity                     : 94.28 %\n","    Specificity                     : 91.46 %\n","    Balanced accuracy               : 92.87 %\n","    Accuracy                        : 92.81 %\n","  \n","\n","  Class-wise metrics\n","  ======================================\n","    Event label  | Nref    Nsys  | F        Pre      Rec    | ER       Del      Ins    | Sens     Spec     Bacc     Acc     \n","    ------------ | -----   ----- | ------   ------   ------ | ------   ------   ------ | ------   ------   ------   ------  \n","    Blender      | 367     380   | 92.6%    91.1%    94.3%  | 0.15     0.06     0.09   | 94.3%    91.5%    92.9%    92.8%   \n","\n","\n","Event based metrics (onset-offset)\n","========================================\n","  Evaluated length                  : 728.53 sec\n","  Evaluated files                   : 88 \n","  Evaluate onset                    : True \n","  Evaluate offset                   : True \n","  T collar                          : 250.00 ms\n","  Offset (length)                   : 50.00 %\n","\n","  Overall metrics (micro-average)\n","  ======================================\n","  F-measure\n","    F-measure (F1)                  : 72.00 %\n","    Precision                       : 65.32 %\n","    Recall                          : 80.20 %\n","  Error rate\n","    Error rate (ER)                 : 0.62 \n","    Substitution rate               : 0.00 \n","    Deletion rate                   : 0.20 \n","    Insertion rate                  : 0.43 \n","\n","  Class-wise average metrics (macro-average)\n","  ======================================\n","  F-measure\n","    F-measure (F1)                  : 72.00 %\n","    Precision                       : 65.32 %\n","    Recall                          : 80.20 %\n","  Error rate\n","    Error rate (ER)                 : 0.62 \n","    Deletion rate                   : 0.20 \n","    Insertion rate                  : 0.43 \n","  \n","\n","  Class-wise metrics\n","  ======================================\n","    Event label  | Nref    Nsys  | F        Pre      Rec    | ER       Del      Ins    |\n","    ------------ | -----   ----- | ------   ------   ------ | ------   ------   ------ |\n","    Blender      | 101     124   | 72.0%    65.3%    80.2%  | 0.62     0.20     0.43   |\n","\n","\n","--------------------------------------------------------------------------------\n","2 ------ Cat 274\n","2/2 [==============================] - 0s 8ms/step\n","PRECISION: 0.831130294038306\n","RECALL: 0.6545570427023581\n","F1: 0.732350843831709\n","--------------------\n","tp: 3081\n","tn: 18427\n","fp: 626\n","fn: 1626\n","--------------------------------------------------------------------------------\n","2\n","55\n","2\n","55\n","PRECISION: 0.831130294038306\n","RECALL: 0.6545570427023581\n","F1: 0.732350843831709\n","--------------------\n","tp: 3081\n","tn: 18427\n","fp: 626\n","fn: 1626\n","--------------------------------------------------------------------------------\n","Accuracy: 0.8233995584988962\n","Segment based metrics\n","========================================\n","  Evaluated length                  : 433.68 sec\n","  Evaluated files                   : 55 \n","  Segment length                    : 1.00 sec\n","\n","  Overall metrics (micro-average)\n","  ======================================\n","  F-measure\n","    F-measure (F1)                  : 79.59 %\n","    Precision                       : 80.41 %\n","    Recall                          : 78.79 %\n","  Error rate\n","    Error rate (ER)                 : 0.40 \n","    Substitution rate               : 0.00 \n","    Deletion rate                   : 0.21 \n","    Insertion rate                  : 0.19 \n","  Accuracy\n","    Sensitivity                     : 78.79 %\n","    Specificity                     : 85.10 %\n","    Balanced accuracy               : 81.94 %\n","    Accuracy                        : 82.34 %\n","\n","  Class-wise average metrics (macro-average)\n","  ======================================\n","  F-measure\n","    F-measure (F1)                  : 79.59 %\n","    Precision                       : 80.41 %\n","    Recall                          : 78.79 %\n","  Error rate\n","    Error rate (ER)                 : 0.40 \n","    Deletion rate                   : 0.21 \n","    Insertion rate                  : 0.19 \n","  Accuracy\n","    Sensitivity                     : 78.79 %\n","    Specificity                     : 85.10 %\n","    Balanced accuracy               : 81.94 %\n","    Accuracy                        : 82.34 %\n","  \n","\n","  Class-wise metrics\n","  ======================================\n","    Event label  | Nref    Nsys  | F        Pre      Rec    | ER       Del      Ins    | Sens     Spec     Bacc     Acc     \n","    ------------ | -----   ----- | ------   ------   ------ | ------   ------   ------ | ------   ------   ------   ------  \n","    Cat          | 198     194   | 79.6%    80.4%    78.8%  | 0.40     0.21     0.19   | 78.8%    85.1%    81.9%    82.3%   \n","\n","\n","Event based metrics (onset-offset)\n","========================================\n","  Evaluated length                  : 408.17 sec\n","  Evaluated files                   : 55 \n","  Evaluate onset                    : True \n","  Evaluate offset                   : True \n","  T collar                          : 250.00 ms\n","  Offset (length)                   : 50.00 %\n","\n","  Overall metrics (micro-average)\n","  ======================================\n","  F-measure\n","    F-measure (F1)                  : 50.60 %\n","    Precision                       : 42.57 %\n","    Recall                          : 62.38 %\n","  Error rate\n","    Error rate (ER)                 : 1.22 \n","    Substitution rate               : 0.00 \n","    Deletion rate                   : 0.38 \n","    Insertion rate                  : 0.84 \n","\n","  Class-wise average metrics (macro-average)\n","  ======================================\n","  F-measure\n","    F-measure (F1)                  : 50.60 %\n","    Precision                       : 42.57 %\n","    Recall                          : 62.38 %\n","  Error rate\n","    Error rate (ER)                 : 1.22 \n","    Deletion rate                   : 0.38 \n","    Insertion rate                  : 0.84 \n","  \n","\n","  Class-wise metrics\n","  ======================================\n","    Event label  | Nref    Nsys  | F        Pre      Rec    | ER       Del      Ins    |\n","    ------------ | -----   ----- | ------   ------   ------ | ------   ------   ------ |\n","    Cat          | 101     148   | 50.6%    42.6%    62.4%  | 1.22     0.38     0.84   |\n","\n","\n","--------------------------------------------------------------------------------\n","3 ------ Dishes 444\n","WARNING:tensorflow:5 out of the last 12 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7ff73443a5f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n","3/3 [==============================] - 1s 216ms/step\n","PRECISION: 0.7288888888888889\n","RECALL: 0.2213225371120108\n","F1: 0.33954451345755693\n","--------------------\n","tp: 820\n","tn: 34438\n","fp: 305\n","fn: 2885\n","--------------------------------------------------------------------------------\n","2\n","89\n","2\n","89\n","PRECISION: 0.7288888888888889\n","RECALL: 0.2213225371120108\n","F1: 0.33954451345755693\n","--------------------\n","tp: 820\n","tn: 34438\n","fp: 305\n","fn: 2885\n","--------------------------------------------------------------------------------\n","Accuracy: 0.7384370015948963\n","Segment based metrics\n","========================================\n","  Evaluated length                  : 587.48 sec\n","  Evaluated files                   : 89 \n","  Segment length                    : 1.00 sec\n","\n","  Overall metrics (micro-average)\n","  ======================================\n","  F-measure\n","    F-measure (F1)                  : 55.68 %\n","    Precision                       : 79.84 %\n","    Recall                          : 42.74 %\n","  Error rate\n","    Error rate (ER)                 : 0.68 \n","    Substitution rate               : 0.00 \n","    Deletion rate                   : 0.57 \n","    Insertion rate                  : 0.11 \n","  Accuracy\n","    Sensitivity                     : 42.74 %\n","    Specificity                     : 93.26 %\n","    Balanced accuracy               : 68.00 %\n","    Accuracy                        : 73.84 %\n","\n","  Class-wise average metrics (macro-average)\n","  ======================================\n","  F-measure\n","    F-measure (F1)                  : 55.68 %\n","    Precision                       : 79.84 %\n","    Recall                          : 42.74 %\n","  Error rate\n","    Error rate (ER)                 : 0.68 \n","    Deletion rate                   : 0.57 \n","    Insertion rate                  : 0.11 \n","  Accuracy\n","    Sensitivity                     : 42.74 %\n","    Specificity                     : 93.26 %\n","    Balanced accuracy               : 68.00 %\n","    Accuracy                        : 73.84 %\n","  \n","\n","  Class-wise metrics\n","  ======================================\n","    Event label  | Nref    Nsys  | F        Pre      Rec    | ER       Del      Ins    | Sens     Spec     Bacc     Acc     \n","    ------------ | -----   ----- | ------   ------   ------ | ------   ------   ------ | ------   ------   ------   ------  \n","    Dishes       | 241     129   | 55.7%    79.8%    42.7%  | 0.68     0.57     0.11   | 42.7%    93.3%    68.0%    73.8%   \n","\n","\n","Event based metrics (onset-offset)\n","========================================\n","  Evaluated length                  : 543.38 sec\n","  Evaluated files                   : 89 \n","  Evaluate onset                    : True \n","  Evaluate offset                   : True \n","  T collar                          : 250.00 ms\n","  Offset (length)                   : 50.00 %\n","\n","  Overall metrics (micro-average)\n","  ======================================\n","  F-measure\n","    F-measure (F1)                  : 36.30 %\n","    Precision                       : 43.97 %\n","    Recall                          : 30.91 %\n","  Error rate\n","    Error rate (ER)                 : 1.08 \n","    Substitution rate               : 0.00 \n","    Deletion rate                   : 0.69 \n","    Insertion rate                  : 0.39 \n","\n","  Class-wise average metrics (macro-average)\n","  ======================================\n","  F-measure\n","    F-measure (F1)                  : 36.30 %\n","    Precision                       : 43.97 %\n","    Recall                          : 30.91 %\n","  Error rate\n","    Error rate (ER)                 : 1.08 \n","    Deletion rate                   : 0.69 \n","    Insertion rate                  : 0.39 \n","  \n","\n","  Class-wise metrics\n","  ======================================\n","    Event label  | Nref    Nsys  | F        Pre      Rec    | ER       Del      Ins    |\n","    ------------ | -----   ----- | ------   ------   ------ | ------   ------   ------ |\n","    Dishes       | 165     116   | 36.3%    44.0%    30.9%  | 1.08     0.69     0.39   |\n","\n","\n","--------------------------------------------------------------------------------\n","4 ------ Dog 319\n","WARNING:tensorflow:5 out of the last 12 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7ff73a50e3b0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n","2/2 [==============================] - 0s 10ms/step\n","PRECISION: 0.8088712585647313\n","RECALL: 0.6060524182653337\n","F1: 0.6929255483472352\n","--------------------\n","tp: 2243\n","tn: 23417\n","fp: 530\n","fn: 1458\n","--------------------------------------------------------------------------------\n","2\n","64\n","2\n","64\n","PRECISION: 0.8088712585647313\n","RECALL: 0.6060524182653337\n","F1: 0.6929255483472352\n","--------------------\n","tp: 2243\n","tn: 23417\n","fp: 530\n","fn: 1458\n","--------------------------------------------------------------------------------\n","Accuracy: 0.834\n","Segment based metrics\n","========================================\n","  Evaluated length                  : 474.62 sec\n","  Evaluated files                   : 64 \n","  Segment length                    : 1.00 sec\n","\n","  Overall metrics (micro-average)\n","  ======================================\n","  F-measure\n","    F-measure (F1)                  : 75.94 %\n","    Precision                       : 78.92 %\n","    Recall                          : 73.18 %\n","  Error rate\n","    Error rate (ER)                 : 0.46 \n","    Substitution rate               : 0.00 \n","    Deletion rate                   : 0.27 \n","    Insertion rate                  : 0.20 \n","  Accuracy\n","    Sensitivity                     : 73.18 %\n","    Specificity                     : 89.10 %\n","    Balanced accuracy               : 81.14 %\n","    Accuracy                        : 83.40 %\n","\n","  Class-wise average metrics (macro-average)\n","  ======================================\n","  F-measure\n","    F-measure (F1)                  : 75.94 %\n","    Precision                       : 78.92 %\n","    Recall                          : 73.18 %\n","  Error rate\n","    Error rate (ER)                 : 0.46 \n","    Deletion rate                   : 0.27 \n","    Insertion rate                  : 0.20 \n","  Accuracy\n","    Sensitivity                     : 73.18 %\n","    Specificity                     : 89.10 %\n","    Balanced accuracy               : 81.14 %\n","    Accuracy                        : 83.40 %\n","  \n","\n","  Class-wise metrics\n","  ======================================\n","    Event label  | Nref    Nsys  | F        Pre      Rec    | ER       Del      Ins    | Sens     Spec     Bacc     Acc     \n","    ------------ | -----   ----- | ------   ------   ------ | ------   ------   ------ | ------   ------   ------   ------  \n","    Dog          | 179     166   | 75.9%    78.9%    73.2%  | 0.46     0.27     0.20   | 73.2%    89.1%    81.1%    83.4%   \n","\n","\n","Event based metrics (onset-offset)\n","========================================\n","  Evaluated length                  : 429.39 sec\n","  Evaluated files                   : 64 \n","  Evaluate onset                    : True \n","  Evaluate offset                   : True \n","  T collar                          : 250.00 ms\n","  Offset (length)                   : 50.00 %\n","\n","  Overall metrics (micro-average)\n","  ======================================\n","  F-measure\n","    F-measure (F1)                  : 52.40 %\n","    Precision                       : 46.88 %\n","    Recall                          : 59.41 %\n","  Error rate\n","    Error rate (ER)                 : 1.08 \n","    Substitution rate               : 0.00 \n","    Deletion rate                   : 0.41 \n","    Insertion rate                  : 0.67 \n","\n","  Class-wise average metrics (macro-average)\n","  ======================================\n","  F-measure\n","    F-measure (F1)                  : 52.40 %\n","    Precision                       : 46.88 %\n","    Recall                          : 59.41 %\n","  Error rate\n","    Error rate (ER)                 : 1.08 \n","    Deletion rate                   : 0.41 \n","    Insertion rate                  : 0.67 \n","  \n","\n","  Class-wise metrics\n","  ======================================\n","    Event label  | Nref    Nsys  | F        Pre      Rec    | ER       Del      Ins    |\n","    ------------ | -----   ----- | ------   ------   ------ | ------   ------   ------ |\n","    Dog          | 101     128   | 52.4%    46.9%    59.4%  | 1.08     0.41     0.67   |\n","\n","\n","--------------------------------------------------------------------------------\n","5 ------ Electric_shaver_toothbrush 221\n","2/2 [==============================] - 0s 296ms/step\n","PRECISION: 0.991046511627907\n","RECALL: 0.9590412962754585\n","F1: 0.9747812660833763\n","--------------------\n","tp: 8523\n","tn: 10476\n","fp: 77\n","fn: 364\n","--------------------------------------------------------------------------------\n","2\n","45\n","2\n","45\n","PRECISION: 0.991046511627907\n","RECALL: 0.9590412962754585\n","F1: 0.9747812660833763\n","--------------------\n","tp: 8523\n","tn: 10476\n","fp: 77\n","fn: 364\n","--------------------------------------------------------------------------------\n","Accuracy: 0.9791666666666666\n","Segment based metrics\n","========================================\n","  Evaluated length                  : 428.06 sec\n","  Evaluated files                   : 45 \n","  Segment length                    : 1.00 sec\n","\n","  Overall metrics (micro-average)\n","  ======================================\n","  F-measure\n","    F-measure (F1)                  : 98.07 %\n","    Precision                       : 98.28 %\n","    Recall                          : 97.86 %\n","  Error rate\n","    Error rate (ER)                 : 0.04 \n","    Substitution rate               : 0.00 \n","    Deletion rate                   : 0.02 \n","    Insertion rate                  : 0.02 \n","  Accuracy\n","    Sensitivity                     : 97.86 %\n","    Specificity                     : 97.98 %\n","    Balanced accuracy               : 97.92 %\n","    Accuracy                        : 97.92 %\n","\n","  Class-wise average metrics (macro-average)\n","  ======================================\n","  F-measure\n","    F-measure (F1)                  : 98.07 %\n","    Precision                       : 98.28 %\n","    Recall                          : 97.86 %\n","  Error rate\n","    Error rate (ER)                 : 0.04 \n","    Deletion rate                   : 0.02 \n","    Insertion rate                  : 0.02 \n","  Accuracy\n","    Sensitivity                     : 97.86 %\n","    Specificity                     : 97.98 %\n","    Balanced accuracy               : 97.92 %\n","    Accuracy                        : 97.92 %\n","  \n","\n","  Class-wise metrics\n","  ======================================\n","    Event label  | Nref    Nsys  | F        Pre      Rec    | ER       Del      Ins    | Sens     Spec     Bacc     Acc     \n","    ------------ | -----   ----- | ------   ------   ------ | ------   ------   ------ | ------   ------   ------   ------  \n","    Electric_s.. | 234     233   | 98.1%    98.3%    97.9%  | 0.04     0.02     0.02   | 97.9%    98.0%    97.9%    97.9%   \n","\n","\n","Event based metrics (onset-offset)\n","========================================\n","  Evaluated length                  : 426.74 sec\n","  Evaluated files                   : 45 \n","  Evaluate onset                    : True \n","  Evaluate offset                   : True \n","  T collar                          : 250.00 ms\n","  Offset (length)                   : 50.00 %\n","\n","  Overall metrics (micro-average)\n","  ======================================\n","  F-measure\n","    F-measure (F1)                  : 83.17 %\n","    Precision                       : 76.36 %\n","    Recall                          : 91.30 %\n","  Error rate\n","    Error rate (ER)                 : 0.37 \n","    Substitution rate               : 0.00 \n","    Deletion rate                   : 0.09 \n","    Insertion rate                  : 0.28 \n","\n","  Class-wise average metrics (macro-average)\n","  ======================================\n","  F-measure\n","    F-measure (F1)                  : 83.17 %\n","    Precision                       : 76.36 %\n","    Recall                          : 91.30 %\n","  Error rate\n","    Error rate (ER)                 : 0.37 \n","    Deletion rate                   : 0.09 \n","    Insertion rate                  : 0.28 \n","  \n","\n","  Class-wise metrics\n","  ======================================\n","    Event label  | Nref    Nsys  | F        Pre      Rec    | ER       Del      Ins    |\n","    ------------ | -----   ----- | ------   ------   ------ | ------   ------   ------ |\n","    Electric_s.. | 46      55    | 83.2%    76.4%    91.3%  | 0.37     0.09     0.28   |\n","\n","\n","--------------------------------------------------------------------------------\n","6 ------ Frying 130\n","1/1 [==============================] - 1s 505ms/step\n","PRECISION: 0.966489998290306\n","RECALL: 0.8997294286169027\n","F1: 0.9319155951203428\n","--------------------\n","tp: 5653\n","tn: 4753\n","fp: 196\n","fn: 630\n","--------------------------------------------------------------------------------\n","2\n","26\n","2\n","26\n","PRECISION: 0.966489998290306\n","RECALL: 0.8997294286169027\n","F1: 0.9319155951203428\n","--------------------\n","tp: 5653\n","tn: 4753\n","fp: 196\n","fn: 630\n","--------------------------------------------------------------------------------\n","Accuracy: 0.9140625\n","Segment based metrics\n","========================================\n","  Evaluated length                  : 255.85 sec\n","  Evaluated files                   : 26 \n","  Segment length                    : 1.00 sec\n","\n","  Overall metrics (micro-average)\n","  ======================================\n","  F-measure\n","    F-measure (F1)                  : 92.95 %\n","    Precision                       : 95.39 %\n","    Recall                          : 90.62 %\n","  Error rate\n","    Error rate (ER)                 : 0.14 \n","    Substitution rate               : 0.00 \n","    Deletion rate                   : 0.09 \n","    Insertion rate                  : 0.04 \n","  Accuracy\n","    Sensitivity                     : 90.62 %\n","    Specificity                     : 92.71 %\n","    Balanced accuracy               : 91.67 %\n","    Accuracy                        : 91.41 %\n","\n","  Class-wise average metrics (macro-average)\n","  ======================================\n","  F-measure\n","    F-measure (F1)                  : 92.95 %\n","    Precision                       : 95.39 %\n","    Recall                          : 90.62 %\n","  Error rate\n","    Error rate (ER)                 : 0.14 \n","    Deletion rate                   : 0.09 \n","    Insertion rate                  : 0.04 \n","  Accuracy\n","    Sensitivity                     : 90.62 %\n","    Specificity                     : 92.71 %\n","    Balanced accuracy               : 91.67 %\n","    Accuracy                        : 91.41 %\n","  \n","\n","  Class-wise metrics\n","  ======================================\n","    Event label  | Nref    Nsys  | F        Pre      Rec    | ER       Del      Ins    | Sens     Spec     Bacc     Acc     \n","    ------------ | -----   ----- | ------   ------   ------ | ------   ------   ------ | ------   ------   ------   ------  \n","    Frying       | 160     152   | 92.9%    95.4%    90.6%  | 0.14     0.09     0.04   | 90.6%    92.7%    91.7%    91.4%   \n","\n","\n","Event based metrics (onset-offset)\n","========================================\n","  Evaluated length                  : 254.09 sec\n","  Evaluated files                   : 26 \n","  Evaluate onset                    : True \n","  Evaluate offset                   : True \n","  T collar                          : 250.00 ms\n","  Offset (length)                   : 50.00 %\n","\n","  Overall metrics (micro-average)\n","  ======================================\n","  F-measure\n","    F-measure (F1)                  : 58.06 %\n","    Precision                       : 52.94 %\n","    Recall                          : 64.29 %\n","  Error rate\n","    Error rate (ER)                 : 0.93 \n","    Substitution rate               : 0.00 \n","    Deletion rate                   : 0.36 \n","    Insertion rate                  : 0.57 \n","\n","  Class-wise average metrics (macro-average)\n","  ======================================\n","  F-measure\n","    F-measure (F1)                  : 58.06 %\n","    Precision                       : 52.94 %\n","    Recall                          : 64.29 %\n","  Error rate\n","    Error rate (ER)                 : 0.93 \n","    Deletion rate                   : 0.36 \n","    Insertion rate                  : 0.57 \n","  \n","\n","  Class-wise metrics\n","  ======================================\n","    Event label  | Nref    Nsys  | F        Pre      Rec    | ER       Del      Ins    |\n","    ------------ | -----   ----- | ------   ------   ------ | ------   ------   ------ |\n","    Frying       | 28      34    | 58.1%    52.9%    64.3%  | 0.93     0.36     0.57   |\n","\n","\n","--------------------------------------------------------------------------------\n","7 ------ Running_water 143\n","1/1 [==============================] - 1s 523ms/step\n","PRECISION: 0.9198428290766208\n","RECALL: 0.8514275322785961\n","F1: 0.8843139106620077\n","--------------------\n","tp: 4682\n","tn: 6621\n","fp: 408\n","fn: 817\n","--------------------------------------------------------------------------------\n","2\n","29\n","2\n","29\n","PRECISION: 0.9198428290766208\n","RECALL: 0.8514275322785961\n","F1: 0.8843139106620077\n","--------------------\n","tp: 4682\n","tn: 6621\n","fp: 408\n","fn: 817\n","--------------------------------------------------------------------------------\n","Accuracy: 0.9110320284697508\n","Segment based metrics\n","========================================\n","  Evaluated length                  : 278.30 sec\n","  Evaluated files                   : 29 \n","  Segment length                    : 1.00 sec\n","\n","  Overall metrics (micro-average)\n","  ======================================\n","  F-measure\n","    F-measure (F1)                  : 91.47 %\n","    Precision                       : 92.41 %\n","    Recall                          : 90.54 %\n","  Error rate\n","    Error rate (ER)                 : 0.17 \n","    Substitution rate               : 0.00 \n","    Deletion rate                   : 0.09 \n","    Insertion rate                  : 0.07 \n","  Accuracy\n","    Sensitivity                     : 90.54 %\n","    Specificity                     : 91.73 %\n","    Balanced accuracy               : 91.13 %\n","    Accuracy                        : 91.10 %\n","\n","  Class-wise average metrics (macro-average)\n","  ======================================\n","  F-measure\n","    F-measure (F1)                  : 91.47 %\n","    Precision                       : 92.41 %\n","    Recall                          : 90.54 %\n","  Error rate\n","    Error rate (ER)                 : 0.17 \n","    Deletion rate                   : 0.09 \n","    Insertion rate                  : 0.07 \n","  Accuracy\n","    Sensitivity                     : 90.54 %\n","    Specificity                     : 91.73 %\n","    Balanced accuracy               : 91.13 %\n","    Accuracy                        : 91.10 %\n","  \n","\n","  Class-wise metrics\n","  ======================================\n","    Event label  | Nref    Nsys  | F        Pre      Rec    | ER       Del      Ins    | Sens     Spec     Bacc     Acc     \n","    ------------ | -----   ----- | ------   ------   ------ | ------   ------   ------ | ------   ------   ------   ------  \n","    Running_wa.. | 148     145   | 91.5%    92.4%    90.5%  | 0.17     0.09     0.07   | 90.5%    91.7%    91.1%    91.1%   \n","\n","\n","Event based metrics (onset-offset)\n","========================================\n","  Evaluated length                  : 271.74 sec\n","  Evaluated files                   : 29 \n","  Evaluate onset                    : True \n","  Evaluate offset                   : True \n","  T collar                          : 250.00 ms\n","  Offset (length)                   : 50.00 %\n","\n","  Overall metrics (micro-average)\n","  ======================================\n","  F-measure\n","    F-measure (F1)                  : 36.78 %\n","    Precision                       : 29.63 %\n","    Recall                          : 48.48 %\n","  Error rate\n","    Error rate (ER)                 : 1.67 \n","    Substitution rate               : 0.00 \n","    Deletion rate                   : 0.52 \n","    Insertion rate                  : 1.15 \n","\n","  Class-wise average metrics (macro-average)\n","  ======================================\n","  F-measure\n","    F-measure (F1)                  : 36.78 %\n","    Precision                       : 29.63 %\n","    Recall                          : 48.48 %\n","  Error rate\n","    Error rate (ER)                 : 1.67 \n","    Deletion rate                   : 0.52 \n","    Insertion rate                  : 1.15 \n","  \n","\n","  Class-wise metrics\n","  ======================================\n","    Event label  | Nref    Nsys  | F        Pre      Rec    | ER       Del      Ins    |\n","    ------------ | -----   ----- | ------   ------   ------ | ------   ------   ------ |\n","    Running_wa.. | 33      54    | 36.8%    29.6%    48.5%  | 1.67     0.52     1.15   |\n","\n","\n","--------------------------------------------------------------------------------\n","8 ------ Speech 1272\n","8/8 [==============================] - 1s 67ms/step\n","PRECISION: 0.864605049803104\n","RECALL: 0.7398414271555996\n","F1: 0.7973723563341166\n","--------------------\n","tp: 14930\n","tn: 87642\n","fp: 2338\n","fn: 5250\n","--------------------------------------------------------------------------------\n","2\n","255\n","2\n","255\n","PRECISION: 0.864605049803104\n","RECALL: 0.7398414271555996\n","F1: 0.7973723563341166\n","--------------------\n","tp: 14930\n","tn: 87642\n","fp: 2338\n","fn: 5250\n","--------------------------------------------------------------------------------\n","Accuracy: 0.8649183572488867\n","Segment based metrics\n","========================================\n","  Evaluated length                  : 1921.75 sec\n","  Evaluated files                   : 255 \n","  Segment length                    : 1.00 sec\n","\n","  Overall metrics (micro-average)\n","  ======================================\n","  F-measure\n","    F-measure (F1)                  : 83.74 %\n","    Precision                       : 85.94 %\n","    Recall                          : 81.65 %\n","  Error rate\n","    Error rate (ER)                 : 0.32 \n","    Substitution rate               : 0.00 \n","    Deletion rate                   : 0.18 \n","    Insertion rate                  : 0.13 \n","  Accuracy\n","    Sensitivity                     : 81.65 %\n","    Specificity                     : 90.09 %\n","    Balanced accuracy               : 85.87 %\n","    Accuracy                        : 86.49 %\n","\n","  Class-wise average metrics (macro-average)\n","  ======================================\n","  F-measure\n","    F-measure (F1)                  : 83.74 %\n","    Precision                       : 85.94 %\n","    Recall                          : 81.65 %\n","  Error rate\n","    Error rate (ER)                 : 0.32 \n","    Deletion rate                   : 0.18 \n","    Insertion rate                  : 0.13 \n","  Accuracy\n","    Sensitivity                     : 81.65 %\n","    Specificity                     : 90.09 %\n","    Balanced accuracy               : 85.87 %\n","    Accuracy                        : 86.49 %\n","  \n","\n","  Class-wise metrics\n","  ======================================\n","    Event label  | Nref    Nsys  | F        Pre      Rec    | ER       Del      Ins    | Sens     Spec     Bacc     Acc     \n","    ------------ | -----   ----- | ------   ------   ------ | ------   ------   ------ | ------   ------   ------   ------  \n","    Speech       | 861     818   | 83.7%    85.9%    81.6%  | 0.32     0.18     0.13   | 81.6%    90.1%    85.9%    86.5%   \n","\n","\n","Event based metrics (onset-offset)\n","========================================\n","  Evaluated length                  : 1798.80 sec\n","  Evaluated files                   : 255 \n","  Evaluate onset                    : True \n","  Evaluate offset                   : True \n","  T collar                          : 250.00 ms\n","  Offset (length)                   : 50.00 %\n","\n","  Overall metrics (micro-average)\n","  ======================================\n","  F-measure\n","    F-measure (F1)                  : 59.89 %\n","    Precision                       : 55.73 %\n","    Recall                          : 64.72 %\n","  Error rate\n","    Error rate (ER)                 : 0.87 \n","    Substitution rate               : 0.00 \n","    Deletion rate                   : 0.35 \n","    Insertion rate                  : 0.51 \n","\n","  Class-wise average metrics (macro-average)\n","  ======================================\n","  F-measure\n","    F-measure (F1)                  : 59.89 %\n","    Precision                       : 55.73 %\n","    Recall                          : 64.72 %\n","  Error rate\n","    Error rate (ER)                 : 0.87 \n","    Deletion rate                   : 0.35 \n","    Insertion rate                  : 0.51 \n","  \n","\n","  Class-wise metrics\n","  ======================================\n","    Event label  | Nref    Nsys  | F        Pre      Rec    | ER       Del      Ins    |\n","    ------------ | -----   ----- | ------   ------   ------ | ------   ------   ------ |\n","    Speech       | 428     497   | 59.9%    55.7%    64.7%  | 0.87     0.35     0.51   |\n","\n","\n","--------------------------------------------------------------------------------\n","9 ------ Vacuum_cleaner 196\n","2/2 [==============================] - 0s 215ms/step\n","PRECISION: 0.9326499231163506\n","RECALL: 0.9657148922619679\n","F1: 0.9488944513975803\n","--------------------\n","tp: 9098\n","tn: 7202\n","fp: 657\n","fn: 323\n","--------------------------------------------------------------------------------\n","2\n","40\n","2\n","40\n","PRECISION: 0.9326499231163506\n","RECALL: 0.9657148922619679\n","F1: 0.9488944513975803\n","--------------------\n","tp: 9098\n","tn: 7202\n","fp: 657\n","fn: 323\n","--------------------------------------------------------------------------------\n","Accuracy: 0.9367088607594937\n","Segment based metrics\n","========================================\n","  Evaluated length                  : 393.07 sec\n","  Evaluated files                   : 40 \n","  Segment length                    : 1.00 sec\n","\n","  Overall metrics (micro-average)\n","  ======================================\n","  F-measure\n","    F-measure (F1)                  : 94.87 %\n","    Precision                       : 90.94 %\n","    Recall                          : 99.14 %\n","  Error rate\n","    Error rate (ER)                 : 0.11 \n","    Substitution rate               : 0.00 \n","    Deletion rate                   : 0.01 \n","    Insertion rate                  : 0.10 \n","  Accuracy\n","    Sensitivity                     : 99.14 %\n","    Specificity                     : 85.80 %\n","    Balanced accuracy               : 92.47 %\n","    Accuracy                        : 93.67 %\n","\n","  Class-wise average metrics (macro-average)\n","  ======================================\n","  F-measure\n","    F-measure (F1)                  : 94.87 %\n","    Precision                       : 90.94 %\n","    Recall                          : 99.14 %\n","  Error rate\n","    Error rate (ER)                 : 0.11 \n","    Deletion rate                   : 0.01 \n","    Insertion rate                  : 0.10 \n","  Accuracy\n","    Sensitivity                     : 99.14 %\n","    Specificity                     : 85.80 %\n","    Balanced accuracy               : 92.47 %\n","    Accuracy                        : 93.67 %\n","  \n","\n","  Class-wise metrics\n","  ======================================\n","    Event label  | Nref    Nsys  | F        Pre      Rec    | ER       Del      Ins    | Sens     Spec     Bacc     Acc     \n","    ------------ | -----   ----- | ------   ------   ------ | ------   ------   ------ | ------   ------   ------   ------  \n","    Vacuum_cle.. | 233     254   | 94.9%    90.9%    99.1%  | 0.11     0.01     0.10   | 99.1%    85.8%    92.5%    93.7%   \n","\n","\n","Event based metrics (onset-offset)\n","========================================\n","  Evaluated length                  : 384.10 sec\n","  Evaluated files                   : 40 \n","  Evaluate onset                    : True \n","  Evaluate offset                   : True \n","  T collar                          : 250.00 ms\n","  Offset (length)                   : 50.00 %\n","\n","  Overall metrics (micro-average)\n","  ======================================\n","  F-measure\n","    F-measure (F1)                  : 57.45 %\n","    Precision                       : 50.00 %\n","    Recall                          : 67.50 %\n","  Error rate\n","    Error rate (ER)                 : 1.00 \n","    Substitution rate               : 0.00 \n","    Deletion rate                   : 0.33 \n","    Insertion rate                  : 0.68 \n","\n","  Class-wise average metrics (macro-average)\n","  ======================================\n","  F-measure\n","    F-measure (F1)                  : 57.45 %\n","    Precision                       : 50.00 %\n","    Recall                          : 67.50 %\n","  Error rate\n","    Error rate (ER)                 : 1.00 \n","    Deletion rate                   : 0.33 \n","    Insertion rate                  : 0.68 \n","  \n","\n","  Class-wise metrics\n","  ======================================\n","    Event label  | Nref    Nsys  | F        Pre      Rec    | ER       Del      Ins    |\n","    ------------ | -----   ----- | ------   ------   ------ | ------   ------   ------ |\n","    Vacuum_cle.. | 40      54    | 57.4%    50.0%    67.5%  | 1.00     0.33     0.68   |\n","\n","\n","--------------------------------------------------------------------------------\n","--------------------------------------------------------------------------------\n","FINAL EVALUATION: \n","--------------------------------------------------------------------------------\n","Accuracy: 0.9846235045742435\n","Segment based metrics\n","========================================\n","  Evaluated length                  : 5490.87 sec\n","  Evaluated files                   : 673 \n","  Segment length                    : 1.00 sec\n","\n","  Overall metrics (micro-average)\n","  ======================================\n","  F-measure\n","    F-measure (F1)                  : 84.60 %\n","    Precision                       : 87.28 %\n","    Recall                          : 82.09 %\n","  Error rate\n","    Error rate (ER)                 : 0.30 \n","    Substitution rate               : 0.00 \n","    Deletion rate                   : 0.18 \n","    Insertion rate                  : 0.12 \n","  Accuracy\n","    Sensitivity                     : 82.09 %\n","    Specificity                     : 99.35 %\n","    Balanced accuracy               : 90.72 %\n","    Accuracy                        : 98.46 %\n","\n","  Class-wise average metrics (macro-average)\n","  ======================================\n","  F-measure\n","    F-measure (F1)                  : 84.13 %\n","    Precision                       : 87.28 %\n","    Recall                          : 82.22 %\n","  Error rate\n","    Error rate (ER)                 : 0.29 \n","    Deletion rate                   : 0.18 \n","    Insertion rate                  : 0.11 \n","  Accuracy\n","    Sensitivity                     : 82.22 %\n","    Specificity                     : 99.33 %\n","    Balanced accuracy               : 90.77 %\n","    Accuracy                        : 98.46 %\n","  \n","\n","  Class-wise metrics\n","  ======================================\n","    Event label  | Nref    Nsys  | F        Pre      Rec    | ER       Del      Ins    | Sens     Spec     Bacc     Acc     \n","    ------------ | -----   ----- | ------   ------   ------ | ------   ------   ------ | ------   ------   ------   ------  \n","    Alarm_bell.. | 304     280   | 76.4%    79.6%    73.4%  | 0.45     0.27     0.19   | 73.4%    98.9%    86.1%    97.6%   \n","    Blender      | 367     380   | 92.6%    91.1%    94.3%  | 0.15     0.06     0.09   | 94.3%    99.4%    96.8%    99.0%   \n","    Cat          | 198     194   | 79.6%    80.4%    78.8%  | 0.40     0.21     0.19   | 78.8%    99.3%    89.0%    98.6%   \n","    Dishes       | 241     129   | 55.7%    79.8%    42.7%  | 0.68     0.57     0.11   | 42.7%    99.5%    71.1%    97.1%   \n","    Dog          | 179     166   | 75.9%    78.9%    73.2%  | 0.46     0.27     0.20   | 73.2%    99.4%    86.3%    98.5%   \n","    Electric_s.. | 234     233   | 98.1%    98.3%    97.9%  | 0.04     0.02     0.02   | 97.9%    99.9%    98.9%    99.8%   \n","    Frying       | 160     152   | 92.9%    95.4%    90.6%  | 0.14     0.09     0.04   | 90.6%    99.9%    95.2%    99.6%   \n","    Running_wa.. | 148     145   | 91.5%    92.4%    90.5%  | 0.17     0.09     0.07   | 90.5%    99.8%    95.2%    99.6%   \n","    Speech       | 861     818   | 83.7%    85.9%    81.6%  | 0.32     0.18     0.13   | 81.6%    97.6%    89.6%    95.2%   \n","    Vacuum_cle.. | 233     254   | 94.9%    90.9%    99.1%  | 0.11     0.01     0.10   | 99.1%    99.6%    99.4%    99.6%   \n","\n","\n","Event based metrics (onset-offset)\n","========================================\n","  Evaluated length                  : 5270.76 sec\n","  Evaluated files                   : 673 \n","  Evaluate onset                    : True \n","  Evaluate offset                   : True \n","  T collar                          : 250.00 ms\n","  Offset (length)                   : 50.00 %\n","\n","  Overall metrics (micro-average)\n","  ======================================\n","  F-measure\n","    F-measure (F1)                  : 54.56 %\n","    Precision                       : 50.35 %\n","    Recall                          : 59.53 %\n","  Error rate\n","    Error rate (ER)                 : 0.99 \n","    Substitution rate               : 0.00 \n","    Deletion rate                   : 0.40 \n","    Insertion rate                  : 0.58 \n","\n","  Class-wise average metrics (macro-average)\n","  ======================================\n","  F-measure\n","    F-measure (F1)                  : 54.98 %\n","    Precision                       : 50.11 %\n","    Recall                          : 61.95 %\n","  Error rate\n","    Error rate (ER)                 : 1.02 \n","    Deletion rate                   : 0.38 \n","    Insertion rate                  : 0.64 \n","  \n","\n","  Class-wise metrics\n","  ======================================\n","    Event label  | Nref    Nsys  | F        Pre      Rec    | ER       Del      Ins    |\n","    ------------ | -----   ----- | ------   ------   ------ | ------   ------   ------ |\n","    Alarm_bell.. | 153     204   | 43.1%    37.7%    50.3%  | 1.33     0.50     0.83   |\n","    Blender      | 101     124   | 72.0%    65.3%    80.2%  | 0.62     0.20     0.43   |\n","    Cat          | 101     148   | 50.6%    42.6%    62.4%  | 1.22     0.38     0.84   |\n","    Dishes       | 165     116   | 36.3%    44.0%    30.9%  | 1.08     0.69     0.39   |\n","    Dog          | 101     128   | 52.4%    46.9%    59.4%  | 1.08     0.41     0.67   |\n","    Electric_s.. | 46      55    | 83.2%    76.4%    91.3%  | 0.37     0.09     0.28   |\n","    Frying       | 28      34    | 58.1%    52.9%    64.3%  | 0.93     0.36     0.57   |\n","    Running_wa.. | 33      54    | 36.8%    29.6%    48.5%  | 1.67     0.52     1.15   |\n","    Speech       | 428     497   | 59.9%    55.7%    64.7%  | 0.87     0.35     0.51   |\n","    Vacuum_cle.. | 40      54    | 57.4%    50.0%    67.5%  | 1.00     0.33     0.68   |\n","\n","\n","--------------------------------------------------------------------------------\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"vBF__jjihr6H","colab":{"base_uri":"https://localhost:8080/","height":204},"executionInfo":{"status":"ok","timestamp":1624912912239,"user_tz":-120,"elapsed":418,"user":{"displayName":"Mihajlo Perendija","photoUrl":"","userId":"04858557923362990038"}},"outputId":"f92fa4ba-1940-4297-a8a8-0843e73e5c07"},"source":["events = pd.read_csv(\"/content/drive/MyDrive/neuronske/data/Synthetic_dataset/synthetic_dataset.csv\", delimiter=\"\\t\") \n","events.head()"],"execution_count":14,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>filename</th>\n","      <th>onset</th>\n","      <th>offset</th>\n","      <th>event_label</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>10.wav</td>\n","      <td>0.287159</td>\n","      <td>1.057712</td>\n","      <td>Alarm_bell_ringing</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>10.wav</td>\n","      <td>1.717124</td>\n","      <td>1.967124</td>\n","      <td>Alarm_bell_ringing</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>10.wav</td>\n","      <td>5.049573</td>\n","      <td>6.013632</td>\n","      <td>Alarm_bell_ringing</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>10.wav</td>\n","      <td>7.240901</td>\n","      <td>8.492352</td>\n","      <td>Speech</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>1000.wav</td>\n","      <td>4.352958</td>\n","      <td>4.664092</td>\n","      <td>Alarm_bell_ringing</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   filename     onset    offset         event_label\n","0    10.wav  0.287159  1.057712  Alarm_bell_ringing\n","1    10.wav  1.717124  1.967124  Alarm_bell_ringing\n","2    10.wav  5.049573  6.013632  Alarm_bell_ringing\n","3    10.wav  7.240901  8.492352              Speech\n","4  1000.wav  4.352958  4.664092  Alarm_bell_ringing"]},"metadata":{"tags":[]},"execution_count":14}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2inhr4We1s4A","executionInfo":{"status":"ok","timestamp":1624912911823,"user_tz":-120,"elapsed":10328,"user":{"displayName":"Mihajlo Perendija","photoUrl":"","userId":"04858557923362990038"}},"outputId":"805c79c9-b9aa-49f7-e21e-a9bc9e15d230"},"source":["!pip install sed_eval\n","\n","import sed_eval\n","import dcase_util\n","\n","def return_onsets_and_offsets_for_sequence(sequence, duration_seconds=10):\n","  single_tick_in_seconds = duration_seconds / len(sequence)\n","  onsets = []\n","  offsets = []\n","\n","  error_allowance = 5\n","  error_counter = 0\n","  in_positive_sequence = 0\n","  \n","  for index, tick in enumerate(sequence):\n","    if tick and not(in_positive_sequence):\n","      in_positive_sequence = 1\n","      onsets.append(index * single_tick_in_seconds)\n","    elif not(tick) and in_positive_sequence:\n","      if error_counter >= error_allowance:\n","        error_counter = 0\n","        in_positive_sequence = 0\n","        offsets.append((index - error_allowance) * single_tick_in_seconds)\n","      else:\n","        error_counter = error_counter + 1\n","    elif tick and in_positive_sequence and error_counter:\n","      error_counter = 0\n","  if in_positive_sequence:\n","    offsets.append((index) * single_tick_in_seconds)\n","\n","  return onsets, offsets\n","\n","def prepare_predicted_sequences_for_evaluation_and_evaluate(event_label, y_pred, I_test, training_data, events_data, return_prepared_data_flag = 0):\n","  references = []\n","  estimations = []\n","\n","  for i, y_predicted in enumerate(y_pred):\n","    file_index = I_test[i]\n","    file_name = training_data.iloc[file_index]['filename']\n","\n","    onsets, offsets = return_onsets_and_offsets_for_sequence(y_predicted, 10)\n","\n","    for j, onset in enumerate(onsets):\n","      estimations.append({\n","          'event_label': event_label,\n","          'event_onset': onset,\n","          'event_offset': offsets[j],\n","          'file': file_name\n","      })\n","\n","    reference_events = events_data[(events_data['filename'] == file_name) & (events_data['event_label'] == event_label)]\n","    for ref_event in np.asarray(reference_events):\n","      references.append({\n","          'event_label': event_label,\n","          'event_onset': ref_event[1],\n","          'event_offset': ref_event[2],\n","          'file': file_name\n","      })\n","\n","  evaluate_and_print_results(references, estimations)\n","\n","  if return_prepared_data_flag:\n","    return references, estimations\n","\n","\n","def evaluate_and_print_results(references, estimations):\n","  reference_event_list = dcase_util.containers.MetaDataContainer(\n","      references\n","  )\n","\n","  estimated_event_list = dcase_util.containers.MetaDataContainer(\n","      estimations\n","  )\n","\n","  segment_based_metrics = sed_eval.sound_event.SegmentBasedMetrics(\n","      event_label_list=reference_event_list.unique_event_labels,\n","      time_resolution=1.0\n","  )\n","  event_based_metrics = sed_eval.sound_event.EventBasedMetrics(\n","      event_label_list=reference_event_list.unique_event_labels,\n","      t_collar=0.250,\n","      evaluate_onset=True,\n","      evaluate_offset=True,\n","      percentage_of_length=0.5\n","  )\n","\n","  for filename in reference_event_list.unique_files:\n","      reference_event_list_for_current_file = reference_event_list.filter(\n","          filename=filename\n","      )\n","\n","      estimated_event_list_for_current_file = estimated_event_list.filter(\n","          filename=filename\n","      )\n","\n","      segment_based_metrics.evaluate(\n","          reference_event_list=reference_event_list_for_current_file,\n","          estimated_event_list=estimated_event_list_for_current_file\n","      )\n","\n","      event_based_metrics.evaluate(\n","          reference_event_list=reference_event_list_for_current_file,\n","          estimated_event_list=estimated_event_list_for_current_file\n","      )\n","\n","  # Get only certain metrics\n","  overall_segment_based_metrics = segment_based_metrics.results_overall_metrics()\n","  print(\"Accuracy:\", overall_segment_based_metrics['accuracy']['accuracy'])\n","\n","  # Or print all metrics as reports\n","  print(segment_based_metrics)\n","  print(event_based_metrics)"],"execution_count":13,"outputs":[{"output_type":"stream","text":["Collecting sed_eval\n","  Downloading https://files.pythonhosted.org/packages/8d/b2/55591da46753ad1f1d375f5a0d1e12728ae9bf7270ecf47ff7fe902a4274/sed_eval-0.2.1.tar.gz\n","Requirement already satisfied: numpy>=1.7.0 in /usr/local/lib/python3.7/dist-packages (from sed_eval) (1.19.5)\n","Collecting dcase_util>=0.2.4\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9b/d4/7568088c54690a85d7dfa22b86993ce3f3d20affca91c67e4babc7df55b8/dcase_util-0.2.18.tar.gz (2.1MB)\n","\u001b[K     || 2.1MB 39.8MB/s \n","\u001b[?25hRequirement already satisfied: scipy>=0.19.1 in /usr/local/lib/python3.7/dist-packages (from dcase_util>=0.2.4->sed_eval) (1.4.1)\n","Requirement already satisfied: matplotlib>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from dcase_util>=0.2.4->sed_eval) (3.2.2)\n","Requirement already satisfied: librosa>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from dcase_util>=0.2.4->sed_eval) (0.8.1)\n","Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from dcase_util>=0.2.4->sed_eval) (1.15.0)\n","Requirement already satisfied: future>=0.16.0 in /usr/local/lib/python3.7/dist-packages (from dcase_util>=0.2.4->sed_eval) (0.16.0)\n","Requirement already satisfied: soundfile>=0.9.0 in /usr/local/lib/python3.7/dist-packages (from dcase_util>=0.2.4->sed_eval) (0.10.3.post1)\n","Requirement already satisfied: pyyaml>=3.11 in /usr/local/lib/python3.7/dist-packages (from dcase_util>=0.2.4->sed_eval) (3.13)\n","Requirement already satisfied: requests>=2.12.4 in /usr/local/lib/python3.7/dist-packages (from dcase_util>=0.2.4->sed_eval) (2.23.0)\n","Requirement already satisfied: tqdm>=4.11.2 in /usr/local/lib/python3.7/dist-packages (from dcase_util>=0.2.4->sed_eval) (4.41.1)\n","Requirement already satisfied: pydot-ng>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from dcase_util>=0.2.4->sed_eval) (2.0.0)\n","Collecting validators>=0.12.0\n","  Downloading https://files.pythonhosted.org/packages/db/2f/7fed3ee94ad665ad2c1de87f858f10a7785251ff75b4fd47987888d07ef1/validators-0.18.2-py3-none-any.whl\n","Collecting python-magic>=0.4.13\n","  Downloading https://files.pythonhosted.org/packages/d3/99/c89223c6547df268596899334ee77b3051f606077317023617b1c43162fb/python_magic-0.4.24-py2.py3-none-any.whl\n","Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.0.0->dcase_util>=0.2.4->sed_eval) (2.4.7)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.0.0->dcase_util>=0.2.4->sed_eval) (0.10.0)\n","Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.0.0->dcase_util>=0.2.4->sed_eval) (2.8.1)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.0.0->dcase_util>=0.2.4->sed_eval) (1.3.1)\n","Requirement already satisfied: pooch>=1.0 in /usr/local/lib/python3.7/dist-packages (from librosa>=0.7.0->dcase_util>=0.2.4->sed_eval) (1.4.0)\n","Requirement already satisfied: numba>=0.43.0 in /usr/local/lib/python3.7/dist-packages (from librosa>=0.7.0->dcase_util>=0.2.4->sed_eval) (0.51.2)\n","Requirement already satisfied: audioread>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from librosa>=0.7.0->dcase_util>=0.2.4->sed_eval) (2.1.9)\n","Requirement already satisfied: scikit-learn!=0.19.0,>=0.14.0 in /usr/local/lib/python3.7/dist-packages (from librosa>=0.7.0->dcase_util>=0.2.4->sed_eval) (0.22.2.post1)\n","Requirement already satisfied: resampy>=0.2.2 in /usr/local/lib/python3.7/dist-packages (from librosa>=0.7.0->dcase_util>=0.2.4->sed_eval) (0.2.2)\n","Requirement already satisfied: decorator>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from librosa>=0.7.0->dcase_util>=0.2.4->sed_eval) (4.4.2)\n","Requirement already satisfied: joblib>=0.14 in /usr/local/lib/python3.7/dist-packages (from librosa>=0.7.0->dcase_util>=0.2.4->sed_eval) (1.0.1)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from librosa>=0.7.0->dcase_util>=0.2.4->sed_eval) (20.9)\n","Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.7/dist-packages (from soundfile>=0.9.0->dcase_util>=0.2.4->sed_eval) (1.14.5)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.12.4->dcase_util>=0.2.4->sed_eval) (2021.5.30)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.12.4->dcase_util>=0.2.4->sed_eval) (2.10)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.12.4->dcase_util>=0.2.4->sed_eval) (3.0.4)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.12.4->dcase_util>=0.2.4->sed_eval) (1.24.3)\n","Requirement already satisfied: appdirs in /usr/local/lib/python3.7/dist-packages (from pooch>=1.0->librosa>=0.7.0->dcase_util>=0.2.4->sed_eval) (1.4.4)\n","Requirement already satisfied: llvmlite<0.35,>=0.34.0.dev0 in /usr/local/lib/python3.7/dist-packages (from numba>=0.43.0->librosa>=0.7.0->dcase_util>=0.2.4->sed_eval) (0.34.0)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from numba>=0.43.0->librosa>=0.7.0->dcase_util>=0.2.4->sed_eval) (57.0.0)\n","Requirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi>=1.0->soundfile>=0.9.0->dcase_util>=0.2.4->sed_eval) (2.20)\n","Building wheels for collected packages: sed-eval, dcase-util\n","  Building wheel for sed-eval (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for sed-eval: filename=sed_eval-0.2.1-cp37-none-any.whl size=26124 sha256=6afbd0513794ee4c89e6df20f86f043774be97870f13130709c9ba53e607306b\n","  Stored in directory: /root/.cache/pip/wheels/3c/72/5d/5fc941f98c583ce9d8adee7f13e24b46459aeded4125f9c369\n","  Building wheel for dcase-util (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for dcase-util: filename=dcase_util-0.2.18-cp37-none-any.whl size=2147233 sha256=008df96271d30fb6afd450a36dd465e3b7a1a203b116fdefd1808243c006b797\n","  Stored in directory: /root/.cache/pip/wheels/d1/5d/9e/c94cd8bfb80541c73d549c734cafcd3de994dbb117a6485c81\n","Successfully built sed-eval dcase-util\n","Installing collected packages: validators, python-magic, dcase-util, sed-eval\n","Successfully installed dcase-util-0.2.18 python-magic-0.4.24 sed-eval-0.2.1 validators-0.18.2\n"],"name":"stdout"}]}]}